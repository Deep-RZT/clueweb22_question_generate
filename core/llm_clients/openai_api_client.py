#!/usr/bin/env python3
"""
OpenAI API Client for Deep Research QA Benchmark
Replaces Claude API with OpenAI GPT-4o for all content generation
"""

import json
import requests
import time
from typing import Dict, List, Any, Optional
from dataclasses import dataclass

@dataclass
class APIResponse:
    """ç»Ÿä¸€çš„APIå“åº”æ ¼å¼"""
    content: str
    model: str
    usage: Dict[str, int]
    success: bool
    error: Optional[str] = None

class OpenAIClient:
    """OpenAI API client for content generation"""
    
    def __init__(self, api_key: str, model: str = "gpt-4o"):
        self.api_key = api_key
        self.model = model
        self.api_url = "https://api.openai.com/v1/chat/completions"
        self.headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}"
        }
        
    def generate_content(self, prompt: str, system_prompt: str = None, 
                        max_tokens: int = 6000, temperature: float = 0.7) -> Optional[str]:
        """
        Generate content using OpenAI API with optimized parameters for longer responses
        
        Args:
            prompt: User prompt
            system_prompt: Optional system prompt
            max_tokens: Maximum tokens to generate (increased for longer responses)
            temperature: Sampling temperature
            
        Returns:
            Generated content or None if failed
        """
        
        messages = []
        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})
        messages.append({"role": "user", "content": prompt})
        
        data = {
            "model": self.model,
            "messages": messages,
            "max_tokens": max_tokens,
            "temperature": temperature,
            "top_p": 0.9,
            "frequency_penalty": 0.1,
            "presence_penalty": 0.1
        }
        
        try:
            response = requests.post(self.api_url, headers=self.headers, json=data, timeout=120)
            response.raise_for_status()
            
            result = response.json()
            if 'choices' in result and len(result['choices']) > 0:
                return result['choices'][0]['message']['content'].strip()
            else:
                print(f"âŒ No choices in OpenAI response: {result}")
                return None
                
        except requests.exceptions.RequestException as e:
            print(f"âŒ OpenAI API request failed: {e}")
            return None
        except Exception as e:
            print(f"âŒ OpenAI API error: {e}")
            return None
    
    def generate_text(self, 
                     prompt: str, 
                     max_tokens: int = 4000,
                     temperature: float = 0.7,
                     system_prompt: Optional[str] = None) -> APIResponse:
        """ç”Ÿæˆæ–‡æœ¬ - ä¸ŽClaude APIå…¼å®¹çš„æŽ¥å£"""
        
        messages = []
        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})
        messages.append({"role": "user", "content": prompt})
        
        data = {
            "model": self.model,
            "messages": messages,
            "max_tokens": max_tokens,
            "temperature": temperature,
            "top_p": 0.9,
            "frequency_penalty": 0.1,
            "presence_penalty": 0.1
        }
        
        try:
            response = requests.post(self.api_url, headers=self.headers, json=data, timeout=120)
            response.raise_for_status()
            
            result = response.json()
            if 'choices' in result and len(result['choices']) > 0:
                content = result['choices'][0]['message']['content'].strip()
                usage = result.get('usage', {})
                
                return APIResponse(
                    content=content,
                    model=self.model,
                    usage={
                        "prompt_tokens": usage.get('prompt_tokens', 0),
                        "completion_tokens": usage.get('completion_tokens', 0),
                        "total_tokens": usage.get('total_tokens', 0)
                    },
                    success=True
                )
            else:
                return APIResponse(
                    content="",
                    model=self.model,
                    usage={},
                    success=False,
                    error="No choices in response"
                )
                
        except requests.exceptions.RequestException as e:
            return APIResponse(
                content="",
                model=self.model,
                usage={},
                success=False,
                error=f"Request failed: {str(e)}"
            )
        except Exception as e:
            return APIResponse(
                content="",
                model=self.model,
                usage={},
                success=False,
                error=f"API error: {str(e)}"
            )
    
    def generate_report(self, documents: List[Dict], topic: str, max_tokens: int = 4000) -> APIResponse:
        """ç”Ÿæˆé¢†åŸŸæŠ¥å‘Š - æ”¯æŒåˆ†æ®µå¤„ç†å’Œèžåˆ"""
        
        # æ£€æŸ¥æ–‡æ¡£æ€»é•¿åº¦
        total_chars = sum(len(doc.get('content', '')) for doc in documents)
        max_chars_per_segment = 80000  # OpenAIä½¿ç”¨æ›´ä¿å®ˆçš„é™åˆ¶
        
        if total_chars > max_chars_per_segment:
            print(f"ðŸ“„ æ–‡æ¡£å†…å®¹è¿‡é•¿ ({total_chars} å­—ç¬¦)ï¼Œå¯ç”¨åˆ†æ®µå¤„ç†...")
            return self._generate_segmented_report(documents, topic, max_tokens)
        else:
            return self._generate_single_report(documents, topic, max_tokens)
    
    def _generate_single_report(self, documents: List[Dict], topic: str, max_tokens: int) -> APIResponse:
        """ç”Ÿæˆå•æ®µæŠ¥å‘Š"""
        # æž„å»ºæ–‡æ¡£å†…å®¹ï¼Œå¹¶æ£€æŸ¥é•¿åº¦
        doc_content = ""
        total_chars = 0
        max_chars = 120000  # çº¦ç›¸å½“äºŽ120K tokensçš„å®‰å…¨é™åˆ¶ï¼Œä¸ºOpenAIç•™æ›´å¤šä½™åœ°
        
        for i, doc in enumerate(documents, 1):
            doc_text = f"\næ–‡æ¡£ {i}:\næ ‡é¢˜: {doc.get('title', 'N/A')}\nå†…å®¹: {doc.get('content', 'N/A')}\n"
            
            # æ£€æŸ¥æ˜¯å¦ä¼šè¶…å‡ºé™åˆ¶
            if total_chars + len(doc_text) > max_chars:
                # å¦‚æžœæ˜¯ç¬¬ä¸€ä¸ªæ–‡æ¡£å°±è¶…é™ï¼Œæˆªæ–­è¯¥æ–‡æ¡£
                if i == 1:
                    remaining_chars = max_chars - total_chars - 200  # ç•™ä¸€äº›ç¼“å†²
                    if remaining_chars > 1000:
                        content = doc.get('content', 'N/A')[:remaining_chars]
                        doc_text = f"\næ–‡æ¡£ {i}:\næ ‡é¢˜: {doc.get('title', 'N/A')}\nå†…å®¹: {content}...[æ–‡æ¡£å·²æˆªæ–­]\n"
                        doc_content += doc_text
                    break
                else:
                    # å·²ç»æœ‰å…¶ä»–æ–‡æ¡£ï¼Œåœæ­¢æ·»åŠ 
                    print(f"âš ï¸ æ–‡æ¡£è¿‡å¤šï¼Œåªä½¿ç”¨å‰ {i-1} ä¸ªæ–‡æ¡£ç”ŸæˆæŠ¥å‘Š")
                    break
            
            doc_content += doc_text
            total_chars += len(doc_text)
        
        if not doc_content.strip():
            # å¦‚æžœæ²¡æœ‰ä»»ä½•æ–‡æ¡£å†…å®¹ï¼Œåˆ›å»ºé”™è¯¯å“åº”
            return APIResponse(
                content="",
                model=self.model,
                usage={},
                success=False,
                error="No document content available after processing"
            )
        
        print(f"ðŸ“Š ä½¿ç”¨æ–‡æ¡£å†…å®¹é•¿åº¦: {total_chars} å­—ç¬¦")
        
        system_prompt = """You are a professional research analyst. Please generate a high-quality domain report based on the provided documents.

Report requirements:
1. Length: 1500-2000 words
2. Clear structure with introduction, main findings, analysis, and conclusion
3. Deep analysis and synthesis based on document content
4. Use academic writing style
5. Write ENTIRELY in English for consistency in comparative analysis
6. If documents contain Japanese content, translate and analyze the concepts in English
7. Maintain academic rigor while ensuring all output is in English"""

        prompt = f"""Please generate a professional research report on "{topic}" based on the following documents:

{doc_content}

Generate a comprehensive 1500-2000 word research report that deeply analyzes the current state, trends, and key findings in this field. Write entirely in English. If the documents contain Japanese content, translate the key concepts and analyze them in English to ensure consistency for comparative analysis."""

        return self.generate_text(
            prompt=prompt,
            max_tokens=max_tokens,
            temperature=0.7,
            system_prompt=system_prompt
        )
    
    def _generate_segmented_report(self, documents: List[Dict], topic: str, max_tokens: int) -> APIResponse:
        """åˆ†æ®µç”ŸæˆæŠ¥å‘Šå¹¶èžåˆ"""
        
        # å°†æ–‡æ¡£åˆ†æ®µ
        segments = self._split_documents_into_segments(documents)
        print(f"ðŸ“š æ–‡æ¡£åˆ†ä¸º {len(segments)} æ®µè¿›è¡Œå¤„ç†")
        
        # ä¸ºæ¯æ®µç”Ÿæˆå­æŠ¥å‘Š
        segment_reports = []
        for i, segment_docs in enumerate(segments, 1):
            print(f"  ðŸ” å¤„ç†ç¬¬ {i}/{len(segments)} æ®µ...")
            
            try:
                segment_result = self._generate_single_report(segment_docs, f"{topic} (ç¬¬{i}æ®µ)", max_tokens // 2)
                if segment_result.success:
                    segment_reports.append({
                        'segment': i,
                        'content': segment_result.content,
                        'doc_count': len(segment_docs),
                        'usage': segment_result.usage
                    })
                    print(f"    âœ… ç¬¬{i}æ®µå®Œæˆ ({len(segment_result.content.split())} è¯)")
                else:
                    print(f"    âŒ ç¬¬{i}æ®µå¤±è´¥: {segment_result.error}")
                    
                # æ®µé—´ä¼‘æ¯
                import time
                time.sleep(2)
                
            except Exception as e:
                print(f"    âŒ ç¬¬{i}æ®µå¤„ç†å¼‚å¸¸: {e}")
                continue
        
        if not segment_reports:
            return APIResponse(
                content="",
                model=self.model,
                usage={},
                success=False,
                error="æ‰€æœ‰æ–‡æ¡£æ®µå¤„ç†å¤±è´¥"
            )
        
        # èžåˆæ‰€æœ‰æ®µæŠ¥å‘Š
        print("  ðŸ”„ èžåˆå„æ®µæŠ¥å‘Š...")
        return self._merge_segment_reports(segment_reports, topic, max_tokens)
    
    def _split_documents_into_segments(self, documents: List[Dict], max_chars_per_segment: int = 80000) -> List[List[Dict]]:
        """å°†æ–‡æ¡£åˆ†å‰²æˆæ®µ"""
        segments = []
        current_segment = []
        current_chars = 0
        
        for doc in documents:
            doc_chars = len(doc.get('content', ''))
            
            # å¦‚æžœå•ä¸ªæ–‡æ¡£å°±è¶…è¿‡é™åˆ¶ï¼Œå•ç‹¬æˆæ®µ
            if doc_chars > max_chars_per_segment:
                if current_segment:
                    segments.append(current_segment)
                    current_segment = []
                    current_chars = 0
                
                # åˆ†å‰²è¶…é•¿æ–‡æ¡£
                content = doc.get('content', '')
                chunk_size = max_chars_per_segment
                for j in range(0, len(content), chunk_size):
                    chunk_content = content[j:j + chunk_size]
                    chunk_doc = doc.copy()
                    chunk_doc['content'] = chunk_content
                    chunk_doc['title'] = f"{doc.get('title', 'N/A')} (éƒ¨åˆ†{j//chunk_size + 1})"
                    segments.append([chunk_doc])
                continue
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦å¼€å§‹æ–°æ®µ
            if current_chars + doc_chars > max_chars_per_segment and current_segment:
                segments.append(current_segment)
                current_segment = []
                current_chars = 0
            
            current_segment.append(doc)
            current_chars += doc_chars
        
        # æ·»åŠ æœ€åŽä¸€æ®µ
        if current_segment:
            segments.append(current_segment)
        
        return segments
    
    def _merge_segment_reports(self, segment_reports: List[Dict], topic: str, max_tokens: int) -> APIResponse:
        """èžåˆå„æ®µæŠ¥å‘Š"""
        
        # æž„å»ºèžåˆæç¤º
        reports_content = ""
        for report in segment_reports:
            reports_content += f"\n=== ç¬¬{report['segment']}æ®µæŠ¥å‘Š (åŸºäºŽ{report['doc_count']}ä¸ªæ–‡æ¡£) ===\n"
            reports_content += report['content']
            reports_content += "\n"
        
        system_prompt = """You are a professional research analyst. Please merge and synthesize multiple segment reports into a single comprehensive report.

Merge requirements:
1. Length: 2000-2500 words (comprehensive synthesis)
2. Eliminate redundancy while preserving key insights
3. Create coherent flow and logical structure
4. Synthesize findings across all segments
5. Maintain academic writing style
6. Write ENTIRELY in English
7. Ensure the final report is well-structured with clear sections"""

        prompt = f"""Please merge the following segment reports about "{topic}" into a single comprehensive research report:

{reports_content}

Requirements:
- Create a unified, comprehensive report that synthesizes insights from all segments
- Eliminate redundancy while preserving unique insights from each segment
- Maintain logical flow and academic structure
- Target length: 2000-2500 words
- Write entirely in English with professional academic tone"""

        try:
            merge_result = self.generate_text(
                prompt=prompt,
                max_tokens=max_tokens,
                temperature=0.7,
                system_prompt=system_prompt
            )
            
            if merge_result.success:
                print(f"    âœ… æŠ¥å‘Šèžåˆå®Œæˆ ({len(merge_result.content.split())} è¯)")
                
                # åˆå¹¶usageç»Ÿè®¡
                total_usage = {
                    'prompt_tokens': sum(r.get('usage', {}).get('prompt_tokens', 0) for r in segment_reports) + merge_result.usage.get('prompt_tokens', 0),
                    'completion_tokens': sum(r.get('usage', {}).get('completion_tokens', 0) for r in segment_reports) + merge_result.usage.get('completion_tokens', 0),
                    'total_tokens': 0
                }
                total_usage['total_tokens'] = total_usage['prompt_tokens'] + total_usage['completion_tokens']
                
                # æ›´æ–°usageä¿¡æ¯
                merge_result.usage = total_usage
                
                return merge_result
            else:
                print(f"    âŒ æŠ¥å‘Šèžåˆå¤±è´¥: {merge_result.error}")
                return merge_result
                
        except Exception as e:
            print(f"    âŒ æŠ¥å‘Šèžåˆå¼‚å¸¸: {e}")
            return APIResponse(
                content="",
                model=self.model,
                usage={},
                success=False,
                error=f"æŠ¥å‘Šèžåˆå¤±è´¥: {str(e)}"
            )
    
    def generate_questions(self, report: str, topic: str, num_questions: int = 50) -> APIResponse:
        """ç”Ÿæˆé—®é¢˜ - ä½¿ç”¨ç®€å•æ–‡æœ¬æ ¼å¼"""
        
        system_prompt = """You are a professional question design expert. Generate high-quality research questions based on the research report.

Question requirements:
1. Cover different difficulty levels: Easy (30%), Medium (40%), Hard (30%)
2. Diverse question types: fact lookup, analytical reasoning, comprehensive evaluation, critical thinking
3. Each question should be based on report content
4. Questions should evaluate deep research capabilities
5. Generate ALL questions in English for consistency in comparative analysis

IMPORTANT: Use simple text format, not JSON. Format each question as:
Q1: [Question text here]
DIFFICULTY: Easy/Medium/Hard
TYPE: Question type
REASONING: Why this question is valuable

Q2: [Next question]
DIFFICULTY: Easy/Medium/Hard
TYPE: Question type  
REASONING: Why this question is valuable"""

        prompt = f"""Based on the following research report about "{topic}", generate {num_questions} high-quality research questions:

Report content:
{report[:3000]}...

CRITICAL REQUIREMENTS:
1. Generate EXACTLY {num_questions} questions - THIS IS MANDATORY
2. Use the simple text format shown above
3. Difficulty distribution: ~{int(num_questions*0.3)} Easy, ~{int(num_questions*0.4)} Medium, ~{int(num_questions*0.3)} Hard
4. All content in English
5. Each question should be numbered Q1, Q2, Q3, ..., Q{num_questions}

DO NOT STOP until you have generated all {num_questions} questions. Count them to ensure you have exactly {num_questions}.

Generate the questions now:"""

        # è®¡ç®—éœ€è¦çš„tokenæ•°é‡: æ¯ä¸ªé—®é¢˜å¤§çº¦80-100 tokens
        estimated_tokens = num_questions * 100 + 500  # åŠ ä¸Šç¼“å†²
        max_tokens = min(max(estimated_tokens, 6000), 8000)  # æœ€å°‘6000ï¼Œæœ€å¤š8000
        
        return self.generate_text(
            prompt=prompt,
            max_tokens=max_tokens,
            temperature=0.8,
            system_prompt=system_prompt
        )
    
    def generate_answer(self, question: str, report: str, difficulty: str) -> APIResponse:
        """ç”Ÿæˆç­”æ¡ˆ"""
        
        # æ ¹æ®éš¾åº¦è®¾ç½®å­—æ•°è¦æ±‚
        word_requirements = {
            "Easy": "400-600å­—",
            "Medium": "800-1200å­—", 
            "Hard": "1500-2000å­—"
        }
        
        word_req = word_requirements.get(difficulty, "800-1200å­—")
        
        system_prompt = f"""You are a professional research expert. Please answer questions based on the provided research report.

Answer requirements:
1. Length: {word_req}
2. Based on report content, do not fabricate information
3. Clear structure and rigorous logic
4. Adjust answer depth according to question difficulty
5. Use academic writing style
6. Answer ENTIRELY in English for consistency in comparative analysis"""

        prompt = f"""Based on the following research report, answer the question:

Question: {question}
Difficulty: {difficulty}

Research Report:
{report}

Please provide a detailed answer of {word_req}. Write entirely in English for consistency in comparative analysis."""

        max_tokens = 2000 if difficulty == "Hard" else 1500 if difficulty == "Medium" else 1000
        
        return self.generate_text(
            prompt=prompt,
            max_tokens=max_tokens,
            temperature=0.7,
            system_prompt=system_prompt
        )
    
    def refine_question(self, question: str, feedback: str, report: str) -> APIResponse:
        """ä¼˜åŒ–é—®é¢˜"""
        
        system_prompt = """ä½ æ˜¯ä¸€ä½é—®é¢˜ä¼˜åŒ–ä¸“å®¶ã€‚è¯·æ ¹æ®åé¦ˆæ„è§æ”¹è¿›é—®é¢˜è´¨é‡ã€‚

ä¼˜åŒ–è¦æ±‚ï¼š
1. æé«˜é—®é¢˜çš„ç ”ç©¶æ·±åº¦
2. å¢žå¼ºå¤šæ­¥éª¤æ€è€ƒè¦æ±‚
3. ç¡®ä¿é—®é¢˜åŸºäºŽæŠ¥å‘Šå†…å®¹
4. ä¿æŒé—®é¢˜çš„æ¸…æ™°æ€§å’Œå¯å›žç­”æ€§"""

        prompt = f"""è¯·æ ¹æ®ä»¥ä¸‹åé¦ˆä¼˜åŒ–é—®é¢˜ï¼š

åŽŸé—®é¢˜ï¼š{question}

åé¦ˆæ„è§ï¼š{feedback}

ç›¸å…³æŠ¥å‘Šå†…å®¹ï¼š
{report[:1000]}...

è¯·æä¾›ä¼˜åŒ–åŽçš„é—®é¢˜ã€‚"""

        return self.generate_text(
            prompt=prompt,
            max_tokens=500,
            temperature=0.8,
            system_prompt=system_prompt
        )

    def generate_with_retry(self, prompt: str, system_prompt: str = None,
                           max_tokens: int = 4000, temperature: float = 0.7,
                           max_retries: int = 3, retry_delay: float = 2.0) -> Optional[str]:
        """
        Generate content with retry logic
        
        Args:
            prompt: User prompt
            system_prompt: System prompt (optional)
            max_tokens: Maximum tokens to generate
            temperature: Temperature for generation
            max_retries: Maximum number of retries
            retry_delay: Delay between retries in seconds
            
        Returns:
            Generated content or None if all retries failed
        """
        
        for attempt in range(max_retries + 1):
            result = self.generate_content(
                prompt=prompt,
                system_prompt=system_prompt,
                max_tokens=max_tokens,
                temperature=temperature
            )
            
            if result is not None:
                return result
            
            if attempt < max_retries:
                print(f"   ðŸ”„ Retrying in {retry_delay} seconds... (attempt {attempt + 1}/{max_retries})")
                time.sleep(retry_delay)
        
        print(f"   âŒ All {max_retries + 1} attempts failed")
        return None

# Compatibility functions for easy migration from Claude API
def call_openai_api(prompt: str, api_key: str, system_prompt: str = None,
                   max_tokens: int = 4000, temperature: float = 0.7) -> Optional[str]:
    """
    Compatibility function for easy migration from Claude API calls
    
    Args:
        prompt: User prompt
        api_key: OpenAI API key
        system_prompt: System prompt (optional)
        max_tokens: Maximum tokens to generate
        temperature: Temperature for generation
        
    Returns:
        Generated content or None if failed
    """
    client = OpenAIClient(api_key)
    return client.generate_content(
        prompt=prompt,
        system_prompt=system_prompt,
        max_tokens=max_tokens,
        temperature=temperature
    )

def call_openai_with_messages(api_key: str, messages: List[Dict[str, str]], 
                             model: str = "gpt-4o", max_tokens: int = 6000, 
                             temperature: float = 0.7) -> Optional[str]:
    """
    Call OpenAI API with messages format - optimized for longer responses
    
    Args:
        api_key: OpenAI API key
        messages: List of message dictionaries
        model: Model to use
        max_tokens: Maximum tokens (increased default)
        temperature: Sampling temperature
        
    Returns:
        Generated content or None if failed
    """
    
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {api_key}"
    }
    
    data = {
        "model": model,
        "messages": messages,
        "max_tokens": max_tokens,
        "temperature": temperature,
        "top_p": 0.9,
        "frequency_penalty": 0.1,
        "presence_penalty": 0.1
    }
    
    try:
        response = requests.post(
            "https://api.openai.com/v1/chat/completions", 
            headers=headers, 
            json=data, 
            timeout=120
        )
        response.raise_for_status()
        
        result = response.json()
        if 'choices' in result and len(result['choices']) > 0:
            return result['choices'][0]['message']['content'].strip()
        else:
            print(f"âŒ No choices in OpenAI response: {result}")
            return None
            
    except requests.exceptions.RequestException as e:
        print(f"âŒ OpenAI API request failed: {e}")
        return None
    except Exception as e:
        print(f"âŒ OpenAI API error: {e}")
        return None

def get_difficulty_specific_system_prompt(difficulty: str) -> str:
    """
    Get system prompt optimized for specific difficulty levels
    
    Args:
        difficulty: Question difficulty (Easy, Medium, Hard)
        
    Returns:
        Optimized system prompt for the difficulty level
    """
    
    base_prompt = """You are an expert researcher providing comprehensive, evidence-based analysis. Your responses must be:

- Structured with clear sections (Introduction, Analysis, Synthesis, Conclusion)
- Well-cited with references to the domain report
- Academically rigorous and detailed
- Written in a formal, analytical style"""

    if difficulty == "Hard":
        return base_prompt + """

CRITICAL REQUIREMENTS FOR HARD QUESTIONS:
- Minimum 1500-2000 words
- Multi-dimensional analysis with interdisciplinary perspectives
- Deep synthesis of complex relationships and patterns
- Critical evaluation of methodological considerations
- Exploration of systemic implications and future developments
- Comprehensive evidence integration from multiple angles
- Sophisticated argumentation with nuanced conclusions

Focus on depth, complexity, and comprehensive coverage of all aspects."""

    elif difficulty == "Medium":
        return base_prompt + """

REQUIREMENTS FOR MEDIUM QUESTIONS:
- Target 800-1200 words
- Multi-step analytical thinking
- Synthesis of different aspects from the domain report
- Critical evaluation of evidence and limitations
- Clear pattern identification and relationship mapping
- Integration of theoretical and practical perspectives

Provide thorough analysis with moderate complexity."""

    else:  # Easy
        return base_prompt + """

REQUIREMENTS FOR EASY QUESTIONS:
- Target 400-600 words
- Clear, direct analysis
- Evidence-based reasoning
- Logical structure and flow
- Accessible but comprehensive coverage

Provide complete but concise analysis.""" 