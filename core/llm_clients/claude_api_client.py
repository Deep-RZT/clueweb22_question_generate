#!/usr/bin/env python3
"""
Claude API Client - ç›´æ¥HTTPè¯·æ±‚ç‰ˆæœ¬
ä½¿ç”¨requestsåº“ç›´æ¥è°ƒç”¨Claude APIï¼Œä¸ä¾èµ–anthropic package
"""

import requests
import json
import time
import logging
from typing import Dict, List, Any, Optional
import os
from dataclasses import dataclass

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class APIResponse:
    """ç»Ÿä¸€çš„APIå“åº”æ ¼å¼"""
    content: str
    model: str
    usage: Dict[str, int]
    success: bool
    error: Optional[str] = None

class ClaudeAPIClient:
    """Claude APIå®¢æˆ·ç«¯ - ç›´æ¥HTTPè¯·æ±‚ç‰ˆæœ¬"""
    
    def __init__(self, api_key: Optional[str] = None):
        """åˆå§‹åŒ–Claudeå®¢æˆ·ç«¯"""
        self.api_key = api_key or os.getenv('ANTHROPIC_API_KEY')
        if not self.api_key:
            raise ValueError("Claude API key not found. Please set ANTHROPIC_API_KEY environment variable.")
        
        self.base_url = "https://api.anthropic.com/v1/messages"
        self.model = "claude-sonnet-4-20250514"  # Claude Sonnet 4
        
        # è¯·æ±‚é™åˆ¶
        self.max_retries = 3
        self.retry_delay = 2
        
        # HTTP headers
        self.headers = {
            "x-api-key": self.api_key,
            "anthropic-version": "2023-06-01",
            "content-type": "application/json"
        }
        
    def _make_request(self, payload: Dict[str, Any]) -> APIResponse:
        """å‘é€HTTPè¯·æ±‚åˆ°Claude API"""
        
        for attempt in range(self.max_retries):
            try:
                logger.info(f"å‘é€Claude APIè¯·æ±‚ (å°è¯• {attempt + 1}/{self.max_retries})")
                
                response = requests.post(
                    self.base_url,
                    headers=self.headers,
                    json=payload,
                    timeout=120  # 2åˆ†é’Ÿè¶…æ—¶
                )
                
                logger.info(f"Claude APIå“åº”çŠ¶æ€ç : {response.status_code}")
                
                if response.status_code == 200:
                    data = response.json()
                    
                    # æå–å“åº”å†…å®¹
                    content = ""
                    if "content" in data and data["content"]:
                        content = data["content"][0].get("text", "")
                    
                    # æ„å»ºç»Ÿä¸€å“åº”
                    usage = data.get("usage", {})
                    api_response = APIResponse(
                        content=content,
                        model=self.model,
                        usage={
                            "prompt_tokens": usage.get("input_tokens", 0),
                            "completion_tokens": usage.get("output_tokens", 0),
                            "total_tokens": usage.get("input_tokens", 0) + usage.get("output_tokens", 0)
                        },
                        success=True
                    )
                    
                    logger.info(f"Claude APIè°ƒç”¨æˆåŠŸ - è¾“å…¥: {usage.get('input_tokens', 0)} tokens, è¾“å‡º: {usage.get('output_tokens', 0)} tokens")
                    return api_response
                
                elif response.status_code == 429:
                    # é€Ÿç‡é™åˆ¶
                    logger.warning(f"Claude APIé€Ÿç‡é™åˆ¶ (å°è¯• {attempt + 1}/{self.max_retries})")
                    if attempt < self.max_retries - 1:
                        time.sleep(self.retry_delay * (2 ** attempt))
                        continue
                    else:
                        return APIResponse(
                            content="",
                            model=self.model,
                            usage={},
                            success=False,
                            error=f"Rate limit exceeded after {self.max_retries} attempts"
                        )
                
                elif response.status_code == 401:
                    # è®¤è¯å¤±è´¥
                    return APIResponse(
                        content="",
                        model=self.model,
                        usage={},
                        success=False,
                        error="Authentication failed - invalid API key"
                    )
                
                else:
                    # å…¶ä»–HTTPé”™è¯¯
                    error_msg = f"HTTP {response.status_code}: {response.text}"
                    logger.error(f"Claude APIé”™è¯¯: {error_msg}")
                    
                    if attempt < self.max_retries - 1:
                        time.sleep(self.retry_delay)
                        continue
                    else:
                        return APIResponse(
                            content="",
                            model=self.model,
                            usage={},
                            success=False,
                            error=error_msg
                        )
                        
            except requests.exceptions.Timeout:
                logger.warning(f"Claude APIè¯·æ±‚è¶…æ—¶ (å°è¯• {attempt + 1}/{self.max_retries})")
                if attempt < self.max_retries - 1:
                    time.sleep(self.retry_delay)
                    continue
                else:
                    return APIResponse(
                        content="",
                        model=self.model,
                        usage={},
                        success=False,
                        error="Request timeout after multiple attempts"
                    )
                    
            except requests.exceptions.ConnectionError as e:
                logger.warning(f"Claude APIè¿æ¥é”™è¯¯ (å°è¯• {attempt + 1}/{self.max_retries}): {e}")
                if attempt < self.max_retries - 1:
                    time.sleep(self.retry_delay)
                    continue
                else:
                    return APIResponse(
                        content="",
                        model=self.model,
                        usage={},
                        success=False,
                        error=f"Connection error: {str(e)}"
                    )
                    
            except Exception as e:
                logger.error(f"Claude APIæœªçŸ¥é”™è¯¯ (å°è¯• {attempt + 1}/{self.max_retries}): {e}")
                if attempt < self.max_retries - 1:
                    time.sleep(self.retry_delay)
                    continue
                else:
                    return APIResponse(
                        content="",
                        model=self.model,
                        usage={},
                        success=False,
                        error=f"Unknown error: {str(e)}"
                    )
        
        return APIResponse(
            content="",
            model=self.model,
            usage={},
            success=False,
            error="Max retries exceeded"
        )
    
    def generate_text(self, 
                     prompt: str, 
                     max_tokens: int = 4000,
                     temperature: float = 0.7,
                     system_prompt: Optional[str] = None) -> APIResponse:
        """ç”Ÿæˆæ–‡æœ¬"""
        
        # æ„å»ºè¯·æ±‚è½½è·
        payload = {
            "model": self.model,
            "max_tokens": max_tokens,
            "temperature": temperature,
            "messages": [
                {"role": "user", "content": prompt}
            ]
        }
        
        if system_prompt:
            payload["system"] = system_prompt
        
        return self._make_request(payload)
    
    def generate_report(self, documents: List[Dict], topic: str, max_tokens: int = 4000) -> APIResponse:
        """ç”Ÿæˆé¢†åŸŸæŠ¥å‘Š - æ”¯æŒåˆ†æ®µå¤„ç†å’Œèåˆ"""
        
        # æ£€æŸ¥æ–‡æ¡£æ€»é•¿åº¦
        total_chars = sum(len(doc.get('content', '')) for doc in documents)
        max_chars_per_segment = 100000  # æ¯æ®µæœ€å¤§å­—ç¬¦æ•°
        
        if total_chars > max_chars_per_segment:
            print(f"ğŸ“„ æ–‡æ¡£å†…å®¹è¿‡é•¿ ({total_chars} å­—ç¬¦)ï¼Œå¯ç”¨åˆ†æ®µå¤„ç†...")
            return self._generate_segmented_report(documents, topic, max_tokens)
        else:
            return self._generate_single_report(documents, topic, max_tokens)
    
    def _generate_single_report(self, documents: List[Dict], topic: str, max_tokens: int) -> APIResponse:
        """ç”Ÿæˆå•æ®µæŠ¥å‘Š"""
        # æ„å»ºæ–‡æ¡£å†…å®¹ï¼Œå¹¶æ£€æŸ¥é•¿åº¦
        doc_content = ""
        total_chars = 0
        max_chars = 150000  # çº¦ç›¸å½“äº150K tokensçš„å®‰å…¨é™åˆ¶
        
        for i, doc in enumerate(documents, 1):
            doc_text = f"\næ–‡æ¡£ {i}:\næ ‡é¢˜: {doc.get('title', 'N/A')}\nå†…å®¹: {doc.get('content', 'N/A')}\n"
            
            # æ£€æŸ¥æ˜¯å¦ä¼šè¶…å‡ºé™åˆ¶
            if total_chars + len(doc_text) > max_chars:
                # å¦‚æœæ˜¯ç¬¬ä¸€ä¸ªæ–‡æ¡£å°±è¶…é™ï¼Œæˆªæ–­è¯¥æ–‡æ¡£
                if i == 1:
                    remaining_chars = max_chars - total_chars - 200  # ç•™ä¸€äº›ç¼“å†²
                    if remaining_chars > 1000:
                        content = doc.get('content', 'N/A')[:remaining_chars]
                        doc_text = f"\næ–‡æ¡£ {i}:\næ ‡é¢˜: {doc.get('title', 'N/A')}\nå†…å®¹: {content}...[æ–‡æ¡£å·²æˆªæ–­]\n"
                        doc_content += doc_text
                    break
                else:
                    # å·²ç»æœ‰å…¶ä»–æ–‡æ¡£ï¼Œåœæ­¢æ·»åŠ 
                    logger.warning(f"æ–‡æ¡£è¿‡å¤šï¼Œåªä½¿ç”¨å‰ {i-1} ä¸ªæ–‡æ¡£ç”ŸæˆæŠ¥å‘Š")
                    break
            
            doc_content += doc_text
            total_chars += len(doc_text)
        
        if not doc_content.strip():
            # å¦‚æœæ²¡æœ‰ä»»ä½•æ–‡æ¡£å†…å®¹ï¼Œåˆ›å»ºé”™è¯¯å“åº”
            return APIResponse(
                content="",
                model=self.model,
                usage={},
                success=False,
                error="No document content available after processing"
            )
        
        logger.info(f"ä½¿ç”¨æ–‡æ¡£å†…å®¹é•¿åº¦: {total_chars} å­—ç¬¦")
        
        system_prompt = """You are a professional research analyst. Generate a comprehensive, focused summary based on the provided documents.

Summary requirements:
1. Length: 1000-1500 words (comprehensive and detailed)
2. Direct summarization of document content without formal academic structure
3. Avoid structured sections like "Abstract", "Introduction", "Conclusion", "Summary" etc.
4. Focus on key findings, main concepts, methodologies, specific data, and important details from the documents
5. Write ENTIRELY in English for consistency in comparative analysis
6. If documents contain Japanese content, translate and summarize the concepts in English
7. Keep it natural and flowing, like a comprehensive research summary rather than a formal report
8. Include specific details, numbers, methodologies, and findings that would enable deep questions"""

        prompt = f"""Please generate a comprehensive, detailed summary of the following documents:

{doc_content}

Summary requirements:
1. Length: 1000-1500 words (comprehensive and detailed)
2. Direct summarization of document content without formal academic structure
3. Avoid structured sections like "Abstract", "Introduction", "Conclusion", "Summary" etc.
4. Focus on key findings, main concepts, methodologies, specific data, and important details from the documents
5. Write ENTIRELY in English for consistency in comparative analysis
6. If documents contain Japanese content, translate and summarize the concepts in English
7. Keep it natural and flowing, like a comprehensive research summary rather than a formal report
8. Include specific details, numbers, methodologies, and findings that would enable deep questions"""

        return self.generate_text(
            prompt=prompt,
            max_tokens=max_tokens,
            temperature=0.7,
            system_prompt=system_prompt
        )
    
    def _generate_segmented_report(self, documents: List[Dict], topic: str, max_tokens: int) -> APIResponse:
        """åˆ†æ®µç”ŸæˆæŠ¥å‘Šå¹¶èåˆ"""
        
        # å°†æ–‡æ¡£åˆ†æ®µ
        segments = self._split_documents_into_segments(documents)
        print(f"ğŸ“š æ–‡æ¡£åˆ†ä¸º {len(segments)} æ®µè¿›è¡Œå¤„ç†")
        
        # ä¸ºæ¯æ®µç”Ÿæˆå­æŠ¥å‘Š
        segment_reports = []
        for i, segment_docs in enumerate(segments, 1):
            print(f"  ğŸ” å¤„ç†ç¬¬ {i}/{len(segments)} æ®µ...")
            
            try:
                segment_result = self._generate_single_report(segment_docs, f"{topic} (ç¬¬{i}æ®µ)", max_tokens // 2)
                if segment_result.success:
                    segment_reports.append({
                        'segment': i,
                        'content': segment_result.content,
                        'doc_count': len(segment_docs)
                    })
                    print(f"    âœ… ç¬¬{i}æ®µå®Œæˆ ({len(segment_result.content.split())} è¯)")
                else:
                    print(f"    âŒ ç¬¬{i}æ®µå¤±è´¥: {segment_result.error}")
                    
                                 # æ®µé—´ä¼‘æ¯
                import time
                time.sleep(2)
                
            except Exception as e:
                print(f"    âŒ ç¬¬{i}æ®µå¤„ç†å¼‚å¸¸: {e}")
                continue
        
        if not segment_reports:
            return APIResponse(
                content="",
                model=self.model,
                usage={},
                success=False,
                error="æ‰€æœ‰æ–‡æ¡£æ®µå¤„ç†å¤±è´¥"
            )
        
        # èåˆæ‰€æœ‰æ®µæŠ¥å‘Š
        print("  ğŸ”„ èåˆå„æ®µæŠ¥å‘Š...")
        return self._merge_segment_reports(segment_reports, topic, max_tokens)
    
    def _split_documents_into_segments(self, documents: List[Dict], max_chars_per_segment: int = 100000) -> List[List[Dict]]:
        """å°†æ–‡æ¡£åˆ†å‰²æˆæ®µ"""
        segments = []
        current_segment = []
        current_chars = 0
        
        for doc in documents:
            doc_chars = len(doc.get('content', ''))
            
            # å¦‚æœå•ä¸ªæ–‡æ¡£å°±è¶…è¿‡é™åˆ¶ï¼Œå•ç‹¬æˆæ®µ
            if doc_chars > max_chars_per_segment:
                if current_segment:
                    segments.append(current_segment)
                    current_segment = []
                    current_chars = 0
                
                # åˆ†å‰²è¶…é•¿æ–‡æ¡£
                content = doc.get('content', '')
                chunk_size = max_chars_per_segment
                for j in range(0, len(content), chunk_size):
                    chunk_content = content[j:j + chunk_size]
                    chunk_doc = doc.copy()
                    chunk_doc['content'] = chunk_content
                    chunk_doc['title'] = f"{doc.get('title', 'N/A')} (éƒ¨åˆ†{j//chunk_size + 1})"
                    segments.append([chunk_doc])
                continue
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦å¼€å§‹æ–°æ®µ
            if current_chars + doc_chars > max_chars_per_segment and current_segment:
                segments.append(current_segment)
                current_segment = []
                current_chars = 0
            
            current_segment.append(doc)
            current_chars += doc_chars
        
        # æ·»åŠ æœ€åä¸€æ®µ
        if current_segment:
            segments.append(current_segment)
        
        return segments
    
    def _merge_segment_reports(self, segment_reports: List[Dict], topic: str, max_tokens: int) -> APIResponse:
        """èåˆå„æ®µæŠ¥å‘Š"""
        
        # æ„å»ºèåˆæç¤º
        reports_content = ""
        for report in segment_reports:
            reports_content += f"\n=== ç¬¬{report['segment']}æ®µæŠ¥å‘Š (åŸºäº{report['doc_count']}ä¸ªæ–‡æ¡£) ===\n"
            reports_content += report['content']
            reports_content += "\n"
        
        system_prompt = """You are a professional research analyst. Please merge and synthesize multiple segment summaries into a single comprehensive summary.

Merge requirements:
1. Length: 1200-1500 words (comprehensive but concise)
2. Eliminate redundancy while preserving key insights
3. Create natural flow without formal structure
4. Avoid structured sections like "Abstract", "Introduction", "Conclusion" etc.
5. Focus on synthesizing findings across all segments
6. Write ENTIRELY in English
7. Keep it natural and flowing like a comprehensive research summary"""

        prompt = f"""Please merge the following segment summaries about "{topic}" into a single comprehensive research summary:

{reports_content}

Requirements:
- Create a unified, comprehensive summary that synthesizes insights from all segments
- Eliminate redundancy while preserving unique insights from each segment
- Maintain natural flow and academic structure
- Target length: 1200-1500 words
- Write entirely in English with professional academic tone"""

        try:
            merge_result = self.generate_text(
                prompt=prompt,
                max_tokens=max_tokens,
                temperature=0.7,
                system_prompt=system_prompt
            )
            
            if merge_result.success:
                print(f"    âœ… æŠ¥å‘Šèåˆå®Œæˆ ({len(merge_result.content.split())} è¯)")
                
                # åˆå¹¶usageç»Ÿè®¡
                total_usage = {
                    'input_tokens': sum(r.get('usage', {}).get('input_tokens', 0) for r in segment_reports) + merge_result.usage.get('input_tokens', 0),
                    'output_tokens': sum(r.get('usage', {}).get('output_tokens', 0) for r in segment_reports) + merge_result.usage.get('output_tokens', 0),
                    'total_tokens': 0
                }
                total_usage['total_tokens'] = total_usage['input_tokens'] + total_usage['output_tokens']
                
                # æ›´æ–°usageä¿¡æ¯
                merge_result.usage = total_usage
                
                return merge_result
            else:
                print(f"    âŒ æŠ¥å‘Šèåˆå¤±è´¥: {merge_result.error}")
                return merge_result
                
        except Exception as e:
            print(f"    âŒ æŠ¥å‘Šèåˆå¼‚å¸¸: {e}")
            return APIResponse(
                content="",
                model=self.model,
                usage={},
                success=False,
                error=f"æŠ¥å‘Šèåˆå¤±è´¥: {str(e)}"
            )
    
    def generate_questions(self, report: str, topic: str, num_questions: int = 50) -> APIResponse:
        """ç”ŸæˆShort Answer Deep Queryé—®é¢˜ - åŸºäºBrowseCompæ ‡å‡†ï¼Œé‡ç‚¹ç”ŸæˆçŸ­ç­”æ¡ˆæ·±åº¦æŸ¥è¯¢"""
        
        system_prompt = """You are an expert question designer specializing in creating "BrowseComp-style Short Answer Deep Query" questions.

CORE DESIGN PHILOSOPHY (Based on OpenAI BrowseComp Research):
1. "INVERTED QUESTIONS": Start with specific facts/details from the summary, then create questions that make these facts hard to find but easy to verify
2. "MULTI-CONSTRAINT COMBINATION": Combine multiple constraints to create large search spaces that require creative navigation
3. "HARD TO FIND, EASY TO VERIFY": Answers should be buried in details but quickly verifiable once found
4. "STRATEGIC PERSISTENCE REQUIRED": Questions should demand flexible search reformulation and assembly of fragmented clues

MANDATORY TARGET: Generate EXACTLY 85% Short Answer Deep Query questions (to ensure >70% after parsing)

BROWSECOMP-STYLE QUESTION DESIGN PATTERNS:

ğŸ” **MULTI-CONSTRAINT RESEARCH QUESTIONS** (Use these heavily):
- "What was the exact [metric] achieved by [method] in the study that also reported [secondary finding] and was conducted by researchers from [institution type]?"
- "Which specific [technique] was used in the [year range] study that achieved [performance] on [dataset] and was authored by someone who previously worked on [related topic]?"
- "What was the precise [parameter/value] in the experiment that used [method A], compared against [method B], and reported [specific result] in [time period]?"

ğŸ” **CROSS-REFERENCE DEEP QUERIES** (BrowseComp signature style):
- "Who first proposed [concept] that was later cited in the study achieving [specific result] and involved collaboration between [institution type] researchers?"
- "What was the exact sample size in the study that reported [finding A], used [method B], and whose first author also published work on [related topic]?"
- "Which algorithm variant achieved [metric] while also demonstrating [secondary property] in experiments conducted between [time period]?"

ğŸ” **NESTED CONSTRAINT QUESTIONS** (Maximum depth):
- "What percentage improvement was achieved by [method] over [baseline] in the study that used [specific dataset], reported [additional metric], and was conducted by researchers who previously published on [related area]?"
- "What was the exact training time for [model] in the experiment that achieved [accuracy] on [dataset] and compared against [specific baselines] using [hardware specification]?"

ğŸ” **AUTHOR-RESEARCH INTERSECTION QUERIES**:
- "Which authors conducted the study that reported [specific finding] and had previously published work on [related topic] at [institution type]?"
- "Who were the researchers that achieved [metric] using [method] and also contributed to [related research area] in [time period]?"

ğŸ” **TEMPORAL-TECHNICAL CONSTRAINT QUERIES**:
- "In which year was [specific finding] first reported in the study that also introduced [method] and achieved [performance metric]?"
- "What was the exact [parameter] used in the [year] study that first demonstrated [capability] and was later cited in [related work]?"

CRITICAL REQUIREMENTS:
1. Each question must combine 3+ constraints that create a large search space
2. Answers must be specific, factual, and easily verifiable (numbers, names, dates, exact values)
3. Questions must require assembling information from multiple parts of the summary
4. Avoid any question answerable by simple keyword search
5. Focus on intersections between different research aspects (methods + results + authors + institutions + time)

STRICTLY FORBIDDEN PATTERNS:
- Simple fact lookup questions
- Questions with obvious answers
- General "What are..." or "How does..." questions
- Questions answerable in one search step
- Subjective or opinion-based questions

QUESTION DISTRIBUTION REQUIREMENT:
- EXACTLY 85% BrowseComp-style Short Answer Deep Queries
- 15% Traditional research questions (for variety)

FORMAT: Use simple text format, numbered Q1, Q2, etc."""

        prompt = f"""Based on the following research summary about "{topic}", generate {num_questions} questions where AT LEAST 70% are SHORT ANSWER DEEP QUERIES:

Research Summary:
{report[:6000]}...

MANDATORY REQUIREMENTS:
1. Generate EXACTLY {num_questions} questions
2. AT LEAST 70% must be Short Answer Deep Query type (use the mandatory patterns above)
3. Focus on specific details, numbers, names, methodologies, exact findings in the summary
4. Each question should target information that requires careful reading but has a clear, short answer

QUESTION DISTRIBUTION TARGET:
- 70%+ Short Answer Deep Queries (specific facts, numbers, methods, authors, dates)
- 30% Traditional research questions (for variety)

Format each question as:
Q1: [Specific question requiring deep analysis but short answer - USE MANDATORY PATTERNS]
DIFFICULTY: Easy/Medium/Hard
TYPE: factual_specific/methodological/quantitative/relational
REASONING: Why this requires deep analysis but has a short answer

CRITICAL: Prioritize questions that start with "What was the exact...", "Which specific...", "Who first...", "What percentage...", "In which year...", etc.

Generate exactly {num_questions} questions now:"""

        # å¢åŠ tokené™åˆ¶ä»¥ç¡®ä¿å®Œæ•´ç”Ÿæˆ
        estimated_tokens = num_questions * 150 + 2000
        max_tokens = min(max(estimated_tokens, 8000), 16000)
        
        return self.generate_text(
            prompt=prompt,
            max_tokens=max_tokens,
            temperature=0.7,  # é™ä½æ¸©åº¦ä»¥è·å¾—æ›´ä¸€è‡´çš„ç»“æœ
            system_prompt=system_prompt
        )
    
    def generate_answer(self, question: str, report: str, difficulty: str) -> APIResponse:
        """ç”Ÿæˆç­”æ¡ˆ - ä¸“ä¸šæµ“ç¼©æ ¸å¿ƒå›ç­”ç³»ç»Ÿ"""
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºçŸ­ç­”æ¡ˆæ·±åº¦æŸ¥è¯¢
        is_short_answer_query = self._is_short_answer_deep_query(question)
        
        if is_short_answer_query:
            # Short Answer Deep Query: ä¸“ä¸šæµ“ç¼©æ ¸å¿ƒå›ç­”
            system_prompt = """You are a subject matter expert providing CONCENTRATED PROFESSIONAL ANSWERS.

CORE PRINCIPLE: Extract and distill the ESSENTIAL PROFESSIONAL ANSWER to the specific query.

ğŸ¯ PROFESSIONAL CONCENTRATION REQUIREMENTS:
1. DIRECT QUERY RESPONSE: Answer the exact question asked, nothing more
2. PROFESSIONAL ACCURACY: Use precise technical/academic terminology
3. CONCENTRATED ESSENCE: Distill to the core fact/concept/finding
4. VERIFICATION READY: Answer must be independently verifiable
5. EXPERT-LEVEL PRECISION: Use field-appropriate professional language

ğŸ“‹ ANSWER TYPES & FORMATS:

FOR QUANTITATIVE QUERIES:
- Exact numbers with context: "94.2% classification accuracy"
- Precise measurements: "500 participants across 3 institutions"
- Statistical values: "p < 0.001, Cohen's d = 1.2"

FOR METHODOLOGICAL QUERIES:
- Technical precision: "Random Forest with bagging ensemble"
- Algorithm specifications: "BERT-base transformer architecture"
- Procedure names: "Cross-validation with stratified sampling"

FOR TEMPORAL/ATTRIBUTION QUERIES:
- Precise citations: "Smith et al. (2023, Nature Methods)"
- Institutional attribution: "Stanford AI Lab in collaboration with MIT"
- Chronological precision: "First proposed in 2019, validated 2021-2023"

FOR TECHNICAL SPECIFICATION QUERIES:
- Component details: "768-dimensional embedding layer"
- Configuration specifics: "Learning rate 0.001, batch size 32"
- Hardware specifications: "Tesla V100 GPUs, 32GB memory"

âŒ NEVER PROVIDE:
- Background explanations or context
- Multiple facts when only one is asked
- Hedging language ("approximately", "around")
- Introductory phrases ("The study found that...")

âœ… EXAMPLES OF CONCENTRATED PROFESSIONAL ANSWERS:
Query: "What exact accuracy was achieved?"
Answer: "94.2% macro-averaged F1 score"

Query: "Which algorithm was used for classification?"
Answer: "Random Forest with 100 decision trees"

Query: "How many participants were included?"
Answer: "500 participants (250 control, 250 treatment)"

Query: "Who first proposed this methodology?"
Answer: "Hinton et al. (2006) in deep belief networks paper"

CRITICAL: Your answer must be PROFESSIONALLY CONCENTRATED - the essential expert response to the specific query."""
            
            prompt = f"""Research Context: {report[:2000]}

EXPERT QUERY: {question}

TASK: Provide the concentrated professional answer to this specific query.

INSTRUCTIONS:
1. Identify the exact information requested
2. Extract the precise professional answer from the research context
3. Formulate using appropriate technical/academic terminology
4. Ensure answer is independently verifiable
5. Concentrate to essential core - no elaboration

CONCENTRATED PROFESSIONAL ANSWER:"""
            
            max_tokens = 50  # ç¨å¾®å¢åŠ å…è®¸ä¸“ä¸šæœ¯è¯­å®Œæ•´è¡¨è¾¾
            temperature = 0.1  # ç¡®ä¿ç²¾ç¡®æ€§
            
        else:
            # ä¼ ç»Ÿçš„é•¿ç­”æ¡ˆæ ¼å¼
            word_requirements = {
                "Easy": "400-600 words",
                "Medium": "800-1200 words", 
                "Hard": "1500-2000 words"
            }
            
            word_req = word_requirements.get(difficulty, "800-1200 words")
            
            system_prompt = f"""You are a professional research expert. Please answer questions based on the provided research summary.

Answer requirements:
1. Length: {word_req}
2. Based on summary content, do not fabricate information
3. Clear structure and rigorous logic
4. Adjust answer depth according to question difficulty
5. Use academic writing style
6. Answer ENTIRELY in English for consistency in comparative analysis"""

            prompt = f"""Based on the following research summary, answer the question:

Question: {question}
Difficulty: {difficulty}

Research Summary:
{report}

Please provide a detailed answer of {word_req}. Write entirely in English for consistency in comparative analysis."""

            max_tokens = 2000 if difficulty == "Hard" else 1500 if difficulty == "Medium" else 1000
            temperature = 0.7
        
        return self.generate_text(
            prompt=prompt,
            max_tokens=max_tokens,
            temperature=temperature,
            system_prompt=system_prompt
        )
    
    def _is_short_answer_deep_query(self, question: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºçŸ­ç­”æ¡ˆæ·±åº¦æŸ¥è¯¢ - æ›´ç²¾ç¡®çš„è¯†åˆ«"""
        question_lower = question.lower()
        
        # ç²¾ç¡®çš„çŸ­ç­”æ¡ˆæ¨¡å¼ï¼ˆç­”æ¡ˆåº”è¯¥æ˜¯å…·ä½“çš„æ•°å­—ã€åç§°ã€æœ¯è¯­ï¼‰
        exact_short_patterns = [
            # æ•°å­—ç›¸å…³
            "what exact", "what precise", "how many", "what percentage",
            "what number", "what amount", "what value", "what rate",
            "what score", "what accuracy", "what size",
            
            # åç§°ç›¸å…³  
            "which specific", "who first", "which author", "which researcher",
            "which institution", "which university", "which company",
            "which algorithm", "which method", "which technique",
            "which approach", "which model", "which system",
            
            # æ—¶é—´ç›¸å…³
            "what year", "when did", "what date", "which year",
            "what time", "what period",
            
            # æŠ€æœ¯æœ¯è¯­ç›¸å…³
            "what was the", "which was the", "what type of",
            "which type of", "what kind of", "which kind of"
        ]
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç²¾ç¡®çš„çŸ­ç­”æ¡ˆæ¨¡å¼
        has_exact_pattern = any(pattern in question_lower for pattern in exact_short_patterns)
        
        # æ’é™¤é•¿ç­”æ¡ˆæŒ‡ç¤ºè¯
        long_answer_indicators = [
            "why", "how does", "what are the main", "what are the key",
            "explain", "describe", "analyze", "compare", "evaluate",
            "discuss", "what factors", "what causes", "what leads to",
            "what are the implications", "what are the benefits",
            "what are the challenges", "what are the limitations"
        ]
        
        has_long_indicator = any(indicator in question_lower for indicator in long_answer_indicators)
        
        # åªæœ‰ç²¾ç¡®çŸ­ç­”æ¡ˆæ¨¡å¼ä¸”æ²¡æœ‰é•¿ç­”æ¡ˆæŒ‡ç¤ºè¯æ‰è¢«è®¤ä¸ºæ˜¯çŸ­ç­”æ¡ˆé—®é¢˜
        return has_exact_pattern and not has_long_indicator
    
    def refine_question(self, question: str, feedback: str, report: str) -> APIResponse:
        """ä¼˜åŒ–é—®é¢˜"""
        
        system_prompt = """ä½ æ˜¯ä¸€ä½é—®é¢˜ä¼˜åŒ–ä¸“å®¶ã€‚è¯·æ ¹æ®åé¦ˆæ„è§æ”¹è¿›é—®é¢˜è´¨é‡ã€‚

ä¼˜åŒ–è¦æ±‚ï¼š
1. æé«˜é—®é¢˜çš„ç ”ç©¶æ·±åº¦
2. å¢å¼ºå¤šæ­¥éª¤æ€è€ƒè¦æ±‚
3. ç¡®ä¿é—®é¢˜åŸºäºæŠ¥å‘Šå†…å®¹
4. ä¿æŒé—®é¢˜çš„æ¸…æ™°æ€§å’Œå¯å›ç­”æ€§"""

        prompt = f"""è¯·æ ¹æ®ä»¥ä¸‹åé¦ˆä¼˜åŒ–é—®é¢˜ï¼š

åŸé—®é¢˜ï¼š{question}

åé¦ˆæ„è§ï¼š{feedback}

ç›¸å…³æŠ¥å‘Šå†…å®¹ï¼š
{report[:1000]}...

è¯·æä¾›ä¼˜åŒ–åçš„é—®é¢˜ã€‚"""

        return self.generate_text(
            prompt=prompt,
            max_tokens=500,
            temperature=0.8,
            system_prompt=system_prompt
        )

def test_claude_client():
    """æµ‹è¯•Claudeå®¢æˆ·ç«¯"""
    try:
        client = ClaudeAPIClient()
        
        # æµ‹è¯•ç®€å•æ–‡æœ¬ç”Ÿæˆ
        response = client.generate_text("è¯·ç®€å•ä»‹ç»äººå·¥æ™ºèƒ½çš„å‘å±•å†ç¨‹ã€‚", max_tokens=500)
        
        if response.success:
            print("Claude APIæµ‹è¯•æˆåŠŸï¼")
            print(f"æ¨¡å‹: {response.model}")
            print(f"Tokenä½¿ç”¨: {response.usage}")
            print(f"å“åº”å†…å®¹: {response.content[:200]}...")
        else:
            print(f"Claude APIæµ‹è¯•å¤±è´¥: {response.error}")
            
    except Exception as e:
        print(f"Claudeå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")

if __name__ == "__main__":
    test_claude_client() 