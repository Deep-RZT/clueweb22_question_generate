"""
Answer Compression Optimizer for Short Answer Deep Query System
ä¸“é—¨å¤„ç†è¶…é•¿ç­”æ¡ˆçš„æ™ºèƒ½å‹ç¼©ä¼˜åŒ–å™¨
"""

import json
import logging
import time
import sys
import os
from typing import List, Dict, Any, Optional, Tuple

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '../..')))
from core.llm_clients.llm_manager import llm_manager

logger = logging.getLogger(__name__)

class AnswerCompressionOptimizer:
    """ç­”æ¡ˆå‹ç¼©ä¼˜åŒ–å™¨ - å¤„ç†è¶…é•¿ç­”æ¡ˆçš„äºŒæ¬¡å‹ç¼©"""
    
    def __init__(self, llm_manager_instance=None):
        # ä½¿ç”¨ä¼ å…¥çš„llm_managerå®ä¾‹ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨å…¨å±€å®ä¾‹
        if llm_manager_instance:
            self.llm_manager = llm_manager_instance
        else:
            self.llm_manager = llm_manager
        self.compression_stats = {
            'processed_count': 0,
            'successful_compressions': 0,
            'failed_compressions': 0,
            'average_compression_ratio': 0.0,
            'quality_improvements': 0
        }
    
    def optimize_qa_pairs(self, qa_pairs: List[Dict[str, Any]], 
                         max_word_limit: int = 15,
                         max_char_limit: int = 100) -> Tuple[List[Dict[str, Any]], Dict[str, Any]]:
        """
        ä¼˜åŒ–QAå¯¹ï¼Œå¯¹è¶…é•¿ç­”æ¡ˆè¿›è¡Œæ™ºèƒ½å‹ç¼©
        
        Args:
            qa_pairs: åŸå§‹QAå¯¹åˆ—è¡¨
            max_word_limit: æœ€å¤§è¯æ•°é™åˆ¶
            max_char_limit: æœ€å¤§å­—ç¬¦é™åˆ¶
        
        Returns:
            (ä¼˜åŒ–åçš„QAå¯¹åˆ—è¡¨, ä¼˜åŒ–ç»Ÿè®¡ä¿¡æ¯)
        """
        logger.info(f"ğŸ”§ å¼€å§‹ç­”æ¡ˆå‹ç¼©ä¼˜åŒ–: {len(qa_pairs)} ä¸ªQAå¯¹")
        
        optimized_pairs = []
        optimization_log = []
        
        for i, qa_pair in enumerate(qa_pairs):
            try:
                original_answer = qa_pair.get('answer', '')
                original_word_count = len(original_answer.split())
                original_char_count = len(original_answer)
                
                # åˆ¤æ–­æ˜¯å¦éœ€è¦å‹ç¼©
                needs_compression = (
                    original_word_count > max_word_limit or 
                    original_char_count > max_char_limit
                )
                
                if needs_compression:
                    logger.info(f"  ğŸ¯ å‹ç¼©ç¬¬{i+1}ä¸ªç­”æ¡ˆ (åŸ: {original_word_count}è¯/{original_char_count}å­—ç¬¦)")
                    
                    # æ‰§è¡Œæ™ºèƒ½å‹ç¼©
                    compressed_result = self._compress_answer(
                        qa_pair['question'], 
                        original_answer,
                        max_word_limit,
                        max_char_limit
                    )
                    
                    if compressed_result['success']:
                        # æ›´æ–°QAå¯¹
                        optimized_qa = qa_pair.copy()
                        optimized_qa['answer'] = compressed_result['compressed_answer']
                        optimized_qa['answer_word_count'] = compressed_result['word_count']
                        optimized_qa['answer_length'] = compressed_result['char_count']
                        optimized_qa['compression_applied'] = True
                        optimized_qa['original_answer'] = original_answer
                        optimized_qa['compression_ratio'] = compressed_result['compression_ratio']
                        
                        optimized_pairs.append(optimized_qa)
                        self.compression_stats['successful_compressions'] += 1
                        
                        logger.info(f"    âœ… å‹ç¼©æˆåŠŸ: {compressed_result['word_count']}è¯/{compressed_result['char_count']}å­—ç¬¦ "
                                  f"(å‹ç¼©ç‡: {compressed_result['compression_ratio']:.1%})")
                        
                        optimization_log.append({
                            'qa_id': qa_pair.get('question_id', f'q_{i+1}'),
                            'action': 'compressed',
                            'original_words': original_word_count,
                            'compressed_words': compressed_result['word_count'],
                            'compression_ratio': compressed_result['compression_ratio'],
                            'quality_preserved': compressed_result.get('quality_preserved', True)
                        })
                        
                    else:
                        # å‹ç¼©å¤±è´¥ï¼Œä¿ç•™åŸç­”æ¡ˆä½†æ ‡è®°
                        optimized_qa = qa_pair.copy()
                        optimized_qa['compression_failed'] = True
                        optimized_qa['compression_error'] = compressed_result.get('error', 'Unknown error')
                        optimized_pairs.append(optimized_qa)
                        self.compression_stats['failed_compressions'] += 1
                        
                        logger.warning(f"    âŒ å‹ç¼©å¤±è´¥: {compressed_result.get('error', 'Unknown error')}")
                        
                        optimization_log.append({
                            'qa_id': qa_pair.get('question_id', f'q_{i+1}'),
                            'action': 'compression_failed',
                            'error': compressed_result.get('error', 'Unknown error')
                        })
                else:
                    # æ— éœ€å‹ç¼©
                    optimized_pairs.append(qa_pair)
                    optimization_log.append({
                        'qa_id': qa_pair.get('question_id', f'q_{i+1}'),
                        'action': 'no_compression_needed',
                        'word_count': original_word_count
                    })
                
                self.compression_stats['processed_count'] += 1
                
            except Exception as e:
                logger.error(f"å¤„ç†QAå¯¹{i+1}æ—¶å‡ºé”™: {e}")
                optimized_pairs.append(qa_pair)  # ä¿ç•™åŸå§‹æ•°æ®
                optimization_log.append({
                    'qa_id': qa_pair.get('question_id', f'q_{i+1}'),
                    'action': 'error',
                    'error': str(e)
                })
        
        # è®¡ç®—æ•´ä½“ç»Ÿè®¡
        total_compressions = self.compression_stats['successful_compressions']
        if total_compressions > 0:
            compression_ratios = [log['compression_ratio'] for log in optimization_log 
                                if log['action'] == 'compressed']
            self.compression_stats['average_compression_ratio'] = sum(compression_ratios) / len(compression_ratios)
        
        optimization_summary = {
            'total_processed': self.compression_stats['processed_count'],
            'successful_compressions': self.compression_stats['successful_compressions'],
            'failed_compressions': self.compression_stats['failed_compressions'],
            'average_compression_ratio': self.compression_stats['average_compression_ratio'],
            'optimization_log': optimization_log
        }
        
        logger.info(f"ğŸ¯ ç­”æ¡ˆå‹ç¼©ä¼˜åŒ–å®Œæˆ: {self.compression_stats['successful_compressions']}/{len(qa_pairs)} æˆåŠŸå‹ç¼©")
        
        return optimized_pairs, optimization_summary
    
    def _compress_answer(self, question: str, original_answer: str, 
                        max_words: int, max_chars: int) -> Dict[str, Any]:
        """
        æ‰§è¡Œå•ä¸ªç­”æ¡ˆçš„æ™ºèƒ½å‹ç¼©
        
        Args:
            question: é—®é¢˜æ–‡æœ¬
            original_answer: åŸå§‹ç­”æ¡ˆ
            max_words: æœ€å¤§è¯æ•°
            max_chars: æœ€å¤§å­—ç¬¦æ•°
        
        Returns:
            å‹ç¼©ç»“æœå­—å…¸
        """
        try:
            # æ„å»ºä¸“ä¸šçš„å‹ç¼©æç¤ºè¯
            system_prompt = """You are an expert answer compression specialist for academic BrowseComp-style questions.

CORE MISSION: Compress verbose answers to ESSENTIAL CORE FACTS while maintaining 100% factual accuracy.

ğŸ¯ COMPRESSION PRINCIPLES:
1. PRESERVE CORE FACT: Keep the essential answer unchanged
2. ELIMINATE REDUNDANCY: Remove all explanatory text, background, context
3. MAINTAIN PRECISION: Keep technical terms, numbers, names exact
4. ENSURE VERIFIABILITY: Answer must remain independently verifiable
5. ACADEMIC BREVITY: Use standard academic/technical abbreviations

ğŸ“‹ COMPRESSION TECHNIQUES:

FOR QUANTITATIVE ANSWERS:
- Keep exact numbers: "94.2% accuracy" â†’ "94.2%"
- Preserve units: "500 participants" â†’ "500"
- Maintain precision: "p < 0.001" â†’ "p < 0.001"

FOR NAME/ATTRIBUTION ANSWERS:
- Essential names only: "Smith et al. (2023)" â†’ "Smith et al."
- Institution abbreviations: "Stanford University" â†’ "Stanford"
- Year when crucial: "proposed in 2019" â†’ "2019" (if year is the answer)

FOR TECHNICAL TERMS:
- Standard abbreviations: "Convolutional Neural Network" â†’ "CNN"
- Algorithm names: "Random Forest classifier" â†’ "Random Forest"
- Keep critical modifiers: "pre-trained BERT model" â†’ "pre-trained BERT"

âŒ NEVER COMPRESS:
- Core factual content (the actual answer)
- Technical precision (exact numbers, statistical values)
- Essential qualifiers (if part of the answer)
- Proper nouns when they ARE the answer

âœ… ALWAYS REMOVE:
- Explanatory phrases ("The study found that...")
- Background context ("In the context of...")
- Hedging language ("approximately", "around")
- Redundant descriptors
- Introductory text"""

            prompt = f"""COMPRESSION TASK:

Original Question: {question}

Original Answer (needs compression): {original_answer}

REQUIREMENTS:
- Maximum {max_words} words
- Maximum {max_chars} characters
- Preserve 100% factual accuracy
- Maintain technical precision
- Keep answer independently verifiable

COMPRESSION INSTRUCTIONS:
1. Identify the CORE FACT being asked for in the question
2. Extract ONLY that essential information from the original answer
3. Use technical abbreviations where appropriate
4. Eliminate ALL explanatory or contextual text
5. Ensure the compressed answer directly answers the question

COMPRESSED ANSWER (max {max_words} words, {max_chars} chars):"""

            # ä½¿ç”¨æ›´ä¸¥æ ¼çš„å‚æ•° - ä½¿ç”¨å®ä¾‹çš„llm_manager
            response = self.llm_manager.generate_text(
                prompt=prompt,
                max_tokens=100,  # ä¸¥æ ¼é™åˆ¶
                temperature=0.1,  # ç¡®ä¿ä¸€è‡´æ€§
                system_prompt=system_prompt,
                provider="openai"  # æ˜ç¡®æŒ‡å®šOpenAIæä¾›å•†
            )
            
            if response.success and response.content:
                compressed_answer = response.content.strip()
                
                # éªŒè¯å‹ç¼©ç»“æœ
                word_count = len(compressed_answer.split())
                char_count = len(compressed_answer)
                
                # è®¡ç®—å‹ç¼©ç‡
                original_words = len(original_answer.split())
                compression_ratio = 1 - (word_count / max(original_words, 1))
                
                # è´¨é‡æ£€æŸ¥
                quality_preserved = self._validate_compression_quality(
                    question, original_answer, compressed_answer
                )
                
                if word_count <= max_words and char_count <= max_chars:
                    return {
                        'success': True,
                        'compressed_answer': compressed_answer,
                        'word_count': word_count,
                        'char_count': char_count,
                        'compression_ratio': compression_ratio,
                        'quality_preserved': quality_preserved
                    }
                else:
                    # å°è¯•è¿›ä¸€æ­¥å‹ç¼©
                    if word_count > max_words:
                        # æ¿€è¿›å‹ç¼©ç­–ç•¥
                        aggressive_result = self._aggressive_compression(
                            compressed_answer, max_words, max_chars
                        )
                        if aggressive_result['success']:
                            aggressive_result['compression_ratio'] = compression_ratio
                            return aggressive_result
                    
                    return {
                        'success': False,
                        'error': f'å‹ç¼©åä»è¶…é™: {word_count}è¯/{char_count}å­—ç¬¦ > {max_words}è¯/{max_chars}å­—ç¬¦',
                        'compressed_answer': compressed_answer,
                        'word_count': word_count,
                        'char_count': char_count
                    }
            else:
                return {
                    'success': False,
                    'error': f'LLMå‹ç¼©å¤±è´¥: {response.error}' if hasattr(response, 'error') else 'LLMå“åº”å¤±è´¥'
                }
        
        except Exception as e:
            return {
                'success': False,
                'error': f'å‹ç¼©å¤„ç†å¼‚å¸¸: {str(e)}'
            }
    
    def _aggressive_compression(self, text: str, max_words: int, max_chars: int) -> Dict[str, Any]:
        """æ¿€è¿›å‹ç¼©ç­–ç•¥ - é’ˆå¯¹ä»ç„¶è¶…é•¿çš„æ–‡æœ¬"""
        try:
            words = text.split()
            
            # ç­–ç•¥1: ä¿ç•™æœ€æ ¸å¿ƒçš„è¯æ±‡
            if len(words) > max_words:
                # ä¿ç•™å‰å‡ ä¸ªæœ€é‡è¦çš„è¯
                core_words = words[:max_words]
                compressed = ' '.join(core_words)
                
                # æ£€æŸ¥å­—ç¬¦é™åˆ¶
                if len(compressed) <= max_chars:
                    return {
                        'success': True,
                        'compressed_answer': compressed,
                        'word_count': len(core_words),
                        'char_count': len(compressed),
                        'method': 'aggressive_truncation'
                    }
            
            # ç­–ç•¥2: å­—ç¬¦çº§æˆªæ–­
            if len(text) > max_chars:
                # æˆªæ–­åˆ°å­—ç¬¦é™åˆ¶ï¼Œç¡®ä¿ä¸åœ¨å•è¯ä¸­é—´
                truncated = text[:max_chars]
                last_space = truncated.rfind(' ')
                if last_space > max_chars * 0.8:  # å¦‚æœç©ºæ ¼ä½ç½®åˆç†
                    truncated = truncated[:last_space]
                
                word_count = len(truncated.split())
                if word_count <= max_words:
                    return {
                        'success': True,
                        'compressed_answer': truncated,
                        'word_count': word_count,
                        'char_count': len(truncated),
                        'method': 'character_truncation'
                    }
            
            return {
                'success': False,
                'error': 'æ¿€è¿›å‹ç¼©ç­–ç•¥ä¹Ÿæ— æ³•æ»¡è¶³é™åˆ¶'
            }
        
        except Exception as e:
            return {
                'success': False,
                'error': f'æ¿€è¿›å‹ç¼©å¼‚å¸¸: {str(e)}'
            }
    
    def _validate_compression_quality(self, question: str, original: str, compressed: str) -> bool:
        """éªŒè¯å‹ç¼©è´¨é‡ - ç¡®ä¿æ ¸å¿ƒä¿¡æ¯ä¿ç•™"""
        try:
            # åŸºæœ¬æ£€æŸ¥ï¼šå‹ç¼©ç­”æ¡ˆä¸èƒ½ä¸ºç©º
            if not compressed or len(compressed.strip()) == 0:
                return False
            
            # æ£€æŸ¥å…³é”®ä¿¡æ¯ä¿ç•™
            # 1. æ•°å­—ä¿¡æ¯
            import re
            original_numbers = re.findall(r'\d+\.?\d*', original)
            compressed_numbers = re.findall(r'\d+\.?\d*', compressed)
            
            # å¦‚æœåŸç­”æ¡ˆæœ‰æ•°å­—ï¼Œå‹ç¼©ç­”æ¡ˆåº”è¯¥ä¿ç•™ä¸»è¦æ•°å­—
            if original_numbers and not compressed_numbers:
                return False
            
            # 2. ä¸“æœ‰åè¯ï¼ˆå¤§å†™å¼€å¤´çš„è¯ï¼‰
            original_proper_nouns = re.findall(r'\b[A-Z][a-z]+\b', original)
            compressed_proper_nouns = re.findall(r'\b[A-Z][a-z]+\b', compressed)
            
            # å¦‚æœåŸç­”æ¡ˆæœ‰ä¸“æœ‰åè¯ï¼Œå‹ç¼©ç­”æ¡ˆåº”è¯¥ä¿ç•™
            if len(original_proper_nouns) > 0 and len(compressed_proper_nouns) == 0:
                return False
            
            # 3. æŠ€æœ¯æœ¯è¯­ä¿ç•™æ£€æŸ¥
            technical_terms = ['accuracy', 'precision', 'recall', 'f1', 'score', 'rate', 'ratio', '%']
            original_has_tech = any(term in original.lower() for term in technical_terms)
            compressed_has_tech = any(term in compressed.lower() for term in technical_terms)
            
            if original_has_tech and not compressed_has_tech:
                # å¯èƒ½æ˜¯æŠ€æœ¯ç­”æ¡ˆï¼Œéœ€è¦ä¿ç•™æŠ€æœ¯ä¿¡æ¯
                return len(compressed_numbers) > 0  # è‡³å°‘ä¿ç•™æ•°å­—
            
            return True
        
        except Exception as e:
            logger.warning(f"è´¨é‡éªŒè¯å¼‚å¸¸: {e}")
            return True  # é»˜è®¤è®¤ä¸ºè´¨é‡å¯æ¥å—
    
    def get_compression_statistics(self) -> Dict[str, Any]:
        """è·å–å‹ç¼©ç»Ÿè®¡ä¿¡æ¯"""
        return self.compression_stats.copy()
    
    def reset_statistics(self):
        """é‡ç½®ç»Ÿè®¡ä¿¡æ¯"""
        self.compression_stats = {
            'processed_count': 0,
            'successful_compressions': 0,
            'failed_compressions': 0,
            'average_compression_ratio': 0.0,
            'quality_improvements': 0
        }


class EnhancedAnswerValidator:
    """å¢å¼ºçš„ç­”æ¡ˆéªŒè¯å™¨ - æ›´æ™ºèƒ½çš„ç­”æ¡ˆè´¨é‡è¯„ä¼°"""
    
    def __init__(self):
        self.validation_criteria = {
            'max_word_count': 15,
            'max_char_count': 100,
            'min_information_density': 0.5,  # ä¿¡æ¯å¯†åº¦æœ€å°è¦æ±‚
            'required_precision': True  # æ˜¯å¦éœ€è¦ç²¾ç¡®æ€§
        }
    
    def validate_answer_quality(self, question: str, answer: str) -> Dict[str, Any]:
        """
        å…¨é¢éªŒè¯ç­”æ¡ˆè´¨é‡
        
        Returns:
            éªŒè¯ç»“æœå­—å…¸ï¼ŒåŒ…å«é€šè¿‡çŠ¶æ€å’Œè¯¦ç»†åˆ†æ
        """
        validation_result = {
            'passed': True,
            'issues': [],
            'metrics': {},
            'suggestions': []
        }
        
        # åŸºæœ¬é•¿åº¦æ£€æŸ¥
        word_count = len(answer.split())
        char_count = len(answer)
        
        validation_result['metrics']['word_count'] = word_count
        validation_result['metrics']['char_count'] = char_count
        
        # é•¿åº¦éªŒè¯
        if word_count > self.validation_criteria['max_word_count']:
            validation_result['passed'] = False
            validation_result['issues'].append(f"ç­”æ¡ˆè¯æ•°è¶…é™: {word_count} > {self.validation_criteria['max_word_count']}")
            validation_result['suggestions'].append("è€ƒè™‘ä½¿ç”¨ç­”æ¡ˆå‹ç¼©ä¼˜åŒ–")
        
        if char_count > self.validation_criteria['max_char_count']:
            validation_result['passed'] = False
            validation_result['issues'].append(f"ç­”æ¡ˆå­—ç¬¦æ•°è¶…é™: {char_count} > {self.validation_criteria['max_char_count']}")
        
        # ä¿¡æ¯å¯†åº¦æ£€æŸ¥
        info_density = self._calculate_information_density(answer)
        validation_result['metrics']['information_density'] = info_density
        
        if info_density < self.validation_criteria['min_information_density']:
            validation_result['issues'].append(f"ä¿¡æ¯å¯†åº¦è¿‡ä½: {info_density:.2f}")
            validation_result['suggestions'].append("å¢åŠ æ ¸å¿ƒä¿¡æ¯ï¼Œå‡å°‘å†—ä½™è¡¨è¾¾")
        
        # ç²¾ç¡®æ€§æ£€æŸ¥
        precision_score = self._evaluate_precision(question, answer)
        validation_result['metrics']['precision_score'] = precision_score
        
        if precision_score < 0.7:
            validation_result['issues'].append(f"ç­”æ¡ˆç²¾ç¡®æ€§ä¸è¶³: {precision_score:.2f}")
        
        return validation_result
    
    def _calculate_information_density(self, text: str) -> float:
        """è®¡ç®—æ–‡æœ¬çš„ä¿¡æ¯å¯†åº¦"""
        import re
        
        # ä¿¡æ¯æ€§è¯æ±‡: æ•°å­—ã€ä¸“æœ‰åè¯ã€æŠ€æœ¯æœ¯è¯­
        information_patterns = [
            r'\d+\.?\d*',  # æ•°å­—
            r'\b[A-Z][a-z]+\b',  # ä¸“æœ‰åè¯
            r'\b\w+(?:ing|ed|er|est|ly)\b',  # æ´¾ç”Ÿè¯
            r'%|percent|ratio|rate|score',  # åº¦é‡è¯
        ]
        
        total_words = len(text.split())
        information_words = 0
        
        for pattern in information_patterns:
            matches = re.findall(pattern, text)
            information_words += len(matches)
        
        return min(information_words / max(total_words, 1), 1.0)
    
    def _evaluate_precision(self, question: str, answer: str) -> float:
        """è¯„ä¼°ç­”æ¡ˆçš„ç²¾ç¡®æ€§"""
        # ç®€åŒ–çš„ç²¾ç¡®æ€§è¯„ä¼°
        question_lower = question.lower()
        answer_lower = answer.lower()
        
        precision_indicators = [
            'exact', 'precise', 'specific', 'how many', 'what percentage',
            'which', 'who', 'when', 'where'
        ]
        
        # å¦‚æœé—®é¢˜è¦æ±‚ç²¾ç¡®ç­”æ¡ˆ
        requires_precision = any(indicator in question_lower for indicator in precision_indicators)
        
        if requires_precision:
            # æ£€æŸ¥ç­”æ¡ˆæ˜¯å¦åŒ…å«å…·ä½“ä¿¡æ¯
            import re
            has_numbers = bool(re.search(r'\d+', answer))
            has_names = bool(re.search(r'\b[A-Z][a-z]+\b', answer))
            has_specific_terms = len(answer.split()) <= 5  # ç®€æ´é€šå¸¸æ„å‘³ç€ç²¾ç¡®
            
            precision_score = sum([has_numbers, has_names, has_specific_terms]) / 3.0
            return precision_score
        else:
            return 0.8  # éç²¾ç¡®æ€§é—®é¢˜çš„é»˜è®¤åˆ†æ•°


def test_answer_compression():
    """æµ‹è¯•ç­”æ¡ˆå‹ç¼©åŠŸèƒ½"""
    print("=== ç­”æ¡ˆå‹ç¼©ä¼˜åŒ–å™¨æµ‹è¯• ===")
    
    # æµ‹è¯•æ•°æ®
    test_qa_pairs = [
        {
            'question_id': 'test_1',
            'question': 'What was the exact accuracy achieved by the model?',
            'answer': 'The model achieved an accuracy of 94.2% which was significantly higher than the baseline performance of 87.3% that was established in previous studies. This represents a substantial improvement in the classification task.',
            'type': 'quantitative'
        },
        {
            'question_id': 'test_2',
            'question': 'Who first proposed this methodology?',
            'answer': 'This methodology was first proposed by Smith and Brown in their groundbreaking 2022 paper published in Nature Machine Intelligence, which has since become the standard approach in the field.',
            'type': 'attribution'
        }
    ]
    
    # åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = AnswerCompressionOptimizer()
    
    # æ‰§è¡Œä¼˜åŒ–
    optimized_pairs, summary = optimizer.optimize_qa_pairs(test_qa_pairs, max_word_limit=10, max_char_limit=50)
    
    print(f"ä¼˜åŒ–ç»“æœ:")
    for pair in optimized_pairs:
        print(f"é—®é¢˜: {pair['question']}")
        print(f"åŸç­”æ¡ˆ: {pair.get('original_answer', pair['answer'])}")
        print(f"ä¼˜åŒ–ç­”æ¡ˆ: {pair['answer']}")
        print(f"è¯æ•°: {pair.get('answer_word_count', len(pair['answer'].split()))}")
        print(f"å‹ç¼©: {'æ˜¯' if pair.get('compression_applied') else 'å¦'}")
        print("-" * 50)
    
    print(f"ä¼˜åŒ–ç»Ÿè®¡: {summary}")

if __name__ == "__main__":
    test_answer_compression() 