#!/usr/bin/env python3
"""
Complete Optimized Main Framework for Tree Extension Deep Query (Experiment 07)
å®Œæ•´ä¼˜åŒ–çš„07å®éªŒä¸»æµç¨‹

æ•´åˆæ‰€æœ‰æ–°å¢åŠŸèƒ½ï¼š
1. å¾ªç¯æé—®æ£€æµ‹ç³»ç»Ÿ
2. Tree Level Queryæ•´åˆ
3. éªŒè¯ä¼˜åŒ–ï¼ˆåŒæ¨¡å‹+å®¹é”™ï¼‰
4. è¯­è¨€å­¦æ·±åº¦æŸ¥è¯¢æ¡†æ¶
5. è½¨è¿¹æ•°æ®ä¿®å¤
6. Excelå¯¼å‡ºä¼˜åŒ–

ä¸“æ³¨äºè¯­è¨€å­¦æ·±åº¦æŸ¥è¯¢æ¨¡å¼ï¼š
- åŸºäºå…³é”®è¯æ›¿æ¢çš„5å±‚çº§æ·±åº¦æŸ¥è¯¢
- ä¸¥æ ¼æŒ‰ç…§æ•°å­¦å…¬å¼Q^(t+1) = Q^t[K_i^t â†’ D(K_i^t)]æ‰§è¡Œ
- åŒ…å«Tree Level Queryæœ€ç»ˆæ•´åˆ
"""

import logging
import sys
import os
import time
import json
from pathlib import Path
from typing import Dict, List, Optional, Any

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

# å¯¼å…¥æ ¸å¿ƒç»„ä»¶
from config import get_config
from core.llm_clients.openai_api_client import OpenAIClient
from document_loader import DocumentLoader
from document_screener import DocumentScreener
from short_answer_locator import ShortAnswerLocator
from export_system import ExportSystem

# å¯¼å…¥æ ¸å¿ƒç»„ä»¶ - ä¸“æ³¨è¯­è¨€å­¦æ¨¡å¼
from linguistic_deep_query_framework import LinguisticDeepQueryFramework
from document_loader import DocumentLoader
from web_search import web_search

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('complete_optimized_experiment.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class LinguisticMainFramework:
    """è¯­è¨€å­¦ä¸»æ¡†æ¶ - ä¸“æ³¨äºç§‘å­¦åŒ–çš„å…³é”®è¯æ›¿æ¢æ·±åº¦æŸ¥è¯¢"""
    
    def __init__(self):
        self.config = get_config()
        self.api_client = None
        self.search_client = web_search
        
        # æ ¸å¿ƒç»„ä»¶
        self.document_loader = DocumentLoader()
        self.document_screener = DocumentScreener()
        self.short_answer_locator = ShortAnswerLocator()
        self.export_system = ExportSystem()
        
        # è¯­è¨€å­¦æ ¸å¿ƒç»„ä»¶
        self.linguistic_framework = None
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.experiment_stats = {
            'session_start_time': time.time(),
            'documents_processed': 0,
            'successful_documents': 0,
            'failed_documents': 0,
            'total_questions_generated': 0,
            'series_extensions': 0,
            'parallel_extensions': 0,
            'tree_level_queries_generated': 0,
            'keyword_replacements_total': 0,
            'validation_pass_rate': 0.0
        }
    
    def initialize_framework(self, api_key: str) -> bool:
        """åˆå§‹åŒ–æ¡†æ¶ç»„ä»¶"""
        try:
            logger.info("åˆå§‹åŒ–å®Œæ•´ä¼˜åŒ–æ¡†æ¶...")
            
            # åˆå§‹åŒ–APIå®¢æˆ·ç«¯
            self.api_client = OpenAIClient(api_key=api_key)
            
            # è®¾ç½®APIå®¢æˆ·ç«¯åˆ°å„ç»„ä»¶
            self.document_screener.set_api_client(self.api_client)
            self.short_answer_locator.set_api_client(self.api_client)
            
            # åˆå§‹åŒ–è¯­è¨€å­¦æ¡†æ¶
            self.linguistic_framework = LinguisticDeepQueryFramework(
                api_client=self.api_client,
                search_client=self.search_client
            )
            
            logger.info("âœ… æ¡†æ¶åˆå§‹åŒ–å®Œæˆ")
            logger.info("è¿è¡Œæ¨¡å¼:")
            logger.info("  - è¯­è¨€å­¦æ·±åº¦æŸ¥è¯¢: åŸºäºå…³é”®è¯æ›¿æ¢çš„5å±‚çº§æ·±åº¦æŸ¥è¯¢")
            logger.info("  - æ•°å­¦å…¬å¼åŒ–æµç¨‹: Q^(t+1) = Q^t[K_i^t â†’ D(K_i^t)]")
            logger.info("  - Tree Level Queryæ•´åˆ: ç”Ÿæˆæœ€ç»ˆæ·±åº¦æ•´åˆé—®é¢˜")
            
            return True
            
        except Exception as e:
            logger.error(f"æ¡†æ¶åˆå§‹åŒ–å¤±è´¥: {e}")
            return False
    
    def run_linguistic_experiment(self, topic: str, max_documents: int = 50) -> Dict[str, Any]:
        """
        è¿è¡Œè¯­è¨€å­¦æ·±åº¦æŸ¥è¯¢å®éªŒ
        
        Args:
            topic: ä¸»é¢˜åç§°
            max_documents: æœ€å¤§å¤„ç†æ–‡æ¡£æ•°
        """
        logger.info(f"ğŸš€ å¯åŠ¨è¯­è¨€å­¦æ·±åº¦æŸ¥è¯¢å®éªŒ: {topic}")
        logger.info(f"æœ€å¤§æ–‡æ¡£æ•°: {max_documents}")
        
        session_id = f"linguistic_deep_{topic}_{int(time.time())}"
        start_time = time.time()
        
        try:
            # 1. åŠ è½½æ–‡æ¡£
            logger.info("ğŸ“„ åŠ è½½æ–‡æ¡£...")
            document_data_list = self.document_loader.load_documents_from_topic(topic, max_documents)
            
            if not document_data_list:
                return self._create_error_result(session_id, "No documents loaded")
            
            # è½¬æ¢DocumentDataå¯¹è±¡ä¸ºå­—å…¸æ ¼å¼
            documents = []
            for doc_data in document_data_list:
                documents.append({
                    'doc_id': doc_data.doc_id,
                    'content': doc_data.content,
                    'topic': doc_data.topic,
                    'file_path': doc_data.file_path,
                    'length': doc_data.length
                })
            
            logger.info(f"åŠ è½½æ–‡æ¡£æ•°: {len(documents)}")
            
            # 2. æ–‡æ¡£ç­›é€‰
            logger.info("ğŸ” æ–‡æ¡£è´¨é‡ç­›é€‰...")
            screened_documents = []
            
            # è½¬æ¢å›DocumentDataå¯¹è±¡è¿›è¡Œç­›é€‰
            for doc_dict in documents[:max_documents]:
                # é‡æ–°æ„å»ºDocumentDataå¯¹è±¡
                from document_loader import DocumentData
                doc_data = DocumentData(
                    doc_id=doc_dict['doc_id'],
                    file_path=doc_dict['file_path'],
                    content=doc_dict['content'],
                    topic=doc_dict['topic'],
                    length=doc_dict['length']
                )
                
                # ä½¿ç”¨DocumentScreenerè¿›è¡Œç­›é€‰
                screening_result = self.document_screener.screen_document(doc_data)
                
                if screening_result.is_suitable:
                    screened_documents.append(doc_dict)  # ä¿ç•™å­—å…¸æ ¼å¼ç»™åç»­å¤„ç†
                    logger.info(f"âœ… æ–‡æ¡£é€šè¿‡ç­›é€‰: {doc_dict['doc_id']} (è´¨é‡åˆ†æ•°: {screening_result.quality_score:.2f})")
                else:
                    logger.info(f"âŒ æ–‡æ¡£æœªé€šè¿‡ç­›é€‰: {doc_dict['doc_id']} (åŸå› : {screening_result.reasoning})")
                
                if len(screened_documents) >= max_documents:
                    break
            
            logger.info(f"ç­›é€‰åæ–‡æ¡£æ•°: {len(screened_documents)}")
            
            # 3. è¿è¡Œè¯­è¨€å­¦æ·±åº¦æŸ¥è¯¢å®éªŒ
            results = self._run_linguistic_mode(screened_documents, topic, session_id)
            
            # 4. è®¡ç®—æœ€ç»ˆç»Ÿè®¡
            total_time = time.time() - start_time
            final_results = self._generate_final_results(results, session_id, total_time)
            
            # 5. ä¿å­˜ç»“æœ
            self._save_complete_results(final_results, session_id)
            
            logger.info(f"âœ… å®Œæ•´å®éªŒå®Œæˆ: {session_id}")
            logger.info(f"æ€»è€—æ—¶: {total_time:.2f}ç§’")
            logger.info(f"æˆåŠŸç‡: {final_results['summary']['success_rate']:.1%}")
            
            return final_results
            
        except Exception as e:
            logger.error(f"å®Œæ•´å®éªŒå¤±è´¥: {e}")
            return self._create_error_result(session_id, str(e))
    

    def _run_linguistic_mode(self, documents: List[Dict], topic: str, session_id: str) -> Dict[str, Any]:
        """è¿è¡Œè¯­è¨€å­¦æ¨¡å¼ - ğŸ”¥ çœŸæ­£ä½¿ç”¨IntegratedPromptTemplates"""
        logger.info("ğŸ”¬ è¿è¡Œè¯­è¨€å­¦æ¨¡å¼ï¼ˆåŸºäºå…³é”®è¯æ›¿æ¢å’ŒIntegratedPromptTemplatesï¼‰")
        
        # éªŒè¯è¯­è¨€å­¦æ¡†æ¶å·²æ­£ç¡®åˆå§‹åŒ–
        if not self.linguistic_framework:
            logger.error("âŒ è¯­è¨€å­¦æ¡†æ¶æœªåˆå§‹åŒ–ï¼")
            return self._create_error_result(session_id, "Linguistic framework not initialized")
        
        try:
            logger.info("âœ… ä½¿ç”¨IntegratedPromptTemplatesçš„è¯­è¨€å­¦æ·±åº¦æŸ¥è¯¢æ¡†æ¶")
            
            results = {
                'session_id': session_id,
                'mode': 'linguistic',
                'topic': topic,
                'processed_documents': [],
                'statistics': {
                    'total_documents': len(documents),
                    'successful_documents': 0,
                    'failed_documents': 0,
                    'total_linguistic_questions': 0,
                    'total_hops': 0,
                    'prompt_templates_used': {
                        'prompt_1_used': 0,
                        'prompt_2_used': 0, 
                        'prompt_3_used': 0
                    }
                },
                'errors': []
            }
            
            # ğŸ”¥ ä¸ç»å…¸æ¨¡å¼ä¿æŒä¸€è‡´ï¼šå…ˆæå–çŸ­ç­”æ¡ˆï¼Œç„¶åä¸ºæ¯ä¸ªçŸ­ç­”æ¡ˆç”Ÿæˆè¯­è¨€å­¦æ·±åº¦æŸ¥è¯¢
            for i, document in enumerate(documents[:20]):  # é™åˆ¶20ä¸ªæ–‡æ¡£
                logger.info(f"ğŸ“„ å¤„ç†æ–‡æ¡£ {i+1}/{min(len(documents), 20)} (ä½¿ç”¨IntegratedPromptTemplates)")
                
                # 1. çŸ­ç­”æ¡ˆå®šä½ï¼ˆä¸ç»å…¸æ¨¡å¼ä¸€è‡´ï¼‰
                short_answers = self.short_answer_locator.locate_short_answers(
                    document['content'], 
                    document.get('doc_id', f'doc_{i}')
                )
                
                if not short_answers:
                    results['statistics']['failed_documents'] += 1
                    results['errors'].append(f"Doc {i+1}: No short answers found")
                    continue
                
                # 2. ä¸ºæ¯ä¸ªçŸ­ç­”æ¡ˆä½¿ç”¨è¯­è¨€å­¦æ¡†æ¶å¤„ç†ï¼ˆä¸ç»å…¸æ¨¡å¼çš„æ¯çŸ­ç­”æ¡ˆå¤„ç†ä¸€è‡´ï¼‰
                for j, short_answer in enumerate(short_answers[:3]):  # é™åˆ¶æ¯æ–‡æ¡£æœ€å¤š3ä¸ªçŸ­ç­”æ¡ˆ
                    try:
                        logger.info(f"   ğŸ¯ å¤„ç†çŸ­ç­”æ¡ˆ {j+1}/{min(len(short_answers), 3)}: {short_answer['answer_text']}")
                        
                        # ä½¿ç”¨è¯­è¨€å­¦æ¡†æ¶å¤„ç†å•ä¸ªçŸ­ç­”æ¡ˆ
                        linguistic_result = self.linguistic_framework.process_single_short_answer_with_linguistic_depth(
                            document_content=document['content'],
                            document_id=f"{document.get('doc_id', f'doc_{i}')}_{j}",
                            short_answer_text=short_answer['answer_text'],
                            short_answer_type=short_answer['answer_type']
                        )
                        
                        if linguistic_result and linguistic_result.get('success'):
                            # ğŸ”„ è½¬æ¢è¯­è¨€å­¦ç»“æœä¸ºExcelå…¼å®¹æ ¼å¼
                            excel_compatible_data = self._convert_linguistic_to_excel_format(linguistic_result, i)
                            
                            # è®°å½•æˆåŠŸçš„æ–‡æ¡£å¤„ç†
                            results['processed_documents'].append({
                                'doc_id': f"{document.get('doc_id', f'doc_{i}')}_{j}",
                                'linguistic_result': linguistic_result,
                                'excel_data': excel_compatible_data,  # æ–°å¢ï¼šExcelå…¼å®¹æ•°æ®
                                'integrated_templates_used': True,
                                'processing_time': time.time()
                            })
                            
                            results['statistics']['successful_documents'] += 1
                            results['statistics']['prompt_templates_used']['prompt_1_used'] += 1
                            
                            # ç»Ÿè®¡è¯­è¨€å­¦ç»“æœ
                            stats = linguistic_result.get('statistics', {})
                            results['statistics']['total_linguistic_questions'] += stats.get('total_questions', 0)
                            results['statistics']['total_hops'] += stats.get('successful_hops', 0)
                            results['statistics']['prompt_templates_used']['prompt_2_used'] += stats.get('successful_hops', 0)
                            results['statistics']['prompt_templates_used']['prompt_3_used'] += stats.get('successful_hops', 0)
                            
                            logger.info(f"âœ… çŸ­ç­”æ¡ˆ {j+1} è¯­è¨€å­¦å¤„ç†æˆåŠŸ (ä½¿ç”¨IntegratedPromptTemplates)")
                        else:
                            results['statistics']['failed_documents'] += 1
                            logger.warning(f"âŒ çŸ­ç­”æ¡ˆ {j+1} è¯­è¨€å­¦å¤„ç†å¤±è´¥")
                            
                    except Exception as e:
                        logger.error(f"å¤„ç†çŸ­ç­”æ¡ˆ {j+1} æ—¶å‡ºé”™: {e}")
                        results['statistics']['failed_documents'] += 1
                        results['errors'].append(f"Doc {i+1}_SA{j+1}: {str(e)}")
            
            # æ›´æ–°å…¨å±€ç»Ÿè®¡
            self.experiment_stats['successful_documents'] += results['statistics']['successful_documents']
            self.experiment_stats['documents_processed'] += results['statistics']['total_documents']
            self.experiment_stats['total_questions_generated'] += results['statistics']['total_linguistic_questions']
            self.experiment_stats['series_extensions'] += results['statistics'].get('series_extensions', 0)
            self.experiment_stats['parallel_extensions'] += results['statistics'].get('parallel_extensions', 0)
            self.experiment_stats['keyword_replacements_total'] += results['statistics'].get('keyword_replacements_total', 0)
            
            # ç»Ÿè®¡Tree Level Queryç”Ÿæˆ
            tree_level_generated = sum(1 for doc in results['processed_documents'] 
                                     if doc.get('linguistic_result', {}).get('tree_level_query'))
            self.experiment_stats['tree_level_queries_generated'] += tree_level_generated
            
            logger.info(f"âœ… è¯­è¨€å­¦æ¨¡å¼å®Œæˆ:")
            logger.info(f"  - æˆåŠŸå¤„ç†æ–‡æ¡£: {results['statistics']['successful_documents']}")
            logger.info(f"  - Prompt-1ä½¿ç”¨æ¬¡æ•°: {results['statistics']['prompt_templates_used']['prompt_1_used']}")
            logger.info(f"  - Prompt-2ä½¿ç”¨æ¬¡æ•°: {results['statistics']['prompt_templates_used']['prompt_2_used']}")
            logger.info(f"  - Prompt-3ä½¿ç”¨æ¬¡æ•°: {results['statistics']['prompt_templates_used']['prompt_3_used']}")
            
            return results
            
        except Exception as e:
            logger.error(f"è¯­è¨€å­¦æ¨¡å¼è¿è¡Œå¤±è´¥: {e}")
            return {
                'mode': 'linguistic',
                'success': False,
                'error': str(e),
                'processed_documents': []
            }
    
    def _generate_final_results(self, processing_results: Dict, session_id: str, total_time: float) -> Dict[str, Any]:
        """ç”Ÿæˆæœ€ç»ˆç»“æœ"""
        
        # è¯­è¨€å­¦æ¨¡å¼ç»“æœ
        successful_docs = processing_results.get('statistics', {}).get('successful_documents', 0)
        total_docs = processing_results.get('statistics', {}).get('total_documents', 0)
        success_rate = successful_docs / max(total_docs, 1) if total_docs > 0 else 0
        
        return {
            'success': processing_results.get('success', True),
            'session_id': session_id,
            'mode': 'linguistic',
            'total_processing_time': total_time,
            'processing_results': processing_results,
            'experiment_statistics': self.experiment_stats.copy(),
            'summary': {
                'total_documents_attempted': total_docs,
                'successful_documents': successful_docs,
                'failed_documents': processing_results.get('statistics', {}).get('failed_documents', 0),
                'success_rate': success_rate,
                'total_questions_generated': self.experiment_stats['total_questions_generated'],
                'series_extensions': self.experiment_stats['series_extensions'],
                'parallel_extensions': self.experiment_stats['parallel_extensions'],
                'tree_level_queries': self.experiment_stats['tree_level_queries_generated'],
                'keyword_replacements_total': self.experiment_stats['keyword_replacements_total'],
                'avg_processing_time': total_time / max(total_docs, 1) if total_docs > 0 else 0
            },
            'linguistic_framework_features': {
                'keyword_replacement_driven': True,
                'search_based_extensions': True,
                'five_level_depth': True,
                'mathematical_formulation': True,
                'tree_level_query_integration': True,
                'circular_prevention': True,
                'series_parallel_extensions': True
            }
        }
    
    def _save_complete_results(self, results: Dict, session_id: str):
        """ä¿å­˜å®Œæ•´ç»“æœ"""
        try:
            # åˆ›å»ºç»“æœç›®å½•
            results_dir = Path("results")
            results_dir.mkdir(exist_ok=True)
            
            # ä¿å­˜è¯¦ç»†JSONç»“æœ
            json_file = results_dir / f"{session_id}_complete_results.json"
            with open(json_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2, default=str)
            
            # ğŸ”¥ æ–°å¢ï¼šå¯¼å‡ºExcelæ ¼å¼æ•°æ®
            self._export_excel_results(results, session_id, results_dir)
            
            # ä¿å­˜ç®€åŒ–æ‘˜è¦
            summary_file = results_dir / f"{session_id}_summary.json"
            summary_data = {
                'session_id': session_id,
                'mode': results.get('mode', 'unknown'),
                'success': results.get('success', False),
                'summary': results.get('summary', {}),
                'processing_time': results.get('total_processing_time', 0),
                'optimizations_applied': results.get('optimizations_applied', {}),
                'linguistic_features': results.get('linguistic_framework_features', {})
            }
            
            with open(summary_file, 'w', encoding='utf-8') as f:
                json.dump(summary_data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"ç»“æœå·²ä¿å­˜:")
            logger.info(f"  è¯¦ç»†ç»“æœ: {json_file}")
            logger.info(f"  æ‘˜è¦ç»“æœ: {summary_file}")
            
        except Exception as e:
            logger.error(f"ä¿å­˜ç»“æœå¤±è´¥: {e}")
    
    def _create_error_result(self, session_id: str, error_message: str) -> Dict[str, Any]:
        """åˆ›å»ºé”™è¯¯ç»“æœ"""
        return {
            'success': False,
            'session_id': session_id,
            'error': error_message,
            'experiment_statistics': self.experiment_stats.copy(),
            'summary': {
                'total_documents_attempted': 0,
                'successful_documents': 0,
                'success_rate': 0.0
            }
        }
    
    def get_framework_status(self) -> Dict[str, Any]:
        """è·å–æ¡†æ¶çŠ¶æ€"""
        return {
            'initialized': self.api_client is not None,
            'components_status': {
                'api_client': self.api_client is not None,
                'linguistic_framework': self.linguistic_framework is not None,
                'tree_level_query': True,
                'circular_prevention': True,
                'series_parallel_extensions': True
            },
            'experiment_stats': self.experiment_stats.copy(),
            'framework_features': [
                'keyword_replacement_driven',
                'five_level_depth',
                'mathematical_formulation',
                'tree_level_query_integration',
                'series_parallel_extensions',
                'circular_prevention',
                'web_search_driven'
            ]
        }

    def get_experiment_statistics(self) -> Dict[str, Any]:
        """è·å–å®éªŒç»Ÿè®¡ä¿¡æ¯"""
        total_time = time.time() - self.experiment_stats['session_start_time']
        
        return {
            **self.experiment_stats,
            'total_session_time': total_time,
            'average_processing_time': total_time / max(self.experiment_stats['documents_processed'], 1),
            'success_rate': self.experiment_stats['successful_documents'] / max(self.experiment_stats['documents_processed'], 1)
        }

    def _convert_linguistic_to_excel_format(self, linguistic_result: Dict[str, Any], doc_index: int) -> Dict[str, Any]:
        """
        å°†è¯­è¨€å­¦æ·±åº¦æŸ¥è¯¢ç»“æœè½¬æ¢ä¸ºExcelå…¼å®¹æ ¼å¼
        
        Args:
            linguistic_result: è¯­è¨€å­¦æ¡†æ¶è¿”å›çš„ç»“æœ
            doc_index: æ–‡æ¡£ç´¢å¼•
            
        Returns:
            Excelå…¼å®¹çš„æ•°æ®ç»“æ„
        """
        document_id = linguistic_result.get('document_id', f'doc_{doc_index}')
        
        # å‡†å¤‡Excelè¡¨æ ¼æ•°æ®
        excel_data = {
            'qa_pairs': [],
            'trajectory_data': [],
            'keyword_replacements': [],
            'validation_results': []
        }
        
        try:
            # 1. å¤„ç†é—®ç­”å¯¹æ•°æ®
            question_chains = linguistic_result.get('question_chains', {})
            for chain_id, questions in question_chains.items():
                for level, question in enumerate(questions):
                    excel_data['qa_pairs'].append({
                        'Tree_ID': f"{document_id}_{chain_id}",
                        'Node_Type': 'Root' if level == 0 else 'Extension',
                        'Node_ID': question.get('question_id', f'{chain_id}_q{level}'),
                        'Question': question.get('question_text', ''),
                        'Answer': question.get('answer', ''),
                        'Short_Answer': question.get('answer', ''),  # è¯­è¨€å­¦æ¨¡å¼ä¸­ç­”æ¡ˆå°±æ˜¯short answer
                        'Document_ID': document_id,
                        'Topic': self._extract_topic_from_doc_id(document_id),
                        'TXT_File': f"{document_id}.txt",
                        'Question_Type': 'linguistic_deep',
                        'Difficulty': 'medium',
                        'Extension_Type': self._determine_linguistic_extension_type(question, level),
                        'Depth_Level': question.get('level', level),
                        'Keywords': ', '.join(question.get('keywords', [])),
                        'Confidence': question.get('validation_passed', False),
                        'Verification_Score': 1.0 if question.get('validation_passed', False) else 0.0
                    })
            
            # 2. å¤„ç†è½¨è¿¹æ•°æ®
            trajectories = linguistic_result.get('trajectories', [])
            for traj in trajectories:
                excel_data['trajectory_data'].append({
                    'è½¨è¿¹ID': f"{document_id}_traj_{traj.get('level', 0)}",
                    'æ–‡æ¡£ID': document_id,
                    'æ€»å¤„ç†æ—¶é—´': round(traj.get('processing_time', 0.0), 2),
                    'æˆåŠŸç‡': "100%" if traj.get('hop_success', False) else "0%",
                    'éªŒè¯æ€»æ•°': 1,
                    'æˆåŠŸéªŒè¯æ•°': 1 if traj.get('validation_passed', False) else 0,
                    'Webæœç´¢æ¬¡æ•°': len(traj.get('keyword_replacements', [])),
                    'æœ€ç»ˆæ ‘æ·±åº¦': traj.get('level', 0),
                    'æœ€ç»ˆæ ‘å¤§å°': len(traj.get('keyword_replacements', [])),
                    'å¹³å‡éªŒè¯åˆ†æ•°': "1.000" if traj.get('validation_passed', False) else "0.000",
                    'å…³é”®è¯å±‚æ¬¡åˆè§„ç‡': "100.0%",
                    'å¿«æ·è·¯å¾„é˜²æ­¢ç‡': "100.0%",
                    'æ ¹é—®é¢˜éªŒè¯åˆ†æ•°': "1.000" if traj.get('validation_passed', False) else "0.000",
                    'å…³é”®è¯æå–è´¨é‡': "1.000",
                    'æ‰©å±•æ­¥éª¤æ•°': len(traj.get('keyword_replacements', []))
                })
            
            # 3. å¤„ç†å…³é”®è¯æ›¿æ¢æ•°æ® (è¯­è¨€å­¦æ¨¡å¼ç‰¹æœ‰)
            for traj in trajectories:
                for kr in traj.get('keyword_replacements', []):
                    excel_data['keyword_replacements'].append({
                        'æ–‡æ¡£ID': document_id,
                        'å±‚çº§': traj.get('level', 0),
                        'åŸå…³é”®è¯': kr.get('original_keyword', ''),
                        'æ›¿æ¢æè¿°': kr.get('replacement_description', ''),
                        'æœç´¢æŸ¥è¯¢': kr.get('search_query', ''),
                        'å”¯ä¸€æ€§éªŒè¯': kr.get('uniqueness_verified', False),
                        'ç½®ä¿¡åº¦': kr.get('confidence', 0.0),
                        'åŸé—®é¢˜': traj.get('original_question', ''),
                        'æ–°é—®é¢˜': traj.get('new_question', ''),
                        'å¤„ç†ç´¢å¼•': doc_index
                    })
            
            # 4. å¤„ç†éªŒè¯ç»“æœæ•°æ®
            for traj in trajectories:
                verification = traj.get('verification_details', {})
                excel_data['validation_results'].append({
                    'æ–‡æ¡£ID': document_id,
                    'å±‚çº§': traj.get('level', 0),
                    'å”¯ä¸€æ€§æ£€æŸ¥': verification.get('uniqueness_check', False),
                    'ç­”æ¡ˆä¸€è‡´æ€§': verification.get('answer_consistency', False),
                    'æœ€å¤§è·³æ•°æ£€æŸ¥': verification.get('max_hops_check', False),
                    'æ— å¾ªç¯æ£€æŸ¥': verification.get('no_circular_check', False),
                    'æ•´ä½“é€šè¿‡': verification.get('passed', False),
                    'ç½®ä¿¡åº¦': verification.get('confidence', 0.0),
                    'æ¨ç†è¯´æ˜': verification.get('reasoning', ''),
                    'å¤„ç†ç´¢å¼•': doc_index
                })
            
            logger.info(f"ğŸ“Š è¯­è¨€å­¦ç»“æœExcelè½¬æ¢å®Œæˆ: {document_id}")
            logger.info(f"   - é—®ç­”å¯¹: {len(excel_data['qa_pairs'])}")
            logger.info(f"   - è½¨è¿¹æ•°æ®: {len(excel_data['trajectory_data'])}")
            logger.info(f"   - å…³é”®è¯æ›¿æ¢: {len(excel_data['keyword_replacements'])}")
            logger.info(f"   - éªŒè¯ç»“æœ: {len(excel_data['validation_results'])}")
            
        except Exception as e:
            logger.error(f"è¯­è¨€å­¦ç»“æœExcelè½¬æ¢å¤±è´¥ {document_id}: {e}")
        
        return excel_data
    
    def _extract_topic_from_doc_id(self, doc_id: str) -> str:
        """ä»æ–‡æ¡£IDä¸­æå–ä¸»é¢˜"""
        if '_' in doc_id:
            return doc_id.split('_')[0]
        return doc_id[:8] if len(doc_id) > 8 else doc_id

    def _determine_linguistic_extension_type(self, question: Dict[str, Any], level: int) -> str:
        """æ ¹æ®é—®é¢˜IDå’Œå±‚çº§åˆ¤æ–­è¯­è¨€å­¦æ‰©å±•ç±»å‹"""
        question_id = question.get('question_id', '')
        
        if level == 0:
            return 'root'
        elif level == 1:
            return 'initial_question'
        elif 'parallel' in question_id:
            return 'parallel_linguistic'
        else:
            return 'series_linguistic'

    def _export_excel_results(self, results: Dict, session_id: str, results_dir: Path):
        """å¯¼å‡ºExcelæ ¼å¼çš„ç»“æœæ•°æ®"""
        try:
            import pandas as pd
            
            excel_file = results_dir / f"{session_id}_complete_data.xlsx"
            mode = results.get('mode', 'unknown')
            
            with pd.ExcelWriter(excel_file, engine='openpyxl') as writer:
                
                if mode == 'linguistic':
                    # è¯­è¨€å­¦æ¨¡å¼ï¼šä½¿ç”¨è½¬æ¢åçš„Excelæ•°æ®
                    self._export_linguistic_excel(results, writer)
                else:
                    # ç»å…¸æ¨¡å¼ï¼šä½¿ç”¨åŸæœ‰å¯¼å‡ºç³»ç»Ÿ
                    self._export_classic_excel(results, writer)
                
                # é€šç”¨ç»Ÿè®¡è¡¨
                self._export_general_statistics(results, writer)
            
            logger.info(f"ğŸ“Š Excelç»“æœå·²å¯¼å‡º: {excel_file}")
            
        except Exception as e:
            logger.error(f"Excelå¯¼å‡ºå¤±è´¥: {e}")
    
    def _export_linguistic_excel(self, results: Dict, writer):
        """å¯¼å‡ºè¯­è¨€å­¦æ¨¡å¼çš„Excelæ•°æ®"""
        import pandas as pd
        
        # æ”¶é›†æ‰€æœ‰Excelæ•°æ®
        all_qa_pairs = []
        all_trajectory_data = []
        all_keyword_replacements = []
        all_validation_results = []
        
        processed_docs = results.get('processing_results', {}).get('processed_documents', [])
        
        for doc_data in processed_docs:
            excel_data = doc_data.get('excel_data', {})
            
            all_qa_pairs.extend(excel_data.get('qa_pairs', []))
            all_trajectory_data.extend(excel_data.get('trajectory_data', []))
            all_keyword_replacements.extend(excel_data.get('keyword_replacements', []))
            all_validation_results.extend(excel_data.get('validation_results', []))
        
        # åˆ›å»ºExcelå·¥ä½œè¡¨
        if all_qa_pairs:
            qa_df = pd.DataFrame(all_qa_pairs)
            qa_df.to_excel(writer, sheet_name='é—®ç­”æ•°æ®', index=False)
            logger.info(f"   ğŸ“ é—®ç­”æ•°æ®: {len(all_qa_pairs)} æ¡è®°å½•")
        
        if all_trajectory_data:
            traj_df = pd.DataFrame(all_trajectory_data)
            traj_df.to_excel(writer, sheet_name='è½¨è¿¹æ•°æ®', index=False)
            logger.info(f"   ğŸ›¤ï¸ è½¨è¿¹æ•°æ®: {len(all_trajectory_data)} æ¡è®°å½•")
        
        if all_keyword_replacements:
            kr_df = pd.DataFrame(all_keyword_replacements)
            kr_df.to_excel(writer, sheet_name='å…³é”®è¯æ›¿æ¢', index=False)
            logger.info(f"   ğŸ”„ å…³é”®è¯æ›¿æ¢: {len(all_keyword_replacements)} æ¡è®°å½•")
        
        if all_validation_results:
            val_df = pd.DataFrame(all_validation_results)
            val_df.to_excel(writer, sheet_name='éªŒè¯ç»“æœ', index=False)
            logger.info(f"   âœ… éªŒè¯ç»“æœ: {len(all_validation_results)} æ¡è®°å½•")
    
    def _export_classic_excel(self, results: Dict, writer):
        """å¯¼å‡ºç»å…¸æ¨¡å¼çš„Excelæ•°æ®"""
        import pandas as pd
        
        # ä½¿ç”¨ç°æœ‰çš„å¯¼å‡ºç³»ç»Ÿå¯¼å‡ºç»å…¸æ¨¡å¼æ•°æ®
        processed_docs = results.get('processing_results', {}).get('processed_documents', [])
        
        qa_pairs = []
        for doc_data in processed_docs:
            tree_data = doc_data.get('tree_data', {})
            tree_id = tree_data.get('tree_id', 'unknown')
            
            # æ ¹é—®é¢˜
            root_question = tree_data.get('root_question', {})
            if root_question:
                qa_pairs.append({
                    'Tree_ID': tree_id,
                    'Node_Type': 'Root',
                    'Node_ID': 'root',
                    'Question': root_question.get('question', ''),
                    'Answer': root_question.get('answer', ''),
                    'Short_Answer': root_question.get('answer', ''),
                    'Document_ID': tree_data.get('root_question', {}).get('document_id', ''),
                    'Question_Type': 'classic_optimized',
                    'Depth_Level': 0
                })
            
            # æ‰©å±•èŠ‚ç‚¹
            nodes = tree_data.get('nodes', {})
            for node_id, node_data in nodes.items():
                qa_pairs.append({
                    'Tree_ID': tree_id,
                    'Node_Type': 'Extension',
                    'Node_ID': node_id,
                    'Question': node_data.get('question', ''),
                    'Answer': node_data.get('answer', ''),
                    'Short_Answer': node_data.get('short_answer', ''),
                    'Document_ID': tree_data.get('root_question', {}).get('document_id', ''),
                    'Question_Type': 'classic_optimized',
                    'Depth_Level': node_data.get('depth_level', 1)
                })
        
        if qa_pairs:
            qa_df = pd.DataFrame(qa_pairs)
            qa_df.to_excel(writer, sheet_name='é—®ç­”æ•°æ®', index=False)
            logger.info(f"   ğŸ“ ç»å…¸æ¨¡å¼é—®ç­”æ•°æ®: {len(qa_pairs)} æ¡è®°å½•")
    
    def _export_general_statistics(self, results: Dict, writer):
        """å¯¼å‡ºé€šç”¨ç»Ÿè®¡ä¿¡æ¯"""
        import pandas as pd
        
        summary = results.get('summary', {})
        stats = results.get('experiment_statistics', {})
        mode = results.get('mode', 'unknown')
        
        # åŸºç¡€ç»Ÿè®¡
        basic_stats = {
            'ç»Ÿè®¡é¡¹ç›®': [
                'è¿è¡Œæ¨¡å¼', 'å¤„ç†æ—¶é—´(ç§’)', 'æ–‡æ¡£æ€»æ•°', 'æˆåŠŸæ–‡æ¡£æ•°', 'å¤±è´¥æ–‡æ¡£æ•°', 
                'æˆåŠŸç‡(%)', 'ç”Ÿæˆé—®é¢˜æ€»æ•°', 'å¹³å‡å¤„ç†æ—¶é—´(ç§’)'
            ],
            'æ•°å€¼': [
                mode,
                round(results.get('total_processing_time', 0), 2),
                summary.get('total_documents_attempted', 0),
                summary.get('successful_documents', 0),
                summary.get('failed_documents', 0),
                f"{summary.get('success_rate', 0) * 100:.1f}%",
                summary.get('total_questions_generated', 0),
                round(summary.get('avg_processing_time', 0), 2)
            ]
        }
        
        # æ¨¡å¼ç‰¹å®šç»Ÿè®¡
        if mode == 'linguistic':
            ling_stats = results.get('processing_results', {}).get('statistics', {})
            basic_stats['ç»Ÿè®¡é¡¹ç›®'].extend([
                'Prompt-1ä½¿ç”¨æ¬¡æ•°', 'Prompt-2ä½¿ç”¨æ¬¡æ•°', 'Prompt-3ä½¿ç”¨æ¬¡æ•°',
                'è¯­è¨€å­¦é—®é¢˜æ•°', 'è·³è·ƒæ¬¡æ•°', 'Seriesæ‰©å±•', 'Parallelæ‰©å±•'
            ])
            basic_stats['æ•°å€¼'].extend([
                ling_stats.get('prompt_templates_used', {}).get('prompt_1_used', 0),
                ling_stats.get('prompt_templates_used', {}).get('prompt_2_used', 0),
                ling_stats.get('prompt_templates_used', {}).get('prompt_3_used', 0),
                ling_stats.get('total_linguistic_questions', 0),
                ling_stats.get('total_hops', 0),
                ling_stats.get('series_extensions', 0),
                ling_stats.get('parallel_extensions', 0)
            ])
        elif mode == 'classic':
            basic_stats['ç»Ÿè®¡é¡¹ç›®'].extend([
                'å¾ªç¯æ£€æµ‹æ¬¡æ•°', 'Tree LevelæŸ¥è¯¢æ•°', 'éªŒè¯æ”¹è¿›æ¬¡æ•°'
            ])
            basic_stats['æ•°å€¼'].extend([
                summary.get('circular_detections', 0),
                summary.get('tree_level_queries', 0),
                stats.get('validation_improvements', 0)
            ])
        
        stats_df = pd.DataFrame(basic_stats)
        stats_df.to_excel(writer, sheet_name='å®éªŒç»Ÿè®¡', index=False)
        
        logger.info(f"   ğŸ“Š ç»Ÿè®¡ä¿¡æ¯: {len(basic_stats['ç»Ÿè®¡é¡¹ç›®'])} é¡¹æŒ‡æ ‡")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”¬ Linguistic Deep Query Framework - è¯­è¨€å­¦æ·±åº¦æŸ¥è¯¢æ¡†æ¶")
    print("=" * 80)
    print("æ ¸å¿ƒç‰¹æ€§:")
    print("  ğŸ¯ åŸºäºå…³é”®è¯æ›¿æ¢çš„5å±‚çº§æ·±åº¦æŸ¥è¯¢")
    print("  ğŸ§® æ•°å­¦å…¬å¼åŒ–æµç¨‹: Q^(t+1) = Q^t[K_i^t â†’ D(K_i^t)]")
    print("  ğŸŒ Webæœç´¢é©±åŠ¨çš„æ‰©å±•ç”Ÿæˆ")
    print("  ğŸ”„ Series & Parallelæ‰©å±•ç­–ç•¥")
    print("  ğŸ­ Tree Level Queryæœ€ç»ˆæ•´åˆ")
    print("  ğŸš« å¾ªç¯é—®é¢˜é¢„é˜²æœºåˆ¶")
    print("=" * 80)
    
    # è·å–ç”¨æˆ·è¾“å…¥
    try:
        api_key = input("è¯·è¾“å…¥OpenAI APIå¯†é’¥: ").strip()
        if not api_key:
            print("âŒ APIå¯†é’¥ä¸èƒ½ä¸ºç©º")
            return False
        
        # ğŸ”¥ å‘ç°å¯ç”¨çš„ClueWeb22 topics
        print("\nğŸ” æ­£åœ¨æ‰«æClueWeb22æ•°æ®é›†...")
        document_loader = DocumentLoader()
        available_topics = document_loader.discover_topics()
        
        if not available_topics:
            print("âŒ æœªæ‰¾åˆ°å¯ç”¨çš„ClueWeb22 topicsï¼Œè¯·æ£€æŸ¥æ•°æ®è·¯å¾„")
            print(f"æ•°æ®è·¯å¾„: {document_loader.config.clueweb22_path}")
            return False
        
        # æ˜¾ç¤ºå¯ç”¨topicså¹¶è®©ç”¨æˆ·é€‰æ‹©
        print(f"\nğŸ“‹ å‘ç° {len(available_topics)} ä¸ªå¯ç”¨topics:")
        for i, topic in enumerate(available_topics, 1):
            print(f"  {i}. {topic}")
        
        while True:
            try:
                choice_input = input(f"\nè¯·é€‰æ‹©topic [1-{len(available_topics)}] (é»˜è®¤: 1): ").strip()
                if not choice_input:
                    choice = 1
                else:
                    choice = int(choice_input)
                
                if 1 <= choice <= len(available_topics):
                    selected_topic = available_topics[choice - 1]
                    break
                else:
                    print(f"âŒ è¯·è¾“å…¥ 1-{len(available_topics)} ä¹‹é—´çš„æ•°å­—")
            except ValueError:
                print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
        
        max_docs_input = input("è¯·è¾“å…¥æœ€å¤§æ–‡æ¡£æ•° (é»˜è®¤: 20): ").strip()
        max_docs = int(max_docs_input) if max_docs_input.isdigit() else 20
        
        print(f"\nğŸ¯ å®éªŒé…ç½®ç¡®è®¤:")
        print(f"  é€‰æ‹©çš„Topic: {selected_topic}")
        print(f"  æ¨¡å¼: è¯­è¨€å­¦æ·±åº¦æŸ¥è¯¢")
        print(f"  æœ€å¤§æ–‡æ¡£æ•°: {max_docs}")
        print(f"  æ•°å­¦å…¬å¼: Q^(t+1) = Q^t[K_i^t â†’ D(K_i^t)]")
        print(f"  ç‰¹æ€§: Extensionç­”æ¡ˆ=å…³é”®è¯ + Webæœç´¢ + Tree Level Query")
        
        confirm = input("\næ˜¯å¦ç»§ç»­? [y/N]: ").strip().lower()
        if confirm != 'y':
            print("å–æ¶ˆè¿è¡Œ")
            return False
        
        # åˆå§‹åŒ–å¹¶è¿è¡Œæ¡†æ¶
        framework = LinguisticMainFramework()
        
        if not framework.initialize_framework(api_key):
            print("âŒ æ¡†æ¶åˆå§‹åŒ–å¤±è´¥")
            return False
        
        # æ˜¾ç¤ºæ¡†æ¶çŠ¶æ€
        status = framework.get_framework_status()
        print(f"\nğŸ“Š æ¡†æ¶çŠ¶æ€:")
        print(f"  åˆå§‹åŒ–çŠ¶æ€: {'âœ…' if status['initialized'] else 'âŒ'}")
        print(f"  è¯­è¨€å­¦æ¡†æ¶: âœ…")
        print(f"  Tree Level Query: âœ…")
        print(f"  å¾ªç¯é¢„é˜²: âœ…")
        print(f"  Series & Parallel: âœ…")
        
        # è¿è¡Œå®éªŒ
        print(f"\nğŸš€ å¼€å§‹è¿è¡Œè¯­è¨€å­¦æ·±åº¦æŸ¥è¯¢å®éªŒ...")
        results = framework.run_linguistic_experiment(selected_topic, max_docs)
        
        # æ˜¾ç¤ºç»“æœæ‘˜è¦
        print(f"\nğŸ“Š å®éªŒç»“æœæ‘˜è¦:")
        print(f"  æˆåŠŸ: {'âœ…' if results['success'] else 'âŒ'}")
        
        if results['success']:
            summary = results['summary']
            print(f"  å¤„ç†æ–‡æ¡£: {summary.get('successful_documents', 0)}/{summary.get('total_documents_attempted', 0)}")
            print(f"  æˆåŠŸç‡: {summary.get('success_rate', 0):.1%}")
            print(f"  ç”Ÿæˆé—®é¢˜: {summary.get('total_questions_generated', 0)}")
            print(f"  Seriesæ‰©å±•: {summary.get('series_extensions', 0)}")
            print(f"  Parallelæ‰©å±•: {summary.get('parallel_extensions', 0)}")
            print(f"  Tree Level Query: {summary.get('tree_level_queries', 0)}")
            print(f"  å…³é”®è¯æ›¿æ¢: {summary.get('keyword_replacements_total', 0)}")
            print(f"  æ€»è€—æ—¶: {results.get('total_processing_time', 0):.2f}ç§’")
        else:
            print(f"  é”™è¯¯: {results.get('error', 'Unknown error')}")
        
        print(f"\nâœ… å®éªŒå®Œæˆï¼Œç»“æœå·²ä¿å­˜åˆ° results/ ç›®å½•")
        return results['success']
        
    except KeyboardInterrupt:
        print("\n\nç”¨æˆ·ä¸­æ–­å®éªŒ")
        return False
    except Exception as e:
        print(f"\nâŒ å®éªŒè¿è¡Œå¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    success = main()
    exit(0 if success else 1) 