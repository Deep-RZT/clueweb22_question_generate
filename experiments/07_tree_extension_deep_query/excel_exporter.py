#!/usr/bin/env python3
"""
ä¼˜åŒ–ç‰ˆExcelå¯¼å‡ºå™¨ - ä¸“é—¨å¤„ç†dictæ ¼å¼çš„JSONæ•°æ®
æ”¯æŒåµŒå¥—ç´¯ç§¯å‹å’ŒLLMæ•´åˆå‹ç»¼åˆé—®é¢˜åŠç­”æ¡ˆçš„å®Œæ•´å¯¼å‡º
"""

import json
import pandas as pd
from pathlib import Path
from typing import Dict, List, Any, Optional
import logging

logger = logging.getLogger(__name__)

class FixedCleanExcelExporter:
    """ä¼˜åŒ–ç‰ˆExcelå¯¼å‡ºå™¨ - å®Œå…¨dictæ ¼å¼æ”¯æŒ"""
    
    def __init__(self, output_dir: str = "results"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)

    def export_clean_excel(self, json_file_path: Path) -> str:
        """å¯¼å‡ºç®€æ´ç‰ˆExcelæ–‡ä»¶"""
        print(f"ğŸ”„ è¯»å–JSONæ–‡ä»¶: {json_file_path.name}")
        
        # è¯»å–JSONæ•°æ®
        with open(json_file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        print("ğŸ“Š è§£ææ•°æ®...")
        parsed_data = self._parse_dict_data(data)
        
        # ç”ŸæˆExcelæ–‡ä»¶å
        timestamp = json_file_path.stem.split('_')[-1]
        excel_filename = f"agent_reasoning_analysis_{timestamp}.xlsx"
        excel_path = self.output_dir / excel_filename
        
        print("ğŸ“ ç”ŸæˆExcelå·¥ä½œè¡¨...")
        self._write_excel_sheets(parsed_data, excel_path)
        
        return str(excel_path)

    def _parse_dict_data(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """è§£ædictæ ¼å¼çš„JSONæ•°æ®"""
        parsed = {
            'efficiency_data': [],   # æ–‡æ¡£å¤„ç†æ•ˆç‡ç»Ÿè®¡
            'composite_qa': [],      # ç³…åˆåçš„é—®ç­”å¯¹
            'all_process_qa': [],    # æ‰€æœ‰è¿‡ç¨‹ä¸­çš„é—®ç­”å¯¹
            'trajectories': [],      # è½¨è¿¹æ•°æ®
        }
        
        processing_results = data.get('processing_results', {})
        processed_docs = processing_results.get('processed_documents', [])
        
        print(f"ğŸ“‹ è§£æ {len(processed_docs)} ä¸ªå¤„ç†æ–‡æ¡£...")
        
        for doc_idx, doc in enumerate(processed_docs):
            doc_id = doc.get('doc_id', f'Unknown_{doc_idx}')
            reasoning_trees = doc.get('reasoning_trees', [])
            trajectory_records = doc.get('trajectory_records', [])
            
            print(f"  ğŸ“„ å¤„ç†æ–‡æ¡£: {doc_id} ({len(reasoning_trees)} æ¨ç†æ ‘)")
            
            # è§£ææ¨ç†æ ‘ï¼ˆç°åœ¨åº”è¯¥æ˜¯dictæ ¼å¼ï¼‰
            for tree_idx, tree_data in enumerate(reasoning_trees):
                if isinstance(tree_data, dict):  # dictæ ¼å¼æ•°æ®
                    tree_id = tree_data.get('tree_id', f'{doc_id}_tree_{tree_idx}')
                    final_composite = tree_data.get('final_composite_query', {})
                    
                    # è·å–æ ¹èŠ‚ç‚¹ç­”æ¡ˆ
                    root_node = tree_data.get('root_node', {})
                    root_query = root_node.get('query', {})
                    root_answer = root_query.get('answer', 'N/A')
                    
                    # å¤„ç†ä¸‰æ ¼å¼çš„ç»¼åˆé—®é¢˜å’Œç­”æ¡ˆ
                    if isinstance(final_composite, dict):
                        # æ–°çš„ä¸‰æ ¼å¼ï¼ˆæ”¯æŒé—®é¢˜ã€ç­”æ¡ˆå’Œå…œåº•æ ‡è®°ï¼‰
                        nested_question = final_composite.get('nested_cumulative', '')
                        nested_answer = final_composite.get('nested_cumulative_answer', root_answer)
                        nested_fallback = final_composite.get('nested_cumulative_fallback', False)
                        
                        llm_question = final_composite.get('llm_integrated', '')
                        llm_answer = final_composite.get('llm_integrated_answer', root_answer)
                        llm_fallback = final_composite.get('llm_integrated_fallback', False)
                        
                        ambiguous_question = final_composite.get('ambiguous_integrated', '')
                        ambiguous_answer = final_composite.get('ambiguous_integrated_answer', root_answer)
                        ambiguous_fallback = final_composite.get('ambiguous_integrated_fallback', False)
                        
                        # æ£€æŸ¥ä¸‰ç§æ ¼å¼æ˜¯å¦æœ‰æ•ˆ
                        nested_valid = nested_question and len(nested_question.strip()) > 30
                        llm_valid = llm_question and len(llm_question.strip()) > 30
                        ambiguous_valid = ambiguous_question and len(ambiguous_question.strip()) > 30
                        
                        # æ·»åŠ åµŒå¥—ç´¯ç§¯å‹
                        parsed['composite_qa'].append({
                            'doc_id': doc_id,
                            'tree_id': tree_id,
                            'composite_question': nested_question if nested_valid else 'âŒ åµŒå¥—ç´¯ç§¯å‹é—®é¢˜ç”Ÿæˆå¤±è´¥',
                            'composite_answer': nested_answer if nested_valid else 'âŒ åµŒå¥—ç´¯ç§¯å‹ç­”æ¡ˆç”Ÿæˆå¤±è´¥',
                            'target_answer': root_answer,
                            'question_length': len(nested_question) if nested_valid else 0,
                            'tree_index': tree_idx,
                            'question_type': 'åµŒå¥—ç´¯ç§¯å‹',
                            'is_valid': nested_valid,
                            'is_fallback': nested_fallback
                        })
                        
                        # æ·»åŠ LLMæ•´åˆå‹
                        parsed['composite_qa'].append({
                            'doc_id': doc_id,
                            'tree_id': tree_id,
                            'composite_question': llm_question if llm_valid else 'âŒ LLMæ•´åˆå‹é—®é¢˜ç”Ÿæˆå¤±è´¥',
                            'composite_answer': llm_answer if llm_valid else 'âŒ LLMæ•´åˆå‹ç­”æ¡ˆç”Ÿæˆå¤±è´¥',
                            'target_answer': root_answer,
                            'question_length': len(llm_question) if llm_valid else 0,
                            'tree_index': tree_idx,
                            'question_type': 'LLMæ•´åˆå‹',
                            'is_valid': llm_valid,
                            'is_fallback': llm_fallback
                        })
                        
                        # æ·»åŠ æ¨¡ç³ŠåŒ–æ•´åˆå‹
                        parsed['composite_qa'].append({
                            'doc_id': doc_id,
                            'tree_id': tree_id,
                            'composite_question': ambiguous_question if ambiguous_valid else 'âŒ æ¨¡ç³ŠåŒ–æ•´åˆå‹é—®é¢˜ç”Ÿæˆå¤±è´¥',
                            'composite_answer': ambiguous_answer if ambiguous_valid else 'âŒ æ¨¡ç³ŠåŒ–æ•´åˆå‹ç­”æ¡ˆç”Ÿæˆå¤±è´¥',
                            'target_answer': root_answer,
                            'question_length': len(ambiguous_question) if ambiguous_valid else 0,
                            'tree_index': tree_idx,
                            'question_type': 'æ¨¡ç³ŠåŒ–æ•´åˆå‹',
                            'is_valid': ambiguous_valid,
                            'is_fallback': ambiguous_fallback
                        })
                    else:
                        # å…¼å®¹æ—§æ ¼å¼
                        composite_question = str(final_composite) if final_composite else ''
                        is_valid = len(composite_question.strip()) > 30
                        
                        parsed['composite_qa'].append({
                            'doc_id': doc_id,
                            'tree_id': tree_id,
                            'composite_question': composite_question if is_valid else 'âŒ æœªç”Ÿæˆæœ‰æ•ˆç»¼åˆé—®é¢˜',
                            'composite_answer': root_answer,
                            'target_answer': root_answer,
                            'question_length': len(composite_question) if is_valid else 0,
                            'tree_index': tree_idx,
                            'question_type': 'æ—§æ ¼å¼ï¼ˆå•ä¸€ç±»å‹ï¼‰',
                            'is_valid': is_valid,
                            'is_fallback': True  # æ—§æ ¼å¼éƒ½æ ‡è®°ä¸ºå…œåº•
                        })
                    
                    # æå–æ‰€æœ‰å±‚çº§çš„é—®ç­”å¯¹ - dictæ ¼å¼
                    process_qa = self._extract_qa_from_dict_tree(tree_data, doc_id, tree_id, tree_idx)
                    parsed['all_process_qa'].extend(process_qa)
                    
                else:
                    # å­—ç¬¦ä¸²æ ¼å¼æ•°æ® - ä¸åº”è¯¥å‡ºç°åœ¨æ–°ç³»ç»Ÿä¸­
                    print(f"    âš ï¸ å‘ç°å­—ç¬¦ä¸²æ ¼å¼æ¨ç†æ ‘ï¼Œè·³è¿‡å¤„ç†")
                    continue
            
            # è§£æè½¨è¿¹è®°å½•
            for traj in trajectory_records:
                if isinstance(traj, dict):
                    traj_info = self._parse_trajectory(traj, doc_id)
                    if traj_info:
                        parsed['trajectories'].append(traj_info)
            
            # ç”Ÿæˆæ–‡æ¡£çº§æ•ˆç‡æ•°æ®
            valid_composites = sum(1 for comp in parsed['composite_qa'] if comp['doc_id'] == doc_id and comp['is_valid'])
            doc_efficiency = {
                'doc_id': doc_id,
                'processing_time': doc.get('processing_time', 0),
                'trees_generated': len(reasoning_trees),
                'valid_composite_questions': valid_composites,
                'invalid_composite_questions': len(reasoning_trees) * 2 - valid_composites,  # ä¹˜ä»¥2å› ä¸ºæ¯ä¸ªæ ‘ç”Ÿæˆ2ç§ç±»å‹
                'success': len(reasoning_trees) > 0
            }
            parsed['efficiency_data'].append(doc_efficiency)
        
        return parsed

    def _extract_qa_from_dict_tree(self, tree_data: Dict[str, Any], doc_id: str, tree_id: str, tree_idx: int) -> List[Dict[str, Any]]:
        """ä»dictæ ¼å¼çš„æ¨ç†æ ‘ä¸­æå–æ‰€æœ‰é—®ç­”å¯¹"""
        qa_pairs = []
        
        try:
            all_nodes = tree_data.get('all_nodes', {})
            
            for node_id, node_data in all_nodes.items():
                query_data = node_data.get('query', {})
                
                qa_pairs.append({
                    'doc_id': doc_id,
                    'tree_id': tree_id,
                    'tree_index': tree_idx,
                    'node_id': node_id,
                    'question': query_data.get('query_text', 'N/A'),
                    'answer': query_data.get('answer', 'N/A'),
                    'branch_type': node_data.get('branch_type', 'unknown'),
                    'layer': node_data.get('layer', 0),
                    'generation_method': query_data.get('generation_method', 'unknown'),
                    'validation_passed': query_data.get('validation_passed', False),
                    'minimal_keywords': len(query_data.get('minimal_keywords', [])),
                    'parent_query_id': query_data.get('parent_query_id'),
                    'extension_type': query_data.get('extension_type', 'unknown')
                })
            
            print(f"    âœ… æå–äº† {len(qa_pairs)} ä¸ªé—®ç­”å¯¹")
            
        except Exception as e:
            print(f"    âŒ æå–é—®ç­”å¯¹å¤±è´¥: {e}")
            logger.error(f"ä»æ ‘ {tree_id} æå–é—®ç­”å¯¹å¤±è´¥: {e}")
        
        return qa_pairs

    def _parse_trajectory(self, traj: Dict, doc_id: str) -> Optional[Dict]:
        """è§£æè½¨è¿¹è®°å½•"""
        try:
            # ä»å®é™…çš„è½¨è¿¹è®°å½•å­—æ®µä¸­æå–æ•°æ®
            keywords_list = traj.get('current_keywords', [])
            keywords_str = ', '.join(keywords_list) if isinstance(keywords_list, list) else str(keywords_list)
            
            # è·å–éªŒè¯ç»“æœ
            validation_results = traj.get('validation_results', {})
            validation_passed = validation_results.get('validation_passed', False) if isinstance(validation_results, dict) else False
            
            return {
                'doc_id': doc_id,
                'step': traj.get('step', 'unknown'),
                'layer_level': traj.get('layer_level', 0),
                'query_id': traj.get('query_id', 'N/A'),
                'query_text': traj.get('current_question', 'N/A')[:200],
                'answer': traj.get('current_answer', 'N/A')[:200],
                'minimal_keywords': keywords_str[:100],  # é™åˆ¶é•¿åº¦
                'generation_method': traj.get('generation_method', 'unknown'),
                'validation_passed': validation_passed,
                'processing_time_ms': traj.get('processing_time_ms', 0),
                'extension_type': traj.get('extension_type', 'N/A'),
                'tree_id': traj.get('tree_id', 'N/A'),
                'parent_question': traj.get('parent_question', 'N/A')[:100] if traj.get('parent_question') else 'N/A',
                'parent_answer': traj.get('parent_answer', 'N/A')[:100] if traj.get('parent_answer') else 'N/A',
                'circular_check': traj.get('circular_check_result', 'N/A'),
                'api_calls': traj.get('api_calls_count', 0)
            }
        except Exception as e:
            print(f"è§£æè½¨è¿¹è®°å½•å¤±è´¥: {e}")
            return None

    def _write_excel_sheets(self, parsed_data: Dict[str, Any], excel_path: Path):
        """å†™å…¥Excelå·¥ä½œè¡¨"""
        
        with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:
            
            # Sheet1: æ–‡æ¡£å¤„ç†æ•ˆç‡ç»Ÿè®¡
            self._write_efficiency_data(parsed_data['efficiency_data'], writer)
            
            # Sheet2: æ‰€æœ‰è¿‡ç¨‹ä¸­çš„é—®ç­”å¯¹
            self._write_all_process_qa(parsed_data['all_process_qa'], writer)
            
            # Sheet3: æ¨ç†è½¨è¿¹è®°å½•
            self._write_trajectories(parsed_data['trajectories'], writer)
            
            # Sheet4: ç³…åˆåçš„ç»¼åˆé—®ç­”ï¼ˆä¸‰æ ¼å¼+å…œåº•æ ‡è®°ï¼‰
            self._write_final_composite_qa(parsed_data['composite_qa'], writer)
        
        print(f"âœ… Excelæ–‡ä»¶å·²ç”Ÿæˆ: {excel_path}")

    def _write_efficiency_data(self, efficiency_data: List[Dict], writer):
        """å†™å…¥æ–‡æ¡£å¤„ç†æ•ˆç‡ç»Ÿè®¡"""
        if not efficiency_data:
            return
        
        df = pd.DataFrame(efficiency_data)
        df = df.reindex(columns=[
            'doc_id', 'processing_time', 'trees_generated', 
            'valid_composite_questions', 'invalid_composite_questions', 'success'
        ])
        
        # é‡å‘½ååˆ—
        df.columns = ['æ–‡æ¡£ID', 'å¤„ç†æ—¶é—´(ç§’)', 'ç”Ÿæˆæ¨ç†æ ‘æ•°', 'æœ‰æ•ˆç»¼åˆé—®é¢˜æ•°', 'æ— æ•ˆé—®é¢˜æ•°', 'å¤„ç†æˆåŠŸ']
        
        df.to_excel(writer, sheet_name='Sheet1-æ–‡æ¡£å¤„ç†æ•ˆç‡ç»Ÿè®¡', index=False)

    def _write_all_process_qa(self, all_process_qa: List[Dict], writer):
        """å†™å…¥æ‰€æœ‰è¿‡ç¨‹ä¸­çš„é—®ç­”å¯¹"""
        if not all_process_qa:
            return
        
        df = pd.DataFrame(all_process_qa)
        df = df.reindex(columns=[
            'doc_id', 'tree_id', 'node_id', 'layer', 'branch_type', 
            'question', 'answer', 'generation_method', 'validation_passed'
        ])
        
        # é‡å‘½ååˆ—
        df.columns = [
            'æ–‡æ¡£ID', 'æ¨ç†æ ‘ID', 'èŠ‚ç‚¹ID', 'å±‚çº§', 'åˆ†æ”¯ç±»å‹', 
            'é—®é¢˜', 'ç­”æ¡ˆ', 'ç”Ÿæˆæ–¹æ³•', 'éªŒè¯é€šè¿‡'
        ]
        
        df.to_excel(writer, sheet_name='Sheet2-æ‰€æœ‰è¿‡ç¨‹ä¸­çš„é—®ç­”å¯¹', index=False)

    def _write_trajectories(self, trajectories: List[Dict], writer):
        """å†™å…¥æ¨ç†è½¨è¿¹è®°å½•"""
        if not trajectories:
            return
        
        df = pd.DataFrame(trajectories)
        # æ›´æ–°åˆ—å®šä¹‰ä»¥åŒ¹é…æ–°çš„è½¨è¿¹è®°å½•å­—æ®µ
        available_columns = [col for col in [
            'doc_id', 'step', 'layer_level', 'query_id', 'query_text', 'answer', 
            'minimal_keywords', 'generation_method', 'validation_passed', 
            'processing_time_ms', 'extension_type', 'tree_id', 'parent_question', 
            'parent_answer', 'circular_check', 'api_calls'
        ] if col in df.columns]
        
        df = df.reindex(columns=available_columns)
        
        # åŠ¨æ€é‡å‘½ååˆ—ï¼Œä»¥åŒ¹é…å®é™…å¯ç”¨çš„åˆ—
        column_mapping = {
            'doc_id': 'æ–‡æ¡£ID',
            'step': 'æ­¥éª¤',
            'layer_level': 'å±‚çº§',
            'query_id': 'æŸ¥è¯¢ID',
            'query_text': 'æŸ¥è¯¢æ–‡æœ¬',
            'answer': 'ç­”æ¡ˆ',
            'minimal_keywords': 'æœ€å°å…³é”®è¯',
            'generation_method': 'ç”Ÿæˆæ–¹æ³•',
            'validation_passed': 'éªŒè¯é€šè¿‡',
            'processing_time_ms': 'å¤„ç†æ—¶é—´(ms)',
            'extension_type': 'æ‰©å±•ç±»å‹',
            'tree_id': 'æ¨ç†æ ‘ID',
            'parent_question': 'çˆ¶é—®é¢˜',
            'parent_answer': 'çˆ¶ç­”æ¡ˆ',
            'circular_check': 'å¾ªç¯æ£€æŸ¥',
            'api_calls': 'APIè°ƒç”¨æ¬¡æ•°'
        }
        
        # åªé‡å‘½åå­˜åœ¨çš„åˆ—
        new_column_names = [column_mapping.get(col, col) for col in df.columns]
        df.columns = new_column_names
        
        df.to_excel(writer, sheet_name='Sheet3-æ¨ç†è½¨è¿¹è®°å½•', index=False)

    def _write_final_composite_qa(self, composite_qa: List[Dict], writer):
        """å†™å…¥ç³…åˆåçš„ç»¼åˆé—®ç­”ï¼ˆä¸‰æ ¼å¼ï¼‰"""
        if not composite_qa:
            return
        
        # å‡†å¤‡æ•°æ®
        composite_data = []
        
        for idx, comp in enumerate(composite_qa):
            question_type = comp['question_type']
            status = "âœ… æœ‰æ•ˆ" if comp['is_valid'] else "âŒ æ— æ•ˆ"
            fallback_status = "ğŸ”„ å…œåº•" if comp.get('is_fallback', False) else "âœ… ç”Ÿäº§"
            
            composite_data.append({
                'åºå·': idx + 1,
                'æ–‡æ¡£ID': comp['doc_id'],
                'æ¨ç†æ ‘ID': comp['tree_id'],
                'é—®é¢˜ç±»å‹': question_type,
                'ç³…åˆé—®é¢˜': comp['composite_question'],
                'ç³…åˆç­”æ¡ˆ': comp['composite_answer'],
                'æœ€ç»ˆç­”æ¡ˆ': comp['target_answer'],
                'é—®é¢˜çŠ¶æ€': status,
                'ç”Ÿæˆæ–¹å¼': fallback_status,
                'é—®é¢˜é•¿åº¦': comp['question_length'],
                'æ ‘ç´¢å¼•': comp['tree_index']
            })
        
        df = pd.DataFrame(composite_data)
        
        # åº”ç”¨Excelæ ¼å¼åŒ–ï¼Œå…œåº•ç»“æœç”¨ä¸åŒé¢œè‰²æ ‡è®°
        df.to_excel(writer, sheet_name='Sheet4-ç³…åˆåçš„ç»¼åˆé—®ç­”', index=False)
        
        # è·å–å·¥ä½œè¡¨ä»¥åº”ç”¨æ ¼å¼åŒ–
        workbook = writer.book
        worksheet = writer.sheets['Sheet4-ç³…åˆåçš„ç»¼åˆé—®ç­”']
        
        # å¯¼å…¥openpyxlæ ·å¼
        from openpyxl.styles import PatternFill, Font
        
        # å®šä¹‰æ ·å¼
        fallback_fill = PatternFill(start_color='FFE6CC', end_color='FFE6CC', fill_type='solid')  # æ©™è‰²èƒŒæ™¯
        production_fill = PatternFill(start_color='E6F3E6', end_color='E6F3E6', fill_type='solid')  # ç»¿è‰²èƒŒæ™¯
        
        # åº”ç”¨æ¡ä»¶æ ¼å¼
        for row_idx, row in enumerate(df.itertuples(), start=2):  # ä»ç¬¬2è¡Œå¼€å§‹ï¼ˆè·³è¿‡è¡¨å¤´ï¼‰
            generation_method = row[9]  # 'ç”Ÿæˆæ–¹å¼'åˆ—
            if 'å…œåº•' in generation_method:
                # å¯¹æ•´è¡Œåº”ç”¨å…œåº•æ ·å¼
                for col_idx in range(1, len(df.columns) + 1):
                    cell = worksheet.cell(row=row_idx, column=col_idx)
                    cell.fill = fallback_fill
            elif 'ç”Ÿäº§' in generation_method:
                # å¯¹æ•´è¡Œåº”ç”¨ç”Ÿäº§æ ·å¼
                for col_idx in range(1, len(df.columns) + 1):
                    cell = worksheet.cell(row=row_idx, column=col_idx)
                    cell.fill = production_fill 