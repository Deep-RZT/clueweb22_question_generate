#!/usr/bin/env python3
"""
ä¿®å¤çš„Excelå¯¼å‡ºå™¨ - èƒ½å¤Ÿæ­£ç¡®è§£æJSONä¸­çš„æ¨ç†æ ‘æ•°æ®
"""

import json
import re
import pandas as pd
from pathlib import Path
from typing import Dict, List, Any, Optional
import logging

logger = logging.getLogger(__name__)

class FixedExcelExporter:
    """ä¿®å¤çš„Excelå¯¼å‡ºå™¨"""
    
    def __init__(self, output_dir: str = "results"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
    
    def export_from_json(self, json_file: Path) -> Optional[Path]:
        """ä»JSONæ–‡ä»¶å¯¼å‡ºExcel"""
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # è§£ææ•°æ®
            parsed_data = self._parse_agent_reasoning_data(data)
            
            # ç”ŸæˆExcelæ–‡ä»¶å
            excel_file = self.output_dir / f"fixed_{json_file.stem}.xlsx"
            
            # å¯¼å‡ºExcel
            with pd.ExcelWriter(excel_file, engine='openpyxl') as writer:
                self._write_summary_sheet(parsed_data, writer)
                self._write_reasoning_trees_sheet(parsed_data, writer)
                self._write_composite_queries_sheet(parsed_data, writer)
                self._write_trajectory_sheet(parsed_data, writer)
                self._write_raw_data_sheet(parsed_data, writer)
            
            logger.info(f"ä¿®å¤çš„Excelæ–‡ä»¶å·²ç”Ÿæˆ: {excel_file}")
            return excel_file
            
        except Exception as e:
            logger.error(f"å¯¼å‡ºExcelå¤±è´¥: {e}")
            return None
    
    def _parse_agent_reasoning_data(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """è§£æAgentæ¨ç†æ•°æ®"""
        parsed = {
            'session_info': {
                'session_id': data.get('session_id', 'N/A'),
                'mode': data.get('mode', 'N/A'),
                'success': data.get('success', False),
                'total_time': data.get('total_processing_time', 0),
                'total_docs': 0,
                'successful_docs': 0,
                'total_trees': 0,
                'total_queries': 0
            },
            'documents': [],
            'trees': [],
            'queries': [],
            'trajectories': []
        }
        
        # è§£æå¤„ç†ç»“æœ
        processing_results = data.get('processing_results', {})
        processed_docs = processing_results.get('processed_documents', [])
        
        parsed['session_info']['total_docs'] = len(processed_docs)
        
        # è§£ææ¯ä¸ªæ–‡æ¡£
        for doc in processed_docs:
            doc_id = doc.get('doc_id', 'Unknown')
            reasoning_trees = doc.get('reasoning_trees', [])
            trajectory_records = doc.get('trajectory_records', [])
            
            doc_info = {
                'doc_id': doc_id,
                'processing_time': doc.get('processing_time', 0),
                'total_trees': doc.get('total_trees', 0),
                'total_queries': doc.get('total_composite_queries', 0),
                'success': doc.get('total_trees', 0) > 0
            }
            parsed['documents'].append(doc_info)
            
            if doc_info['success']:
                parsed['session_info']['successful_docs'] += 1
            
            # è§£ææ¨ç†æ ‘
            for tree_str in reasoning_trees:
                if isinstance(tree_str, str):
                    tree_info = self._parse_tree_string(tree_str, doc_id)
                    if tree_info:
                        parsed['trees'].append(tree_info)
                        parsed['session_info']['total_trees'] += 1
                        
                        # æå–ç»¼åˆé—®é¢˜
                        if tree_info.get('final_composite_query'):
                            query_info = {
                                'doc_id': doc_id,
                                'tree_id': tree_info['tree_id'],
                                'composite_query': tree_info['final_composite_query'],
                                'root_question': tree_info['root_question'],
                                'root_answer': tree_info['root_answer'],
                                'max_layers': tree_info['max_layers'],
                                'node_count': tree_info['node_count']
                            }
                            parsed['queries'].append(query_info)
                            parsed['session_info']['total_queries'] += 1
            
            # è§£æè½¨è¿¹è®°å½•
            for traj in trajectory_records:
                if isinstance(traj, dict):
                    traj_info = {
                        'doc_id': doc_id,
                        'step': traj.get('step', 'N/A'),
                        'step_id': traj.get('step_id', 0),
                        'query_id': traj.get('query_id', 'N/A'),
                        'query_text': traj.get('query_text', 'N/A'),
                        'answer': traj.get('answer', 'N/A'),
                        'keyword_count': traj.get('keyword_count', 0),
                        'validation_passed': traj.get('validation_passed', False)
                    }
                    parsed['trajectories'].append(traj_info)
        
        return parsed
    
    def _parse_tree_string(self, tree_str: str, doc_id: str) -> Optional[Dict[str, Any]]:
        """è§£ææ¨ç†æ ‘å­—ç¬¦ä¸²"""
        try:
            # æå–tree_id
            tree_id_match = re.search(r"tree_id='([^']+)'", tree_str)
            tree_id = tree_id_match.group(1) if tree_id_match else 'Unknown'
            
            # æå–æ ¹é—®é¢˜ä¿¡æ¯
            root_question_match = re.search(r"query_text='([^']+)'", tree_str)
            root_question = root_question_match.group(1) if root_question_match else 'N/A'
            
            # æå–æ ¹ç­”æ¡ˆ
            answer_match = re.search(r"answer='([^']+)'", tree_str)
            root_answer = answer_match.group(1) if answer_match else 'N/A'
            
            # æå–æœ€å¤§å±‚æ•°
            max_layers_match = re.search(r"max_layers=(\d+)", tree_str)
            max_layers = int(max_layers_match.group(1)) if max_layers_match else 0
            
            # è®¡ç®—èŠ‚ç‚¹æ•°é‡
            node_count = len(re.findall(r"QuestionTreeNode\(", tree_str))
            
            # æå–ç»¼åˆé—®é¢˜
            composite_match = re.search(r"final_composite_query='([^']+)'", tree_str)
            composite_query = composite_match.group(1) if composite_match else 'Logical reasoning chain question requiring genuine step-by-step solving'
            
            # æå–å…³é”®è¯
            keywords = re.findall(r"keyword='([^']+)'", tree_str)
            
            return {
                'doc_id': doc_id,
                'tree_id': tree_id,
                'root_question': root_question,
                'root_answer': root_answer,
                'max_layers': max_layers,
                'node_count': node_count,
                'final_composite_query': composite_query,
                'keywords': keywords[:5],  # å‰5ä¸ªå…³é”®è¯
                'keyword_count': len(keywords)
            }
            
        except Exception as e:
            logger.warning(f"è§£ææ¨ç†æ ‘å­—ç¬¦ä¸²å¤±è´¥: {e}")
            return None
    
    def _write_summary_sheet(self, data: Dict[str, Any], writer):
        """å†™å…¥æ‘˜è¦è¡¨"""
        session_info = data['session_info']
        
        summary_data = [
            ['é¡¹ç›®', 'æ•°å€¼'],
            ['ä¼šè¯ID', session_info['session_id']],
            ['æ¨¡å¼', session_info['mode']],
            ['æˆåŠŸçŠ¶æ€', 'âœ…' if session_info['success'] else 'âŒ'],
            ['æ€»å¤„ç†æ—¶é—´(ç§’)', f"{session_info['total_time']:.1f}"],
            ['æ€»å¤„ç†æ—¶é—´(åˆ†é’Ÿ)', f"{session_info['total_time']/60:.1f}"],
            [''],
            ['æ–‡æ¡£ç»Ÿè®¡', ''],
            ['æ€»æ–‡æ¡£æ•°', session_info['total_docs']],
            ['æˆåŠŸæ–‡æ¡£æ•°', session_info['successful_docs']],
            ['å¤±è´¥æ–‡æ¡£æ•°', session_info['total_docs'] - session_info['successful_docs']],
            ['æˆåŠŸç‡', f"{session_info['successful_docs']/max(session_info['total_docs'], 1):.1%}"],
            [''],
            ['æ¨ç†æ ‘ç»Ÿè®¡', ''],
            ['æ€»æ¨ç†æ ‘æ•°', session_info['total_trees']],
            ['æ€»ç»¼åˆé—®é¢˜æ•°', session_info['total_queries']],
            ['å¹³å‡å¤„ç†æ—¶é—´/æ–‡æ¡£', f"{session_info['total_time']/max(session_info['total_docs'], 1):.1f}ç§’"],
            ['å¹³å‡æ¨ç†æ ‘/æ–‡æ¡£', f"{session_info['total_trees']/max(session_info['successful_docs'], 1):.1f}"]
        ]
        
        df = pd.DataFrame(summary_data)
        df.to_excel(writer, sheet_name='æ‘˜è¦', index=False, header=False)
    
    def _write_reasoning_trees_sheet(self, data: Dict[str, Any], writer):
        """å†™å…¥æ¨ç†æ ‘è¡¨"""
        if not data['trees']:
            return
        
        tree_data = []
        for tree in data['trees']:
            tree_data.append({
                'æ–‡æ¡£ID': tree['doc_id'],
                'æ¨ç†æ ‘ID': tree['tree_id'],
                'æ ¹é—®é¢˜': tree['root_question'][:100] + '...' if len(tree['root_question']) > 100 else tree['root_question'],
                'æ ¹ç­”æ¡ˆ': tree['root_answer'],
                'æœ€å¤§å±‚æ•°': tree['max_layers'],
                'èŠ‚ç‚¹æ•°é‡': tree['node_count'],
                'å…³é”®è¯æ•°é‡': tree['keyword_count'],
                'ä¸»è¦å…³é”®è¯': ', '.join(tree['keywords'][:3]),
                'ç»¼åˆé—®é¢˜': tree['final_composite_query'][:100] + '...' if len(tree['final_composite_query']) > 100 else tree['final_composite_query']
            })
        
        df = pd.DataFrame(tree_data)
        df.to_excel(writer, sheet_name='æ¨ç†æ ‘', index=False)
    
    def _write_composite_queries_sheet(self, data: Dict[str, Any], writer):
        """å†™å…¥ç»¼åˆé—®é¢˜è¡¨"""
        if not data['queries']:
            return
        
        query_data = []
        for query in data['queries']:
            query_data.append({
                'æ–‡æ¡£ID': query['doc_id'],
                'æ¨ç†æ ‘ID': query['tree_id'],
                'ç»¼åˆé—®é¢˜': query['composite_query'],
                'æ ¹é—®é¢˜': query['root_question'][:80] + '...' if len(query['root_question']) > 80 else query['root_question'],
                'æ ¹ç­”æ¡ˆ': query['root_answer'],
                'æ¨ç†å±‚æ•°': query['max_layers'],
                'èŠ‚ç‚¹æ•°é‡': query['node_count'],
                'é—®é¢˜é•¿åº¦': len(query['composite_query']),
                'å¤æ‚åº¦': 'é«˜' if query['max_layers'] >= 3 else 'ä¸­' if query['max_layers'] >= 2 else 'ä½'
            })
        
        df = pd.DataFrame(query_data)
        df.to_excel(writer, sheet_name='ç»¼åˆé—®é¢˜', index=False)
    
    def _write_trajectory_sheet(self, data: Dict[str, Any], writer):
        """å†™å…¥è½¨è¿¹è®°å½•è¡¨"""
        if not data['trajectories']:
            return
        
        traj_data = []
        for traj in data['trajectories']:
            traj_data.append({
                'æ–‡æ¡£ID': traj['doc_id'],
                'æ­¥éª¤ID': traj['step_id'],
                'æ­¥éª¤åç§°': traj['step'],
                'æŸ¥è¯¢ID': traj['query_id'],
                'é—®é¢˜': traj['query_text'][:100] + '...' if len(traj['query_text']) > 100 else traj['query_text'],
                'ç­”æ¡ˆ': traj['answer'],
                'å…³é”®è¯æ•°é‡': traj['keyword_count'],
                'éªŒè¯é€šè¿‡': 'âœ…' if traj['validation_passed'] else 'âŒ'
            })
        
        df = pd.DataFrame(traj_data)
        df.to_excel(writer, sheet_name='è½¨è¿¹è®°å½•', index=False)
    
    def _write_raw_data_sheet(self, data: Dict[str, Any], writer):
        """å†™å…¥åŸå§‹æ•°æ®ç»Ÿè®¡è¡¨"""
        doc_data = []
        for doc in data['documents']:
            doc_data.append({
                'æ–‡æ¡£ID': doc['doc_id'],
                'å¤„ç†æ—¶é—´(ç§’)': f"{doc['processing_time']:.1f}",
                'æ¨ç†æ ‘æ•°é‡': doc['total_trees'],
                'ç»¼åˆé—®é¢˜æ•°é‡': doc['total_queries'],
                'å¤„ç†çŠ¶æ€': 'âœ… æˆåŠŸ' if doc['success'] else 'âŒ å¤±è´¥'
            })
        
        df = pd.DataFrame(doc_data)
        df.to_excel(writer, sheet_name='æ–‡æ¡£æ˜ç»†', index=False)

def main():
    """ä¸»å‡½æ•° - ä¿®å¤ç°æœ‰çš„JSONæ–‡ä»¶"""
    results_dir = Path("results")
    
    # æŸ¥æ‰¾JSONæ–‡ä»¶
    json_files = list(results_dir.glob("agent_reasoning_production_*.json"))
    
    if not json_files:
        print("âŒ æœªæ‰¾åˆ°JSONæ–‡ä»¶")
        return
    
    exporter = FixedExcelExporter()
    
    for json_file in json_files:
        print(f"ğŸ”„ å¤„ç†æ–‡ä»¶: {json_file.name}")
        excel_file = exporter.export_from_json(json_file)
        
        if excel_file:
            print(f"âœ… Excelæ–‡ä»¶å·²ç”Ÿæˆ: {excel_file.name}")
        else:
            print(f"âŒ Excelç”Ÿæˆå¤±è´¥: {json_file.name}")

if __name__ == "__main__":
    main() 