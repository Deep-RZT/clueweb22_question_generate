#!/usr/bin/env python3
"""
Linguistic Deep Query Framework
åŸºäºè¯­è¨€å­¦+ç§‘å­¦åŒ–çš„Short Answer Deep Research Queryæ„å»ºæµç¨‹

å®ç°5ä¸ªå±‚çº§çš„é—®é¢˜æ·±åŒ–æµç¨‹ï¼š
å±‚çº§0ï¸âƒ£ï¼šåŸå§‹æ–‡æ¡£
å±‚çº§1ï¸âƒ£ï¼šåˆå§‹é—®é¢˜ä¸Short AnsweræŠ½å–
å±‚çº§2ï¸âƒ£åŠä¹‹åï¼šç³»åˆ—æ·±åŒ–ä¸å¹¶è¡Œæ‰©å±•ï¼ˆåŸºäºå…³é”®è¯æ›¿æ¢ï¼‰

æ ¸å¿ƒæ€æƒ³ï¼šé€šè¿‡æœç´¢è·å¾—çš„æè¿°æ¥æ›¿æ¢é—®é¢˜ä¸­çš„å…³é”®è¯ï¼Œä½¿é—®é¢˜æ›´åŠ æŠ½è±¡å’Œé—´æ¥
"""

import logging
import json
import time
import re
from typing import List, Dict, Optional, Any, Tuple
from dataclasses import dataclass
from enum import Enum

logger = logging.getLogger(__name__)

# Integrated prompt templates from complete_prompt_template_system.py
class IntegratedPromptTemplates:
    """é›†æˆçš„æç¤ºè¯æ¨¡æ¿ç³»ç»Ÿ"""
    
    @staticmethod
    def get_prompt_1_short_answer_extraction(text_content: str) -> str:
        """Prompt-1: Short Answer Extraction & Initial Question Generation"""
        return f"""**Given the following text snippet:**
ã€TEXT_CONTENTã€‘
{text_content[:2000]}

**Task:**
1. Extract **3 clear and unique Short Answers** (proper nouns or numbers) from the text.
2. For each Short Answer, construct a **clear question**.

**Requirements:**
* Each question must contain at least **two explicit keywords** to ensure the Short Answer is precise, unique, and requires no ambiguous interpretation.
* All extracted keywords must be **highly specific** (e.g., proper nouns, numbers, technical terms), **distinctive**, and **unique** (not repeated).
* The query must be based on the original document (requiring a web search, not answerable by common sense) and have only one correct, solvable answer.

**Output Format:**
Question 1: [Generated question with at least 2 explicit keywords]
Answer 1: [Specific proper noun, number, or technical term]

Question 2: [Generated question with at least 2 explicit keywords]  
Answer 2: [Specific proper noun, number, or technical term]

Question 3: [Generated question with at least 2 explicit keywords]
Answer 3: [Specific proper noun, number, or technical term]"""
    
    @staticmethod
    def get_prompt_2_keyword_extraction_replacement(question_previous_level: str, answer_unchanged: str) -> str:
        """Prompt-2: Keyword Extraction & Replacement Descriptions"""
        return f"""**Given the following question and its Short Answer from the previous level:**
ã€QUESTION_PREVIOUS_LEVELã€‘
{question_previous_level}

ã€ANSWER_UNCHANGEDã€‘  
{answer_unchanged}

**Task:**
1. From the ã€QUESTION_PREVIOUS_LEVELã€‘, extract all **minimal keywords** (typically nouns or numbers) sufficient to uniquely identify the ã€ANSWER_UNCHANGEDã€‘.
2. For each extracted keyword, simulate a **search operation**. From the *search results*, identify and extract a **new, more indirect or abstract descriptive phrase** to replace the original keyword.

**Output Format:**
Keywords Extracted:
- Keyword 1: [Extracted Keyword 1]
- Keyword 2: [Extracted Keyword 2]

Replacement Descriptions (from search results):
- [Extracted Keyword 1] â†’ [New, more indirect/abstract description 1]
- [Extracted Keyword 2] â†’ [New, more indirect/abstract description 2]"""
    
    @staticmethod
    def get_prompt_3_new_question_generation_validation(question_previous_level: str, target_keyword: str, keyword_replacements: List[Dict[str, str]]) -> str:
        """Prompt-3: New Question Generation & Validation - ğŸ”¥ ä¿®æ­£ï¼šç­”æ¡ˆæ˜¯ç›®æ ‡å…³é”®è¯"""
        replacements_text = "\n".join([
            f"- {kr['original']} â†’ {kr['replacement']}"
            for kr in keyword_replacements
        ])
        
        return f"""**Based on the provided keyword replacement descriptions, construct a new, more challenging question:**

**Original Question:** {question_previous_level}
**Target Answer (First Keyword):** {target_keyword}

**Keyword Replacement Descriptions:**
{replacements_text}

**CRITICAL REQUIREMENT:**
The new question must have "{target_keyword}" as its ONLY correct answer. This follows the workflow requirement that extension questions' answers are keywords from the root query.

**Task:**
1. Construct a **New Question** by replacing the original keywords with their respective replacement descriptions.
2. Ensure the new question naturally leads to "{target_keyword}" as the answer.
3. **Validate** the New Question against all criteria.

**Output Format:**
New Question: [Constructed question using replacement descriptions that answers to "{target_keyword}"]

**Validation Results:**
âœ“ Answer Consistency: Pass/Fail - [Does the question lead to "{target_keyword}" as answer?]
âœ“ Keyword Uniqueness: Pass/Fail - [Are the replacement descriptions unique enough?]  
âœ“ Inference Depth (â‰¤2 hops): Pass/Fail - [Reasoning]
âœ“ No Cyclic/Shallow Exposure: Pass/Fail - [Reasoning]

**Overall Validation Conclusion:** Pass/Fail"""

class ExpansionType(Enum):
    """æ‰©å±•ç±»å‹"""
    SERIES = "series"      # ç³»åˆ—æ·±åŒ–ï¼šå¯¹åŒä¸€å…³é”®è¯ç»§ç»­æ·±åŒ–
    PARALLEL = "parallel"  # å¹¶è¡Œæ‰©å±•ï¼šå¯¹å¤šä¸ªå…³é”®è¯åŒæ—¶æ‰©å±•

@dataclass
class ShortAnswer:
    """çŸ­ç­”æ¡ˆæ•°æ®ç»“æ„"""
    answer_text: str
    answer_type: str  # noun, number, name, date, location
    confidence: float
    extraction_source: str  # ä»æ–‡æ¡£ä¸­çš„å“ªé‡Œæå–çš„

@dataclass
class KeywordReplacement:
    """å…³é”®è¯æ›¿æ¢è®°å½•"""
    original_keyword: str
    replacement_description: str
    search_query: str
    search_results: List[str]
    uniqueness_verified: bool
    confidence: float

@dataclass
class LinguisticQuestion:
    """è¯­è¨€å­¦é—®é¢˜ç»“æ„"""
    question_text: str
    answer: str
    level: int
    keywords: List[str]
    keyword_replacements: List[KeywordReplacement]
    validation_passed: bool
    max_hops_required: int
    parent_question_id: Optional[str] = None
    question_id: str = ""

@dataclass
class HopTrajectory:
    """æ¯ä¸€æ­¥hopçš„è½¨è¿¹è®°å½•"""
    level: int
    original_question: str
    original_answer: str
    keyword_replacements: List[KeywordReplacement]
    new_question: str
    validation_passed: bool
    verification_details: Dict[str, Any]
    hop_success: bool
    processing_time: float

class LinguisticDeepQueryFramework:
    """è¯­è¨€å­¦æ·±åº¦æŸ¥è¯¢æ¡†æ¶"""
    
    def __init__(self, api_client=None, search_client=None):
        self.api_client = api_client
        self.search_client = search_client
        self.max_levels = 5
        self.max_hops_allowed = 2
        self.trajectory_history: List[HopTrajectory] = []
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'documents_processed': 0,
            'short_answers_extracted': 0,
            'questions_generated': 0,
            'successful_hops': 0,
            'failed_hops': 0,
            'validation_passed': 0,
            'validation_failed': 0,
            'series_extensions': 0,
            'parallel_extensions': 0
        }
    
    def set_api_client(self, api_client):
        """è®¾ç½®APIå®¢æˆ·ç«¯"""
        self.api_client = api_client
    
    def set_search_client(self, search_client):
        """è®¾ç½®æœç´¢å®¢æˆ·ç«¯"""
        self.search_client = search_client
    
    def process_document_with_linguistic_depth(self, document_content: str, document_id: str) -> Dict[str, Any]:
        """
        ä½¿ç”¨è¯­è¨€å­¦æ·±åº¦æ¡†æ¶å¤„ç†æ–‡æ¡£
        
        Args:
            document_content: åŸå§‹æ–‡æ¡£å†…å®¹
            document_id: æ–‡æ¡£ID
            
        Returns:
            å®Œæ•´çš„å¤„ç†ç»“æœï¼ŒåŒ…å«æ‰€æœ‰å±‚çº§çš„é—®é¢˜
        """
        logger.info(f"å¼€å§‹è¯­è¨€å­¦æ·±åº¦å¤„ç†æ–‡æ¡£: {document_id}")
        start_time = time.time()
        
        try:
            # å±‚çº§0ï¸âƒ£ï¼šåŸå§‹æ–‡æ¡£ï¼ˆå·²æä¾›ï¼‰
            
            # å±‚çº§1ï¸âƒ£ï¼šåˆå§‹é—®é¢˜ä¸Short AnsweræŠ½å–
            short_answers = self._extract_short_answers(document_content)
            if not short_answers:
                logger.warning(f"æœªèƒ½ä»æ–‡æ¡£ {document_id} ä¸­æå–åˆ°Short Answer")
                return self._create_empty_result(document_id, "No short answers extracted")
            
            initial_questions = self._generate_initial_questions(short_answers, document_content)
            if not initial_questions:
                logger.warning(f"æœªèƒ½ä¸ºæ–‡æ¡£ {document_id} ç”Ÿæˆåˆå§‹é—®é¢˜")
                return self._create_empty_result(document_id, "No initial questions generated")
            
            # å±‚çº§2ï¸âƒ£åŠä¹‹åï¼šç³»åˆ—æ·±åŒ–ä¸å¹¶è¡Œæ‰©å±•
            all_questions = {}
            all_trajectories = []
            
            # ä¸ºæ¯ä¸ªåˆå§‹é—®é¢˜æ„å»ºæ·±åŒ–é“¾
            for i, initial_q in enumerate(initial_questions):
                question_chain, trajectories = self._build_question_chain(initial_q, document_content, max_depth=self.max_levels-1)
                all_questions[f"chain_{i}"] = question_chain
                all_trajectories.extend(trajectories)
            
            # è®¡ç®—å¤„ç†æ—¶é—´
            processing_time = time.time() - start_time
            
            # ğŸ”¥ æ–°å¢ï¼šç”ŸæˆTree Level Queryæ•´åˆé—®é¢˜
            tree_level_query = None
            if all_questions and self.api_client:  # å¦‚æœæœ‰é—®é¢˜é“¾å¹¶ä¸”æœ‰APIå®¢æˆ·ç«¯ï¼Œå°è¯•ç”Ÿæˆæ•´åˆé—®é¢˜
                # å‡†å¤‡é—®é¢˜æ ‘æ•°æ®ç”¨äºæ•´åˆ
                tree_data = self._prepare_tree_data_for_integration(all_questions, short_answers, document_id)
                
                # ä½¿ç”¨TreeLevelQueryIntegratorç”Ÿæˆæ•´åˆé—®é¢˜
                from tree_level_query_integrator import TreeLevelQueryIntegrator
                tree_integrator = TreeLevelQueryIntegrator(api_client=self.api_client)
                
                tree_level_query = tree_integrator.generate_tree_level_query(
                    tree_data, integration_strategy='keyword_replacement'  # é€‚åˆè¯­è¨€å­¦æ¨¡å¼
                )
                
                if tree_level_query:
                    logger.info(f"ğŸ¯ è¯­è¨€å­¦æ¨¡å¼ç”ŸæˆTree Level Query: {tree_level_query.integrated_question[:60]}...")
                else:
                    logger.warning("è¯­è¨€å­¦æ¨¡å¼Tree Level Queryç”Ÿæˆå¤±è´¥")

            # æ„å»ºç»“æœ
            result = {
                'success': True,
                'document_id': document_id,
                'processing_time': processing_time,
                'short_answers': [self._serialize_short_answer(sa) for sa in short_answers],
                'initial_questions': [self._serialize_question(q) for q in initial_questions],
                'question_chains': all_questions,
                'trajectories': [self._serialize_trajectory(t) for t in all_trajectories],
                'tree_level_query': self._serialize_tree_level_query(tree_level_query) if tree_level_query else None,  # ğŸ”¥ æ–°å¢
                'statistics': {
                    'total_questions': sum(len(chain) for chain in all_questions.values()),
                    'total_levels': max(len(chain) for chain in all_questions.values()) if all_questions else 0,
                    'successful_hops': len([t for t in all_trajectories if t.hop_success]),
                    'validation_pass_rate': len([t for t in all_trajectories if t.validation_passed]) / max(len(all_trajectories), 1),
                    'tree_level_query_generated': tree_level_query is not None  # ğŸ”¥ æ–°å¢ç»Ÿè®¡
                },
                'framework_version': '1.0_linguistic'
            }
            
            self.stats['documents_processed'] += 1
            logger.info(f"è¯­è¨€å­¦æ·±åº¦å¤„ç†å®Œæˆ: {document_id}, è€—æ—¶: {processing_time:.2f}s")
            
            return result
            
        except Exception as e:
            logger.error(f"è¯­è¨€å­¦æ·±åº¦å¤„ç†å¤±è´¥ {document_id}: {e}")
            return self._create_empty_result(document_id, str(e))
    
    def _extract_short_answers(self, document_content: str) -> List[ShortAnswer]:
        """
        å±‚çº§1ï¸âƒ£ï¼šä»æ–‡æ¡£ä¸­æå–Short Answer
        å®ç°Prompt-1çš„é€»è¾‘ - ä½¿ç”¨IntegratedPromptTemplates
        """
        if not self.api_client:
            logger.error("éœ€è¦APIå®¢æˆ·ç«¯æ¥æå–Short Answer")
            return []
        
        try:
            # ğŸ”¥ ä½¿ç”¨IntegratedPromptTemplatesçš„Prompt-1
            prompt = IntegratedPromptTemplates.get_prompt_1_short_answer_extraction(document_content)

            response = self.api_client.generate_response(
                prompt=prompt,
                temperature=0.3,
                max_tokens=800
            )
            
            # è§£æå“åº”
            parsed_data = self._parse_json_response(response)
            if not parsed_data or 'short_answers' not in parsed_data:
                logger.warning("æ— æ³•è§£æShort Answerå“åº”")
                return []
            
            short_answers = []
            for sa_data in parsed_data['short_answers'][:3]:  # é™åˆ¶æœ€å¤š3ä¸ª
                short_answer = ShortAnswer(
                    answer_text=sa_data.get('answer', ''),
                    answer_type=sa_data.get('answer_type', 'unknown'),
                    confidence=sa_data.get('confidence', 0.5),
                    extraction_source=document_content[:200]
                )
                short_answers.append(short_answer)
            
            self.stats['short_answers_extracted'] += len(short_answers)
            logger.info(f"æå–åˆ° {len(short_answers)} ä¸ªShort Answer")
            
            return short_answers
            
        except Exception as e:
            logger.error(f"æå–Short Answerå¤±è´¥: {e}")
            return []
    
    def _generate_initial_questions(self, short_answers: List[ShortAnswer], document_content: str) -> List[LinguisticQuestion]:
        """ç”Ÿæˆåˆå§‹é—®é¢˜ï¼ˆå±‚çº§1ï¸âƒ£ï¼‰"""
        if not self.api_client:
            return []
        
        try:
            questions = []
            
            for i, sa in enumerate(short_answers):
                # Promptè¯´æ˜: åŸºäºShort Answerç”Ÿæˆæ˜ç¡®é—®é¢˜ï¼ŒåŒ…å«å¾ªç¯é¢„é˜²é€»è¾‘
                base_prompt = f"""Based on the following Short Answer, generate a clear and specific question:

Short Answer: {sa.answer_text}
Answer Type: {sa.answer_type}
Document Context: {document_content[:1000]}

Requirements:
1. The question must contain at least two explicit keywords
2. The question must uniquely determine the answer
3. The question should be objective and verifiable
4. Avoid subjective or "how" type questions

ğŸ”„ CIRCULAR PREVENTION REQUIREMENTS:
- AVOID time-based questions if answer contains dates/years
- AVOID entity property questions if answer is an entity name
- AVOID direct "who/what/when" questions that simply reverse the statement
- USE indirect, contextual descriptions instead of direct terms

GOOD EXAMPLES:
- Instead of "When was X launched?" â†’ "What milestone occurred in the year of technological breakthrough?"
- Instead of "Which company developed Y?" â†’ "What organization pioneered the revolutionary Z technology?"
- Instead of "Who invented A?" â†’ "Which innovator contributed to the field of B?"

OUTPUT REQUIREMENTS:
- Question must be indirect and require reasoning
- Question must avoid obvious circular patterns
- Question must use descriptive/contextual language

è¾“å‡ºæ ¼å¼ï¼ˆJSONï¼‰ï¼š
{{
    "question": "ç”Ÿæˆçš„é—®é¢˜",
    "keywords": ["å…³é”®è¯1", "å…³é”®è¯2", "å…³é”®è¯3"],
    "confidence": 0.0-1.0
}}"""

                response = self.api_client.generate_response(
                    prompt=base_prompt,
                    temperature=0.4,
                    max_tokens=300
                )
                
                parsed = self._parse_json_response(response)
                if parsed and 'question' in parsed:
                    question = LinguisticQuestion(
                        question_text=parsed['question'],
                        answer=sa.answer_text,
                        level=1,
                        keywords=parsed.get('keywords', []),
                        keyword_replacements=[],
                        validation_passed=True,  # åˆå§‹é—®é¢˜é»˜è®¤é€šè¿‡
                        max_hops_required=1,
                        question_id=f"q1_{i}"
                    )
                    questions.append(question)
            
            self.stats['questions_generated'] += len(questions)
            logger.info(f"ç”Ÿæˆ {len(questions)} ä¸ªåˆå§‹é—®é¢˜")
            
            return questions
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆåˆå§‹é—®é¢˜å¤±è´¥: {e}")
            return []
    
    def _build_question_chain(self, initial_question: LinguisticQuestion, document_content: str, max_depth: int) -> Tuple[List[LinguisticQuestion], List[HopTrajectory]]:
        """
        æ„å»ºé—®é¢˜é“¾ï¼šä»åˆå§‹é—®é¢˜å¼€å§‹ï¼Œé€å±‚æ·±åŒ–
        å®ç°å±‚çº§2ï¸âƒ£åŠä¹‹åçš„é€»è¾‘ï¼Œæ”¯æŒSerieså’ŒParallelæ‰©å±•
        """
        question_chain = [initial_question]
        trajectories = []
        current_questions = [initial_question]  # æ”¯æŒå¹¶è¡Œæ‰©å±•çš„å¤šä¸ªé—®é¢˜
        
        for depth in range(2, max_depth + 1):
            logger.info(f"æ„å»ºæ·±åº¦ {depth} çš„é—®é¢˜")
            
            # ğŸ”¥ å†³å®šæ‰©å±•ç±»å‹ï¼šSeries vs Parallel
            extension_type = self._choose_extension_type(depth, len(current_questions))
            
            if extension_type == ExpansionType.SERIES:
                # Seriesæ‰©å±•ï¼šå¯¹å½“å‰æœ€åä¸€ä¸ªé—®é¢˜è¿›è¡Œæ·±åŒ–
                logger.info(f"æ‰§è¡ŒSeriesæ‰©å±• (æ·±åº¦ {depth})")
                new_question, trajectory = self._perform_linguistic_hop(current_questions[-1], depth, document_content)
                
                trajectories.append(trajectory)
                
                if trajectory.hop_success and new_question:
                    question_chain.append(new_question)
                    current_questions = [new_question]  # Series: åªä¿ç•™æœ€æ–°é—®é¢˜
                    self.stats['successful_hops'] += 1
                    self.stats['series_extensions'] += 1
                else:
                    logger.info(f"Seriesæ‰©å±•å¤±è´¥ï¼Œåœæ­¢æ„å»ºé“¾")
                    self.stats['failed_hops'] += 1
                    break
            
            elif extension_type == ExpansionType.PARALLEL:
                # Parallelæ‰©å±•ï¼šä¸ºæ¯ä¸ªå½“å‰é—®é¢˜ç”Ÿæˆå¹¶è¡Œé—®é¢˜
                logger.info(f"æ‰§è¡ŒParallelæ‰©å±• (æ·±åº¦ {depth})")
                parallel_questions = []
                
                for i, current_q in enumerate(current_questions[:2]):  # é™åˆ¶æœ€å¤š2ä¸ªå¹¶è¡Œ
                    new_question, trajectory = self._perform_linguistic_hop(current_q, depth, document_content)
                    trajectories.append(trajectory)
                    
                    if trajectory.hop_success and new_question:
                        # ä¸ºå¹¶è¡Œé—®é¢˜æ·»åŠ æ ‡è¯†
                        new_question.question_id = f"{new_question.question_id}_parallel_{i}"
                        parallel_questions.append(new_question)
                        question_chain.append(new_question)
                        self.stats['successful_hops'] += 1
                        self.stats['parallel_extensions'] += 1
                    else:
                        self.stats['failed_hops'] += 1
                
                if parallel_questions:
                    current_questions = parallel_questions  # Parallel: ä¿ç•™æ‰€æœ‰å¹¶è¡Œé—®é¢˜
                else:
                    logger.info(f"Parallelæ‰©å±•å¤±è´¥ï¼Œåœæ­¢æ„å»ºé“¾")
                    break
        
        return question_chain, trajectories
    
    def _choose_extension_type(self, depth: int, current_questions_count: int) -> ExpansionType:
        """
        é€‰æ‹©æ‰©å±•ç±»å‹ï¼šSeries vs Parallel
        
        Args:
            depth: å½“å‰æ·±åº¦
            current_questions_count: å½“å‰é—®é¢˜æ•°é‡
            
        Returns:
            é€‰æ‹©çš„æ‰©å±•ç±»å‹
        """
        # ğŸ”¥ æ‰©å±•ç±»å‹é€‰æ‹©ç­–ç•¥
        
        # 1. å¦‚æœå·²æœ‰å¤šä¸ªå¹¶è¡Œé—®é¢˜ï¼Œä¼˜å…ˆSeriesæ·±åŒ–
        if current_questions_count > 1:
            logger.info(f"å·²æœ‰ {current_questions_count} ä¸ªå¹¶è¡Œé—®é¢˜ï¼Œé€‰æ‹©Seriesæ·±åŒ–")
            return ExpansionType.SERIES
        
        # 2. å¥‡æ•°æ·±åº¦å€¾å‘äºParallelï¼Œå¶æ•°æ·±åº¦å€¾å‘äºSeries
        if depth % 2 == 1:  # å¥‡æ•°æ·±åº¦ï¼šå°è¯•Parallelæ‰©å±•
            logger.info(f"æ·±åº¦ {depth} (å¥‡æ•°)ï¼Œé€‰æ‹©Parallelæ‰©å±•")
            return ExpansionType.PARALLEL
        else:  # å¶æ•°æ·±åº¦ï¼šSeriesæ·±åŒ–
            logger.info(f"æ·±åº¦ {depth} (å¶æ•°)ï¼Œé€‰æ‹©Seriesæ‰©å±•")
            return ExpansionType.SERIES
    
    def _perform_linguistic_hop(self, current_question: LinguisticQuestion, target_level: int, document_content: str) -> Tuple[Optional[LinguisticQuestion], HopTrajectory]:
        """
        æ‰§è¡Œä¸€æ¬¡è¯­è¨€å­¦hopï¼šå…³é”®è¯æå–ã€æœç´¢æ›¿æ¢ã€æ–°é—®é¢˜ç”Ÿæˆ
        å®ç°Prompt-2å’ŒPrompt-3çš„é€»è¾‘
        """
        start_time = time.time()
        hop_trajectory = HopTrajectory(
            level=target_level,
            original_question=current_question.question_text,
            original_answer=current_question.answer,
            keyword_replacements=[],
            new_question="",
            validation_passed=False,
            verification_details={},
            hop_success=False,
            processing_time=0.0
        )
        
        try:
            # æ­¥éª¤1ï¼šæå–å…³é”®è¯
            keywords = self._extract_keywords_from_question(current_question.question_text)
            if not keywords:
                hop_trajectory.verification_details['error'] = "No keywords extracted"
                hop_trajectory.processing_time = time.time() - start_time
                return None, hop_trajectory
            
            # æ­¥éª¤2ï¼šä¸ºæ¯ä¸ªå…³é”®è¯ç”Ÿæˆæ›¿æ¢æè¿°
            keyword_replacements = []
            for keyword in keywords[:3]:  # é™åˆ¶æœ€å¤š3ä¸ªå…³é”®è¯
                replacement = self._generate_keyword_replacement(keyword, current_question.answer)
                if replacement:
                    keyword_replacements.append(replacement)
            
            if not keyword_replacements:
                hop_trajectory.verification_details['error'] = "No keyword replacements generated"
                hop_trajectory.processing_time = time.time() - start_time
                return None, hop_trajectory
            
            hop_trajectory.keyword_replacements = keyword_replacements
            
            # æ­¥éª¤3ï¼šç”Ÿæˆæ–°é—®é¢˜
            new_question_text = self._generate_new_question_with_replacements(
                current_question.question_text, 
                keyword_replacements
            )
            
            if not new_question_text:
                hop_trajectory.verification_details['error'] = "Failed to generate new question"
                hop_trajectory.processing_time = time.time() - start_time
                return None, hop_trajectory
            
            # æ­¥éª¤4ï¼šéªŒè¯æ–°é—®é¢˜
            # ğŸ”¥ å…³é”®ä¿®æ­£ï¼šéªŒè¯æ—¶ä½¿ç”¨ç›®æ ‡å…³é”®è¯ä½œä¸ºç­”æ¡ˆ
            target_keyword = keyword_replacements[0].original_keyword if keyword_replacements else current_question.answer
            validation_result = self._validate_new_question(
                original_question=current_question.question_text,
                new_question=new_question_text,
                answer=target_keyword,  # ğŸ”¥ ä½¿ç”¨ç›®æ ‡å…³é”®è¯
                keyword_replacements=keyword_replacements
            )
            
            hop_trajectory.new_question = new_question_text
            hop_trajectory.validation_passed = validation_result['passed']
            hop_trajectory.verification_details = validation_result
            
            if validation_result['passed']:
                # ğŸ”¥ å…³é”®ä¿®æ­£ï¼šæ–°é—®é¢˜çš„ç­”æ¡ˆæ˜¯è¢«æ›¿æ¢çš„å…³é”®è¯ï¼Œè€Œä¸æ˜¯åŸå§‹ç­”æ¡ˆ
                # é€‰æ‹©ç¬¬ä¸€ä¸ªéªŒè¯é€šè¿‡çš„å…³é”®è¯ä½œä¸ºæ–°é—®é¢˜çš„ç­”æ¡ˆ
                target_keyword = keyword_replacements[0].original_keyword if keyword_replacements else current_question.answer
                
                # åˆ›å»ºæ–°é—®é¢˜å¯¹è±¡
                new_question = LinguisticQuestion(
                    question_text=new_question_text,
                    answer=target_keyword,  # ğŸ”¥ ç­”æ¡ˆå˜æˆå…³é”®è¯ï¼
                    level=target_level,
                    keywords=[kr.original_keyword for kr in keyword_replacements],
                    keyword_replacements=keyword_replacements,
                    validation_passed=True,
                    max_hops_required=min(current_question.max_hops_required + 1, self.max_hops_allowed),
                    parent_question_id=current_question.question_id,
                    question_id=f"q{target_level}_{int(time.time() % 10000)}"
                )
                
                hop_trajectory.hop_success = True
                self.stats['validation_passed'] += 1
                
                hop_trajectory.processing_time = time.time() - start_time
                return new_question, hop_trajectory
            else:
                self.stats['validation_failed'] += 1
                hop_trajectory.processing_time = time.time() - start_time
                return None, hop_trajectory
                
        except Exception as e:
            logger.error(f"æ‰§è¡Œlinguistic hopå¤±è´¥: {e}")
            hop_trajectory.verification_details['error'] = str(e)
            hop_trajectory.processing_time = time.time() - start_time
            return None, hop_trajectory
    
    def _extract_keywords_from_question(self, question: str) -> List[str]:
        """
        ä»é—®é¢˜ä¸­æå–å…³é”®è¯
        å®ç°Prompt-2çš„æ­¥éª¤1
        """
        if not self.api_client:
            return []
        
        try:
            # ğŸ”¥ ä½¿ç”¨IntegratedPromptTemplatesçš„å…³é”®è¯æå–é€»è¾‘
            prompt = f"""From the following question, extract all **minimal keywords** (typically nouns or numbers) that are meaningful for replacement:

Question: {question}

Requirements:
1. Extract specific, meaningful keywords
2. Focus on **proper nouns**, **numbers**, **technical terms**, **dates**
3. Each keyword must be **independently meaningful**
4. Avoid generic terms like "system", "method", "approach"
5. Prefer single-word or short-phrase keywords (1-3 words)

Output Format (JSON):
{{
    "keywords": ["keyword1", "keyword2", "keyword3"]
}}"""

            response = self.api_client.generate_response(
                prompt=prompt,
                temperature=0.2,
                max_tokens=200
            )
            
            parsed = self._parse_json_response(response)
            if parsed and 'keywords' in parsed:
                return parsed['keywords'][:5]  # é™åˆ¶æœ€å¤š5ä¸ªå…³é”®è¯
            
            return []
            
        except Exception as e:
            logger.error(f"æå–å…³é”®è¯å¤±è´¥: {e}")
            return []
    
    def _generate_keyword_replacement(self, keyword: str, original_answer: str) -> Optional[KeywordReplacement]:
        """
        ä¸ºå…³é”®è¯ç”Ÿæˆæ›¿æ¢æè¿°
        å®ç°Prompt-2çš„æ­¥éª¤2
        """
        if not self.api_client or not self.search_client:
            return None
        
        try:
            # æ‰§è¡Œæœç´¢
            search_query = f"{keyword} definition characteristics"
            search_results = self.search_client(search_query)
            
            if not search_results or 'results' not in search_results:
                return None
            
            # ä»æœç´¢ç»“æœä¸­ç”Ÿæˆæ›¿æ¢æè¿°
            search_content = " ".join([result.get('content', '')[:200] for result in search_results['results'][:3]])
            
            # Promptè¯´æ˜: åŸºäºæœç´¢ç»“æœä¸ºå…³é”®è¯ç”ŸæˆæŠ½è±¡æ›¿æ¢æè¿°
            prompt = f"""Based on search results, generate a more abstract or indirect replacement description for the keyword:

Keyword: {keyword}
Original Answer: {original_answer}
Search Results: {search_content}

Requirements:
1. The replacement description must uniquely identify the original keyword
2. The description should be more abstract or indirect while maintaining accuracy
3. Avoid directly using the original keyword
4. Ensure the replaced question can still determine the original answer

Output Format (JSON):
{{
    "replacement_description": "Abstract replacement description",
    "uniqueness_confidence": 0.0-1.0,
    "reasoning": "Why this description uniquely identifies the original keyword"
}}"""

            response = self.api_client.generate_response(
                prompt=prompt,
                temperature=0.4,
                max_tokens=300
            )
            
            parsed = self._parse_json_response(response)
            if parsed and 'replacement_description' in parsed:
                return KeywordReplacement(
                    original_keyword=keyword,
                    replacement_description=parsed['replacement_description'],
                    search_query=search_query,
                    search_results=[r.get('content', '')[:100] for r in search_results['results'][:3]],
                    uniqueness_verified=parsed.get('uniqueness_confidence', 0.0) >= 0.7,
                    confidence=parsed.get('uniqueness_confidence', 0.5)
                )
            
            return None
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆå…³é”®è¯æ›¿æ¢å¤±è´¥ {keyword}: {e}")
            return None
    
    def _generate_new_question_with_replacements(self, original_question: str, keyword_replacements: List[KeywordReplacement]) -> Optional[str]:
        """
        åŸºäºå…³é”®è¯æ›¿æ¢ç”Ÿæˆæ–°é—®é¢˜
        å®ç°Prompt-3çš„é€»è¾‘
        """
        if not self.api_client:
            return None
        
        try:
            # ğŸ”¥ å…³é”®ä¿®æ­£ï¼šè·å–ç›®æ ‡å…³é”®è¯ï¼ˆç¬¬ä¸€ä¸ªå…³é”®è¯ä½œä¸ºæ–°é—®é¢˜çš„ç­”æ¡ˆï¼‰
            target_keyword = keyword_replacements[0].original_keyword if keyword_replacements else "unknown"
            
            # è½¬æ¢ä¸ºPrompt-3éœ€è¦çš„æ ¼å¼
            replacements_dict = [
                {'original': kr.original_keyword, 'replacement': kr.replacement_description}
                for kr in keyword_replacements
            ]
            
            # ğŸ”¥ ä½¿ç”¨ä¿®æ­£åçš„IntegratedPromptTemplatesçš„Prompt-3
            prompt = IntegratedPromptTemplates.get_prompt_3_new_question_generation_validation(
                original_question, target_keyword, replacements_dict
            )
            
            # ç®€åŒ–ä¸ºé—®é¢˜ç”Ÿæˆéƒ¨åˆ†
            prompt += f"""

**FOR THIS STEP - ONLY GENERATE THE NEW QUESTION:**
Output Format (JSON):
{{
    "new_question": "Constructed question that has '{target_keyword}' as the answer",
    "confidence": 0.0-1.0,
    "target_answer_confirmed": "{target_keyword}",
    "reasoning": "How the question was constructed to answer '{target_keyword}'"
}}"""

            response = self.api_client.generate_response(
                prompt=prompt,
                temperature=0.3,
                max_tokens=400
            )
            
            parsed = self._parse_json_response(response)
            if parsed and 'new_question' in parsed:
                return parsed['new_question']
            
            return None
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆæ–°é—®é¢˜å¤±è´¥: {e}")
            return None
    
    def _validate_new_question(self, original_question: str, new_question: str, answer: str, keyword_replacements: List[KeywordReplacement]) -> Dict[str, Any]:
        """
        éªŒè¯æ–°é—®é¢˜
        å®ç°Prompt-3çš„éªŒè¯é€»è¾‘
        """
        if not self.api_client:
            return {'passed': False, 'reason': 'No API client'}
        
        try:
            # ğŸ”¥ ä½¿ç”¨IntegratedPromptTemplatesçš„éªŒè¯é€»è¾‘
            prompt = f"""**Validate the following new question against all criteria:**

**Original Question:** {original_question}
**New Question:** {new_question}
**Answer:** {answer}

**CRITICAL VALIDATION CRITERIA:**

**1. Answer Consistency Check:**
* Does the new question still uniquely lead to the original answer ({answer})?
* Can someone answering this question arrive at exactly "{answer}" and nothing else?

**2. Keyword Uniqueness Check:**
* Do the replacement descriptions uniquely determine their original keywords through indirect inference?
* Can each replacement description be traced back to exactly one original keyword?

**3. Inference Depth Check (Max Hops â‰¤ 2):**
* Can the answer be determined within a maximum of two search/reasoning steps from the New Question?
* Is the question challenging but not impossibly indirect?

**4. No Cyclic/Shallow Exposure Check:**
* Does the New Question avoid cyclic descriptions or exposing shallow, original information?
* Is it genuinely deeper/more abstract than the original question?
* Does it avoid patterns like "A occurred in Year B" leading to "What year did A occur?"

**5. Shortcut Check:**
* Does the new question avoid containing keywords that could directly pinpoint other answers?

**Output Format (JSON):**
{{
    "answer_consistency": true/false,
    "keyword_uniqueness": true/false,
    "inference_depth": true/false,
    "no_cyclic_exposure": true/false,
    "shortcut_check": true/false,
    "overall_passed": true/false,
    "confidence": 0.0-1.0,
    "reasoning": "Detailed validation analysis"
}}"""

            response = self.api_client.generate_response(
                prompt=prompt,
                temperature=0.2,
                max_tokens=500
            )
            
            parsed = self._parse_json_response(response)
            if parsed:
                return {
                    'passed': parsed.get('overall_passed', False),
                    'answer_consistency': parsed.get('answer_consistency', False),
                    'keyword_uniqueness': parsed.get('keyword_uniqueness', False),
                    'inference_depth': parsed.get('inference_depth', False),
                    'no_cyclic_exposure': parsed.get('no_cyclic_exposure', False),
                    'shortcut_check': parsed.get('shortcut_check', False),
                    'confidence': parsed.get('confidence', 0.0),
                    'reasoning': parsed.get('reasoning', '')
                }
            
            return {'passed': False, 'reason': 'Failed to parse validation response'}
            
        except Exception as e:
            logger.error(f"éªŒè¯æ–°é—®é¢˜å¤±è´¥: {e}")
            return {'passed': False, 'reason': str(e)}
    
    def _parse_json_response(self, response: str) -> Optional[Dict[str, Any]]:
        """è§£æJSONå“åº”"""
        try:
            # æŸ¥æ‰¾JSONéƒ¨åˆ†
            json_start = response.find('{')
            json_end = response.rfind('}') + 1
            
            if json_start >= 0 and json_end > json_start:
                json_text = response[json_start:json_end]
                return json.loads(json_text)
            
            return None
            
        except Exception as e:
            logger.warning(f"è§£æJSONå“åº”å¤±è´¥: {e}")
            return None
    
    def _serialize_short_answer(self, sa: ShortAnswer) -> Dict[str, Any]:
        """åºåˆ—åŒ–ShortAnswer"""
        return {
            'answer_text': sa.answer_text,
            'answer_type': sa.answer_type,
            'confidence': sa.confidence,
            'extraction_source': sa.extraction_source[:100]
        }
    
    def _serialize_question(self, q: LinguisticQuestion) -> Dict[str, Any]:
        """åºåˆ—åŒ–LinguisticQuestion"""
        return {
            'question_id': q.question_id,
            'question_text': q.question_text,
            'answer': q.answer,
            'level': q.level,
            'keywords': q.keywords,
            'keyword_replacements': [self._serialize_replacement(kr) for kr in q.keyword_replacements],
            'validation_passed': q.validation_passed,
            'max_hops_required': q.max_hops_required,
            'parent_question_id': q.parent_question_id
        }
    
    def _serialize_replacement(self, kr: KeywordReplacement) -> Dict[str, Any]:
        """åºåˆ—åŒ–KeywordReplacement"""
        return {
            'original_keyword': kr.original_keyword,
            'replacement_description': kr.replacement_description,
            'search_query': kr.search_query,
            'uniqueness_verified': kr.uniqueness_verified,
            'confidence': kr.confidence
        }
    
    def _serialize_trajectory(self, trajectory: HopTrajectory) -> Dict[str, Any]:
        """åºåˆ—åŒ–HopTrajectory"""
        return {
            'level': trajectory.level,
            'original_question': trajectory.original_question,
            'original_answer': trajectory.original_answer,
            'keyword_replacements': [
                {
                    'original_keyword': kr.original_keyword,
                    'replacement_description': kr.replacement_description,
                    'search_query': kr.search_query,
                    'confidence': kr.confidence
                } for kr in trajectory.keyword_replacements
            ],
            'new_question': trajectory.new_question,
            'validation_passed': trajectory.validation_passed,
            'verification_details': trajectory.verification_details,
            'hop_success': trajectory.hop_success,
            'processing_time': trajectory.processing_time
        }
    
    def _prepare_tree_data_for_integration(self, all_questions: Dict[str, List[LinguisticQuestion]], 
                                         short_answers: List[ShortAnswer], document_id: str) -> Dict[str, Any]:
        """ä¸ºTree Level Queryæ•´åˆå‡†å¤‡æ•°æ®"""
        # è·å–ç¬¬ä¸€ä¸ªé“¾çš„æ ¹é—®é¢˜ä½œä¸ºä¸»è¦æ ¹é—®é¢˜
        first_chain = list(all_questions.values())[0] if all_questions else []
        if not first_chain:
            return {}
        
        root_question = first_chain[0]
        
        # æ„å»ºtree_dataæ ¼å¼
        tree_data = {
            'root_question': {
                'question': root_question.question_text,
                'answer': short_answers[0].answer_text if short_answers else root_question.answer,  # ä½¿ç”¨åŸå§‹çŸ­ç­”æ¡ˆ
                'keywords': root_question.keywords
            },
            'nodes': {}
        }
        
        # æ·»åŠ æ‰€æœ‰æ‰©å±•èŠ‚ç‚¹
        node_id_counter = 0
        for chain_id, question_chain in all_questions.items():
            for level, question in enumerate(question_chain[1:], 1):  # è·³è¿‡æ ¹é—®é¢˜
                node_id = f"linguistic_{chain_id}_{level}_{node_id_counter}"
                tree_data['nodes'][node_id] = {
                    'question': question.question_text,
                    'answer': question.answer,  # è¯­è¨€å­¦æ¨¡å¼ï¼šç­”æ¡ˆæ˜¯å…³é”®è¯
                    'depth_level': level,
                    'parent_node_id': 'root' if level == 1 else f"linguistic_{chain_id}_{level-1}_{node_id_counter-1}",
                    'keywords': question.keywords,
                    'extension_type': 'keyword_replacement'
                }
                node_id_counter += 1
        
        return tree_data
    
    def _serialize_tree_level_query(self, tree_level_query) -> Dict[str, Any]:
        """åºåˆ—åŒ–TreeLevelQuery"""
        if not tree_level_query:
            return None
        
        return {
            'integrated_question': tree_level_query.integrated_question,
            'root_answer': tree_level_query.root_answer,
            'integration_depth': tree_level_query.integration_depth,
            'component_questions': tree_level_query.component_questions,
            'reasoning_path': tree_level_query.reasoning_path,
            'confidence': tree_level_query.confidence,
            'complexity_score': tree_level_query.complexity_score,
            'metadata': tree_level_query.metadata
        }

    def _create_empty_result(self, document_id: str, reason: str) -> Dict[str, Any]:
        """åˆ›å»ºç©ºç»“æœ"""
        return {
            'success': False,
            'document_id': document_id,
            'error': reason,
            'short_answers': [],
            'initial_questions': [],
            'question_chains': {},
            'trajectories': [],
            'statistics': {},
            'framework_version': '1.0_linguistic'
        }
    
    def get_framework_statistics(self) -> Dict[str, Any]:
        """è·å–æ¡†æ¶ç»Ÿè®¡ä¿¡æ¯"""
        return {
            'framework_stats': self.stats.copy(),
            'trajectory_count': len(self.trajectory_history),
            'processing_summary': {
                'documents_processed': self.stats['documents_processed'],
                'success_rate': self.stats['successful_hops'] / max(self.stats['successful_hops'] + self.stats['failed_hops'], 1),
                'avg_questions_per_doc': self.stats['questions_generated'] / max(self.stats['documents_processed'], 1)
            }
        }
    
    def process_single_short_answer_with_linguistic_depth(self, document_content: str, document_id: str, 
                                                        short_answer_text: str, short_answer_type: str) -> Dict[str, Any]:
        """
        å¤„ç†å•ä¸ªçŸ­ç­”æ¡ˆçš„è¯­è¨€å­¦æ·±åº¦æŸ¥è¯¢ï¼ˆä¸ç»å…¸æ¨¡å¼ä¿æŒä¸€è‡´çš„å¤„ç†æ–¹å¼ï¼‰
        
        Args:
            document_content: åŸå§‹æ–‡æ¡£å†…å®¹
            document_id: æ–‡æ¡£ID  
            short_answer_text: çŸ­ç­”æ¡ˆæ–‡æœ¬
            short_answer_type: çŸ­ç­”æ¡ˆç±»å‹
            
        Returns:
            å®Œæ•´çš„å¤„ç†ç»“æœï¼Œé’ˆå¯¹å•ä¸ªçŸ­ç­”æ¡ˆçš„è¯­è¨€å­¦æ·±åŒ–
        """
        logger.info(f"å¼€å§‹è¯­è¨€å­¦æ·±åº¦å¤„ç†å•ä¸ªçŸ­ç­”æ¡ˆ: {document_id} - {short_answer_text}")
        start_time = time.time()
        
        try:
            # æ„å»ºShortAnswerå¯¹è±¡
            short_answer = ShortAnswer(
                answer_text=short_answer_text,
                answer_type=short_answer_type,
                confidence=1.0,
                extraction_source=document_content[:100]
            )
            
            # å±‚çº§1ï¸âƒ£ï¼šä¸ºè¿™ä¸ªçŸ­ç­”æ¡ˆç”Ÿæˆåˆå§‹é—®é¢˜
            initial_question = self._generate_single_initial_question(short_answer, document_content)
            if not initial_question:
                logger.warning(f"æœªèƒ½ä¸ºçŸ­ç­”æ¡ˆ {short_answer_text} ç”Ÿæˆåˆå§‹é—®é¢˜")
                return self._create_empty_result(document_id, "No initial question generated for short answer")
            
            # å±‚çº§2ï¸âƒ£åŠä¹‹åï¼šä¸ºè¿™ä¸ªé—®é¢˜æ„å»ºæ·±åŒ–é“¾
            question_chain, trajectories = self._build_question_chain(initial_question, document_content, max_depth=self.max_levels-1)
            
            # è®¡ç®—å¤„ç†æ—¶é—´
            processing_time = time.time() - start_time
            
            # æ„å»ºç»“æœ
            result = {
                'success': True,
                'document_id': document_id,
                'processing_time': processing_time,
                'short_answer': self._serialize_short_answer(short_answer),
                'initial_question': self._serialize_question(initial_question),
                'question_chains': {'main_chain': question_chain},  # å•ä¸ªé“¾
                'trajectories': [self._serialize_trajectory(t) for t in trajectories],
                'statistics': {
                    'total_questions': len(question_chain),
                    'total_levels': len(question_chain),
                    'successful_hops': len([t for t in trajectories if t.hop_success]),
                    'validation_pass_rate': len([t for t in trajectories if t.validation_passed]) / max(len(trajectories), 1)
                },
                'framework_version': '1.0_linguistic_single_sa'
            }
            
            self.stats['documents_processed'] += 1
            logger.info(f"è¯­è¨€å­¦æ·±åº¦å¤„ç†å•ä¸ªçŸ­ç­”æ¡ˆå®Œæˆ: {document_id}, è€—æ—¶: {processing_time:.2f}s")
            
            return result
            
        except Exception as e:
            logger.error(f"è¯­è¨€å­¦æ·±åº¦å¤„ç†å•ä¸ªçŸ­ç­”æ¡ˆå¤±è´¥ {document_id}: {e}")
            return self._create_empty_result(document_id, str(e))
    
    def _generate_single_initial_question(self, short_answer: ShortAnswer, document_content: str) -> Optional[LinguisticQuestion]:
        """ä¸ºå•ä¸ªçŸ­ç­”æ¡ˆç”Ÿæˆåˆå§‹é—®é¢˜"""
        if not self.api_client:
            return None
        
        try:
            # Promptè¯´æ˜: ä¸ºå•ä¸ªçŸ­ç­”æ¡ˆç”Ÿæˆæ˜ç¡®é—®é¢˜ï¼ŒåŒ…å«å¾ªç¯é¢„é˜²é€»è¾‘
            base_prompt = f"""Based on the following Short Answer, generate a clear and specific question:

Short Answer: {short_answer.answer_text}
Answer Type: {short_answer.answer_type}
Document Context: {document_content[:1000]}

Requirements:
1. The question must contain at least two explicit keywords
2. The question must uniquely determine the answer
3. The question should be objective and verifiable
4. Avoid subjective or "how" type questions

ğŸ”„ CIRCULAR PREVENTION REQUIREMENTS:
- AVOID time-based questions if answer contains dates/years
- AVOID entity property questions if answer is an entity name
- AVOID direct "who/what/when" questions that simply reverse the statement
- USE indirect, contextual descriptions instead of direct terms

OUTPUT REQUIREMENTS:
- Question must be indirect and require reasoning
- Question must avoid obvious circular patterns
- Question must use descriptive/contextual language

è¾“å‡ºæ ¼å¼ï¼ˆJSONï¼‰ï¼š
{{
    "question": "Generated question",
    "keywords": ["keyword1", "keyword2", "keyword3"],
    "confidence": 0.0-1.0
}}"""

            response = self.api_client.generate_response(
                prompt=base_prompt,
                temperature=0.3,
                max_tokens=400
            )
            
            parsed = self._parse_json_response(response)
            if parsed and 'question' in parsed:
                return LinguisticQuestion(
                    question_id=f"q_1",
                    question_text=parsed['question'],
                    answer=short_answer.answer_text,
                    level=1,
                    keywords=parsed.get('keywords', []),
                    keyword_replacements=[],
                    validation_passed=True,
                    max_hops_required=0,
                    parent_question_id=""
                )
            
            return None
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆå•ä¸ªåˆå§‹é—®é¢˜å¤±è´¥: {e}")
            return None 