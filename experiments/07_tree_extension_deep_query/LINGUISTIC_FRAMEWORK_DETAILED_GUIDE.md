# è¯­è¨€å­¦æ·±åº¦æŸ¥è¯¢æ¡†æ¶ - è¯¦ç»†ä»£ç è§£é‡Š 
# Linguistic Deep Query Framework - Detailed Code Documentation

## ğŸ“‹ ç›®å½• / Table of Contents

1. [æ¡†æ¶æ¦‚è¿° / Framework Overview](#æ¡†æ¶æ¦‚è¿°--framework-overview)
2. [æ ¸å¿ƒæ¶æ„ / Core Architecture](#æ ¸å¿ƒæ¶æ„--core-architecture)
3. [ä»£ç å±‚æ¬¡ç»“æ„ / Code Hierarchy](#ä»£ç å±‚æ¬¡ç»“æ„--code-hierarchy)
4. [äº¤äº’é€»è¾‘è¯¦è§£ / Interaction Logic](#äº¤äº’é€»è¾‘è¯¦è§£--interaction-logic)
5. [æ•°å­¦å…¬å¼å®ç° / Mathematical Formula Implementation](#æ•°å­¦å…¬å¼å®ç°--mathematical-formula-implementation)
6. [APIä¼˜åŒ–æœºåˆ¶ / API Optimization](#apiä¼˜åŒ–æœºåˆ¶--api-optimization)
7. [æ•°æ®æµä¸å¯¼å‡º / Data Flow & Export](#æ•°æ®æµä¸å¯¼å‡º--data-flow--export)

---

## æ¡†æ¶æ¦‚è¿° / Framework Overview

### ğŸ¯ æ ¸å¿ƒè®¾è®¡ç†å¿µ / Core Design Philosophy

è¯­è¨€å­¦æ·±åº¦æŸ¥è¯¢æ¡†æ¶æ˜¯ä¸€ä¸ªåŸºäº**å…³é”®è¯æ›¿æ¢**å’Œ**Webæœç´¢å¢å¼º**çš„æ·±åº¦é—®ç­”ç”Ÿæˆç³»ç»Ÿã€‚ä¸åŒäºä¼ ç»Ÿçš„åŸºäºæ–‡æ¡£å†…å®¹çš„é—®ç­”ç”Ÿæˆï¼Œæœ¬æ¡†æ¶é‡‡ç”¨**æ•°å­¦å…¬å¼åŒ–**çš„æ–¹æ³•ï¼Œé€šè¿‡ä¸¥æ ¼çš„**Q^(t+1) = Q^t[K_i^t â†’ D(K_i^t)]**å…¬å¼ï¼Œå®ç°5å±‚çº§çš„æ·±åº¦æŸ¥è¯¢æ‰©å±•ã€‚

The Linguistic Deep Query Framework is a depth-driven QA generation system based on **keyword replacement** and **web search enhancement**. Unlike traditional document-content-based QA generation, this framework adopts a **mathematical formulation** approach through the strict formula **Q^(t+1) = Q^t[K_i^t â†’ D(K_i^t)]** to achieve 5-level deep query expansion.

### ğŸ”‘ å…³é”®ç‰¹æ€§ / Key Features

1. **Extensionç­”æ¡ˆ=å…³é”®è¯** / Extension Answers are Keywords from Root Query
2. **Webæœç´¢é©±åŠ¨æ‰©å±•** / Web Search-Driven Extensions  
3. **Series & ParallelåŒé‡ç­–ç•¥** / Dual Series & Parallel Strategies
4. **Tree Level Queryæœ€ç»ˆæ•´åˆ** / Tree Level Query Final Integration
5. **å¾ªç¯é¢„é˜²æœºåˆ¶** / Circular Prevention Mechanism
6. **æ™ºèƒ½APIé‡è¯•** / Intelligent API Retry (10 attempts with exponential backoff)

---

## æ ¸å¿ƒæ¶æ„ / Core Architecture

### ğŸ“ æ–‡ä»¶ç»“æ„ / File Structure

```
experiments/07_tree_extension_deep_query/
â”œâ”€â”€ complete_optimized_main.py          # ä¸»æ¡†æ¶å…¥å£ / Main Framework Entry
â”œâ”€â”€ linguistic_deep_query_framework.py  # è¯­è¨€å­¦æ ¸å¿ƒé€»è¾‘ / Linguistic Core Logic
â”œâ”€â”€ document_loader.py                  # æ–‡æ¡£åŠ è½½å™¨ / Document Loader
â”œâ”€â”€ document_screener.py               # æ–‡æ¡£ç­›é€‰å™¨ / Document Screener
â”œâ”€â”€ short_answer_locator.py            # çŸ­ç­”æ¡ˆå®šä½å™¨ / Short Answer Locator
â”œâ”€â”€ web_search.py                      # Webæœç´¢æ¨¡å— / Web Search Module
â”œâ”€â”€ export_system.py                   # å¯¼å‡ºç³»ç»Ÿ / Export System
â””â”€â”€ tree_level_query_integrator.py     # TreeæŸ¥è¯¢æ•´åˆå™¨ / Tree Query Integrator
```

### ğŸ—ï¸ ç±»å±‚æ¬¡ç»“æ„ / Class Hierarchy

```python
# ä¸»æ¡†æ¶ç±» / Main Framework Class
class LinguisticMainFramework:
    """
    è¯­è¨€å­¦ä¸»æ¡†æ¶ - ä¸“æ³¨äºç§‘å­¦åŒ–çš„å…³é”®è¯æ›¿æ¢æ·±åº¦æŸ¥è¯¢
    Main linguistic framework focusing on scientific keyword replacement deep queries
    """
    
    # æ ¸å¿ƒç»„ä»¶ / Core Components
    - document_loader: DocumentLoader           # æ–‡æ¡£åŠ è½½
    - document_screener: DocumentScreener       # æ–‡æ¡£ç­›é€‰  
    - short_answer_locator: ShortAnswerLocator  # çŸ­ç­”æ¡ˆå®šä½
    - linguistic_framework: LinguisticDeepQueryFramework  # è¯­è¨€å­¦æ¡†æ¶
    - export_system: ExportSystem               # å¯¼å‡ºç³»ç»Ÿ
```

---

## ä»£ç å±‚æ¬¡ç»“æ„ / Code Hierarchy

### ğŸ”„ ç¬¬ä¸€å±‚ï¼šä¸»æ§åˆ¶å™¨ / Layer 1: Main Controller

**æ–‡ä»¶**: `complete_optimized_main.py`  
**ç±»**: `LinguisticMainFramework`

```python
def run_linguistic_experiment(self, topic: str, max_documents: int = 50):
    """
    è¿è¡Œè¯­è¨€å­¦æ·±åº¦æŸ¥è¯¢å®éªŒçš„ä¸»æ§åˆ¶å‡½æ•°
    Main control function for running linguistic deep query experiments
    
    Flow / æµç¨‹:
    1. åŠ è½½æ–‡æ¡£ / Load documents
    2. LLMç­›é€‰ / LLM screening  
    3. çŸ­ç­”æ¡ˆå®šä½ / Short answer location
    4. è¯­è¨€å­¦æ·±åº¦å¤„ç† / Linguistic depth processing
    5. ç»“æœå¯¼å‡º / Result export
    """
```

**å…³é”®äº¤äº’é€»è¾‘ / Key Interaction Logic:**
- ğŸ“„ **æ–‡æ¡£åŠ è½½**: `document_loader.load_documents_from_topic()`
- ğŸ” **è´¨é‡ç­›é€‰**: `document_screener.screen_document()`  
- ğŸ¯ **çŸ­ç­”æ¡ˆå®šä½**: `short_answer_locator.locate_short_answers()`
- ğŸ§  **è¯­è¨€å­¦å¤„ç†**: `linguistic_framework.process_single_short_answer_with_linguistic_depth()`

### ğŸ”„ ç¬¬äºŒå±‚ï¼šè¯­è¨€å­¦æ ¸å¿ƒ / Layer 2: Linguistic Core

**æ–‡ä»¶**: `linguistic_deep_query_framework.py`  
**ç±»**: `LinguisticDeepQueryFramework`

```python
def process_single_short_answer_with_linguistic_depth(
    self, 
    document_content: str,
    document_id: str, 
    short_answer_text: str,
    short_answer_type: str
) -> Dict[str, Any]:
    """
    æ ¸å¿ƒå¤„ç†å‡½æ•°ï¼šä¸ºå•ä¸ªçŸ­ç­”æ¡ˆç”Ÿæˆå®Œæ•´çš„è¯­è¨€å­¦æ·±åº¦æŸ¥è¯¢
    Core processing function: Generate complete linguistic depth queries for single short answer
    
    Mathematical Implementation / æ•°å­¦å®ç°:
    Q^(t+1) = Q^t[K_i^t â†’ D(K_i^t)]
    
    Where / å…¶ä¸­:
    - Q^t: å½“å‰å±‚çº§é—®é¢˜ / Current level question
    - K_i^t: ç¬¬iä¸ªå…³é”®è¯ / i-th keyword  
    - D(K_i^t): å…³é”®è¯çš„Webæœç´¢æè¿° / Web search description of keyword
    - Q^(t+1): ä¸‹ä¸€å±‚çº§é—®é¢˜ / Next level question
    """
```

**5å±‚çº§å¤„ç†æµç¨‹ / 5-Level Processing Flow:**

```python
# Layer 0: æ ¹é—®é¢˜ç”Ÿæˆ / Root Question Generation
root_question = self._generate_root_question(document_content, short_answer_text)

# Layer 1-5: é€’å½’æ‰©å±• / Recursive Extensions  
for level in range(1, 6):
    # Seriesæ‰©å±• / Series Extensions
    series_questions = self._generate_series_extensions(current_questions, level)
    
    # Parallelæ‰©å±• / Parallel Extensions  
    parallel_questions = self._generate_parallel_extensions(current_questions, level)
    
    # éªŒè¯ä¸ç­›é€‰ / Validation & Filtering
    validated_questions = self._validate_questions(series_questions + parallel_questions)
```

### ğŸ”„ ç¬¬ä¸‰å±‚ï¼šæ ¸å¿ƒç®—æ³•æ¨¡å— / Layer 3: Core Algorithm Modules

#### ğŸŒ Webæœç´¢æ¨¡å— / Web Search Module

**æ–‡ä»¶**: `web_search.py`

```python
def web_search(query: str, num_results: int = 5) -> List[Dict[str, str]]:
    """
    æ‰§è¡ŒWebæœç´¢ï¼Œè·å–å…³é”®è¯çš„ç›¸å…³æè¿°ä¿¡æ¯
    Execute web search to get relevant descriptions for keywords
    
    Purpose / ç›®çš„:
    ä¸ºå…³é”®è¯æ›¿æ¢æä¾›æŠ½è±¡æˆ–é—´æ¥çš„æ›¿æ¢æè¿°
    Provide abstract or indirect replacement descriptions for keyword substitution
    """
```

#### âœ… éªŒè¯æœºåˆ¶ / Validation Mechanism

**æ–‡ä»¶**: `linguistic_deep_query_framework.py` (å†…éƒ¨æ–¹æ³•)

```python
def _validate_question_uniqueness_and_consistency(
    self, 
    new_question: str,
    existing_questions: List[str],
    target_keyword: str
) -> Dict[str, Any]:
    """
    éªŒè¯é—®é¢˜çš„å”¯ä¸€æ€§å’Œä¸€è‡´æ€§
    Validate question uniqueness and consistency
    
    Validation Checks / éªŒè¯æ£€æŸ¥:
    1. å”¯ä¸€æ€§æ£€æŸ¥ / Uniqueness Check
    2. å¾ªç¯æ£€æµ‹ / Circular Detection  
    3. æ·±åº¦éªŒè¯ / Depth Validation
    4. ç­”æ¡ˆä¸€è‡´æ€§ / Answer Consistency
    5. å…³é”®è¯å±‚æ¬¡åˆè§„ / Keyword Hierarchy Compliance
    """
```

---

## äº¤äº’é€»è¾‘è¯¦è§£ / Interaction Logic

### ğŸ”„ å®Œæ•´æ•°æ®æµ / Complete Data Flow

```mermaid
æ–‡æ¡£åŠ è½½ â†’ LLMç­›é€‰ â†’ çŸ­ç­”æ¡ˆå®šä½ â†’ è¯­è¨€å­¦å¤„ç† â†’ éªŒè¯ â†’ å¯¼å‡º
Document Loading â†’ LLM Screening â†’ Short Answer Location â†’ Linguistic Processing â†’ Validation â†’ Export
```

### ğŸ“ Promptæ¨¡æ¿äº¤äº’ / Prompt Template Interactions

æ¡†æ¶ä½¿ç”¨**IntegratedPromptTemplates**å®ç°ä¸‰ä¸ªæ ¸å¿ƒPromptçš„è°ƒç”¨ï¼š

The framework uses **IntegratedPromptTemplates** to implement three core prompt invocations:

```python
# Prompt-1: æ ¹é—®é¢˜ç”Ÿæˆ / Root Question Generation
root_prompt = self.prompt_templates.get_root_question_prompt(
    document_content=document_content,
    short_answer_text=short_answer_text,
    short_answer_type=short_answer_type
)

# Prompt-2: Extensioné—®é¢˜ç”Ÿæˆ / Extension Question Generation  
extension_prompt = self.prompt_templates.get_extension_question_prompt(
    original_question=original_question,
    keyword=keyword,
    replacement_description=web_search_result
)

# Prompt-3: æ·±å±‚æ‰©å±• / Deep Extensions
deep_prompt = self.prompt_templates.get_deep_extension_prompt(
    question_chain=question_chain,
    current_level=current_level
)
```

### ğŸ”„ APIè°ƒç”¨å±‚æ¬¡ / API Call Hierarchy

```python
# ç¬¬ä¸€å±‚ï¼šä¸»æ¡†æ¶è°ƒç”¨ / Layer 1: Main Framework Calls
LinguisticMainFramework.run_linguistic_experiment()
    â†“
# ç¬¬äºŒå±‚ï¼šæ–‡æ¡£å¤„ç†è°ƒç”¨ / Layer 2: Document Processing Calls  
DocumentScreener.screen_document() â†’ OpenAI API
ShortAnswerLocator.locate_short_answers() â†’ OpenAI API
    â†“
# ç¬¬ä¸‰å±‚ï¼šè¯­è¨€å­¦å¤„ç†è°ƒç”¨ / Layer 3: Linguistic Processing Calls
LinguisticDeepQueryFramework.process_single_short_answer_with_linguistic_depth()
    â†“ 
# ç¬¬å››å±‚ï¼šå…·ä½“ç”Ÿæˆè°ƒç”¨ / Layer 4: Specific Generation Calls
_generate_root_question() â†’ OpenAI API
_generate_extension_questions() â†’ OpenAI API  
_validate_questions() â†’ OpenAI API
web_search() â†’ Web Search API
```

---

## æ•°å­¦å…¬å¼å®ç° / Mathematical Formula Implementation

### ğŸ§® æ ¸å¿ƒå…¬å¼ / Core Formula

**Q^(t+1) = Q^t[K_i^t â†’ D(K_i^t)]**

### ğŸ“Š ä»£ç å®ç° / Code Implementation

```python
def _execute_keyword_replacement_formula(
    self,
    original_question: str,      # Q^t
    keyword: str,               # K_i^t  
    replacement_description: str # D(K_i^t)
) -> str:                      # Q^(t+1)
    """
    æ‰§è¡Œæ•°å­¦å…¬å¼ï¼šQ^(t+1) = Q^t[K_i^t â†’ D(K_i^t)]
    Execute mathematical formula: Q^(t+1) = Q^t[K_i^t â†’ D(K_i^t)]
    
    Process / è¿‡ç¨‹:
    1. åœ¨åŸé—®é¢˜Q^tä¸­å®šä½å…³é”®è¯K_i^t
    2. ä½¿ç”¨Webæœç´¢è·å–D(K_i^t)  
    3. æ‰§è¡Œæ›¿æ¢æ“ä½œç”ŸæˆQ^(t+1)
    4. éªŒè¯æ–°é—®é¢˜çš„æœ‰æ•ˆæ€§
    """
    
    # Step 1: å…³é”®è¯å®šä½ / Keyword Location
    keyword_position = original_question.find(keyword)
    
    # Step 2: Webæœç´¢è·å–æè¿° / Web Search for Description
    search_results = web_search(keyword, num_results=3)
    replacement_description = self._extract_best_description(search_results)
    
    # Step 3: æ‰§è¡Œæ›¿æ¢ / Execute Replacement
    new_question = original_question.replace(keyword, replacement_description)
    
    # Step 4: éªŒè¯æ–°é—®é¢˜ / Validate New Question
    validation_result = self._validate_question_uniqueness_and_consistency(
        new_question=new_question,
        original_question=original_question,
        target_keyword=keyword
    )
    
    return new_question if validation_result['passed'] else None
```

### ğŸ”„ Series vs Parallelæ‰©å±•ç­–ç•¥ / Series vs Parallel Extension Strategies

```python
def _generate_series_extensions(self, questions: List[str], level: int) -> List[str]:
    """
    Seriesæ‰©å±•ï¼šå¯¹æ¯ä¸ªé—®é¢˜ä¾æ¬¡è¿›è¡Œå…³é”®è¯æ›¿æ¢
    Series Extension: Sequential keyword replacement for each question
    
    Strategy / ç­–ç•¥:
    å¯¹äºé—®é¢˜Qï¼Œä¾æ¬¡å¤„ç†å…¶å…³é”®è¯K1, K2, K3...
    For question Q, sequentially process keywords K1, K2, K3...
    """
    
def _generate_parallel_extensions(self, questions: List[str], level: int) -> List[str]:
    """
    Parallelæ‰©å±•ï¼šå¯¹åŒä¸€é—®é¢˜çš„å¤šä¸ªå…³é”®è¯åŒæ—¶è¿›è¡Œæ›¿æ¢
    Parallel Extension: Simultaneous replacement of multiple keywords in same question
    
    Strategy / ç­–ç•¥:  
    å¯¹äºé—®é¢˜Qï¼ŒåŒæ—¶å¤„ç†å¤šä¸ªå…³é”®è¯ç»„åˆ
    For question Q, simultaneously process multiple keyword combinations
    """
```

---

## APIä¼˜åŒ–æœºåˆ¶ / API Optimization

### ğŸ”„ æ™ºèƒ½é‡è¯•æœºåˆ¶ / Intelligent Retry Mechanism

**æ–‡ä»¶**: `core/llm_clients/openai_api_client.py`

```python
def generate_content(
    self, 
    prompt: str, 
    system_prompt: str = None,
    max_tokens: int = 6000, 
    temperature: float = 0.7,
    max_retries: int = 10,        # å¢åŠ åˆ°10æ¬¡é‡è¯• / Increased to 10 retries
    retry_delay: float = 2.0
) -> Optional[str]:
    """
    OpenAI APIè°ƒç”¨çš„ä¼˜åŒ–é‡è¯•æœºåˆ¶
    Optimized retry mechanism for OpenAI API calls
    
    Improvements / æ”¹è¿›:
    1. å¢åŠ é‡è¯•æ¬¡æ•°åˆ°10æ¬¡ / Increased retry attempts to 10
    2. æ™ºèƒ½ç­‰å¾…æ—¶é—´è®¡ç®— / Intelligent wait time calculation
    3. è¯»å–Retry-Afterå“åº”å¤´ / Read Retry-After response headers  
    4. æŒ‡æ•°é€€é¿æœ€å¤§60ç§’ / Exponential backoff max 60 seconds
    """
    
    for attempt in range(max_retries):
        try:
            # APIè°ƒç”¨é€»è¾‘ / API call logic
            response = requests.post(self.api_url, headers=self.headers, json=data, timeout=120)
            
        except requests.exceptions.HTTPError as e:
            if e.response.status_code == 429:  # Rate limit
                # æ™ºèƒ½ç­‰å¾…æ—¶é—´è®¡ç®— / Intelligent wait time calculation
                retry_after = e.response.headers.get('Retry-After')
                if retry_after:
                    wait_time = int(retry_after)
                else:
                    wait_time = min(retry_delay * (2 ** attempt), 60)  # æœ€å¤§60ç§’ / Max 60 seconds
                
                print(f"ğŸš¦ APIé€Ÿç‡é™åˆ¶ï¼Œ{wait_time}ç§’åé‡è¯•...")
                time.sleep(wait_time)
                continue
```

### ğŸ“Š é¢‘ç‡é™åˆ¶å¤„ç†ç­–ç•¥ / Rate Limit Handling Strategy

1. **è¯»å–å®˜æ–¹å»ºè®®ç­‰å¾…æ—¶é—´** / Read Official Suggested Wait Time
2. **æŒ‡æ•°é€€é¿ç®—æ³•** / Exponential Backoff Algorithm  
3. **æœ€å¤§ç­‰å¾…æ—¶é—´é™åˆ¶** / Maximum Wait Time Limit
4. **å¤šæ¬¡é‡è¯•ä¿éšœ** / Multiple Retry Guarantee

---

## æ•°æ®æµä¸å¯¼å‡º / Data Flow & Export

### ğŸ“ˆ Excelå¤šè¡¨å¯¼å‡ºç³»ç»Ÿ / Excel Multi-Sheet Export System

**æ–‡ä»¶**: `complete_optimized_main.py` (æ–¹æ³•: `_export_linguistic_excel`)

```python
def _export_linguistic_excel(self, results: Dict, writer):
    """
    å¯¼å‡ºè¯­è¨€å­¦æ¨¡å¼çš„Excelæ•°æ®åˆ°å¤šä¸ªå·¥ä½œè¡¨
    Export linguistic mode data to multiple Excel worksheets
    
    Worksheets / å·¥ä½œè¡¨:
    1. é—®ç­”æ•°æ® / QA Data
    2. è½¨è¿¹æ•°æ® / Trajectory Data  
    3. å…³é”®è¯æ›¿æ¢ / Keyword Replacements
    4. éªŒè¯ç»“æœ / Validation Results
    5. å®éªŒç»Ÿè®¡ / Experiment Statistics
    """
```

### ğŸ“Š æ•°æ®è½¬æ¢é€»è¾‘ / Data Conversion Logic

```python
def _convert_linguistic_to_excel_format(
    self, 
    linguistic_result: Dict[str, Any], 
    doc_index: int
) -> Dict[str, Any]:
    """
    å°†è¯­è¨€å­¦æ·±åº¦æŸ¥è¯¢ç»“æœè½¬æ¢ä¸ºExcelå…¼å®¹æ ¼å¼
    Convert linguistic deep query results to Excel-compatible format
    
    Conversion Process / è½¬æ¢è¿‡ç¨‹:
    1. é—®ç­”å¯¹æ•°æ®ç»“æ„åŒ– / Structure QA pair data
    2. è½¨è¿¹æ•°æ®ç»Ÿè®¡åŒ– / Statisticalize trajectory data
    3. å…³é”®è¯æ›¿æ¢è®°å½• / Record keyword replacements  
    4. éªŒè¯ç»“æœé‡åŒ– / Quantify validation results
    """
    
    excel_data = {
        'qa_pairs': [],           # Tree_ID, Node_Type, Question, Answerç­‰
        'trajectory_data': [],    # å¤„ç†æ—¶é—´, æˆåŠŸç‡, éªŒè¯åˆ†æ•°ç­‰  
        'keyword_replacements': [], # åŸå…³é”®è¯, æ›¿æ¢æè¿°, å”¯ä¸€æ€§éªŒè¯ç­‰
        'validation_results': []  # å”¯ä¸€æ€§æ£€æŸ¥, ç­”æ¡ˆä¸€è‡´æ€§, å¾ªç¯æ£€æµ‹ç­‰
    }
```

### ğŸ”„ Tree Level Queryæ•´åˆ / Tree Level Query Integration

**æ–‡ä»¶**: `tree_level_query_integrator.py`

```python
class TreeLevelQueryIntegrator:
    """
    Tree Level Queryæ•´åˆå™¨ - å°†å¤šå±‚çº§é—®é¢˜æ•´åˆä¸ºæœ€ç»ˆæ·±åº¦é—®é¢˜
    Tree Level Query Integrator - Integrate multi-level questions into final deep question
    
    Integration Strategies / æ•´åˆç­–ç•¥:
    1. å…³é”®è¯æ›¿æ¢æ•´åˆ / Keyword Replacement Integration
    2. ä¸Šä¸‹æ–‡é“¾å¼æ•´åˆ / Contextual Chaining Integration  
    3. å±‚æ¬¡åŒ–èåˆæ•´åˆ / Hierarchical Fusion Integration
    """
    
    def integrate_tree_level_query(
        self, 
        question_chains: Dict[str, List[str]]
    ) -> str:
        """
        ç”Ÿæˆæœ€ç»ˆçš„Tree Level Query
        Generate final Tree Level Query
        
        Process / è¿‡ç¨‹:
        1. åˆ†æé—®é¢˜é“¾çš„å±‚æ¬¡ç»“æ„ / Analyze hierarchical structure of question chains
        2. æå–æ ¸å¿ƒæ¦‚å¿µå’Œå…³é”®è¯ / Extract core concepts and keywords
        3. æ„å»ºæ•´åˆé—®é¢˜æ¨¡æ¿ / Build integration question template
        4. ç”Ÿæˆæœ€ç»ˆæ·±åº¦é—®é¢˜ / Generate final deep question
        """
```

---

## ğŸ¯ æ€»ç»“ / Summary

### ğŸ“‹ æ¡†æ¶æ ¸å¿ƒä¼˜åŠ¿ / Core Framework Advantages

1. **æ•°å­¦åŒ–ä¸¥æ ¼æ€§** / Mathematical Rigor: ä¸¥æ ¼æŒ‰ç…§`Q^(t+1) = Q^t[K_i^t â†’ D(K_i^t)]`å…¬å¼æ‰§è¡Œ
2. **æ™ºèƒ½æ‰©å±•ç­–ç•¥** / Intelligent Extension Strategy: Series & ParallelåŒé‡æ‰©å±•æœºåˆ¶
3. **å¼ºå¤§éªŒè¯ç³»ç»Ÿ** / Robust Validation System: 5é‡éªŒè¯ç¡®ä¿é—®é¢˜è´¨é‡
4. **ä¼˜åŒ–APIå¤„ç†** / Optimized API Handling: 10æ¬¡é‡è¯•+æ™ºèƒ½ç­‰å¾…
5. **å®Œæ•´æ•°æ®å¯¼å‡º** / Complete Data Export: 5ä¸ªExcelè¡¨æ ¼å…¨é¢è®°å½•

### ğŸ”„ å®Œæ•´äº¤äº’é“¾è·¯ / Complete Interaction Chain

```
ç”¨æˆ·è¾“å…¥ â†’ æ–‡æ¡£åŠ è½½ â†’ LLMç­›é€‰ â†’ çŸ­ç­”æ¡ˆå®šä½ â†’ 
User Input â†’ Document Loading â†’ LLM Screening â†’ Short Answer Location â†’

è¯­è¨€å­¦å¤„ç† â†’ å…³é”®è¯æ›¿æ¢ â†’ Webæœç´¢ â†’ é—®é¢˜ç”Ÿæˆ â†’ 
Linguistic Processing â†’ Keyword Replacement â†’ Web Search â†’ Question Generation â†’

éªŒè¯æœºåˆ¶ â†’ Treeæ•´åˆ â†’ Excelå¯¼å‡º â†’ ç»“æœæŠ¥å‘Š
Validation â†’ Tree Integration â†’ Excel Export â†’ Result Report
```

### ğŸ­ åˆ›æ–°ç‚¹ / Innovation Points

1. **Extensionç­”æ¡ˆå³å…³é”®è¯**: çªç ´ä¼ ç»Ÿæ–‡æ¡£ç­”æ¡ˆé™åˆ¶
2. **Webæœç´¢å¢å¼º**: å¼•å…¥å¤–éƒ¨çŸ¥è¯†ä¸°å¯Œé—®é¢˜ç”Ÿæˆ  
3. **Tree Level Query**: å¤šå±‚çº§é—®é¢˜çš„æ™ºèƒ½æ•´åˆ
4. **å¾ªç¯é¢„é˜²**: ä¸¥æ ¼é˜²æ­¢é—®é¢˜ç”Ÿæˆä¸­çš„å¾ªç¯ç°è±¡
5. **æ•°å­¦å…¬å¼åŒ–**: å°†é—®é¢˜ç”Ÿæˆè¿‡ç¨‹å®Œå…¨å…¬å¼åŒ–

è¿™ä¸ªæ¡†æ¶ä»£è¡¨äº†æ·±åº¦é—®ç­”ç”ŸæˆæŠ€æœ¯çš„é‡è¦çªç ´ï¼Œå®ç°äº†ä»ä¼ ç»ŸåŸºäºæ–‡æ¡£å†…å®¹çš„é—®ç­”ç”Ÿæˆåˆ°åŸºäºè¯­è¨€å­¦æ·±åº¦æŸ¥è¯¢çš„èŒƒå¼è½¬æ¢ã€‚

This framework represents a significant breakthrough in deep QA generation technology, achieving a paradigm shift from traditional document-content-based QA generation to linguistic deep query-based generation. 