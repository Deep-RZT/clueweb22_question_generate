#!/usr/bin/env python3
"""
Agentæ·±åº¦æ¨ç†æµ‹è¯•æ¡†æ¶ - ä¸»å…¥å£æ–‡ä»¶
Agent Depth Reasoning Test Framework - Main Entry Point

åŸºäºå…¨æ–°çš„6æ­¥è®¾è®¡ï¼Œä¸ºæ™ºèƒ½Agentæ„å»ºæ·±åº¦æ¨ç†æµ‹è¯•é¢˜åº“
æ ¸å¿ƒç›®æ ‡ï¼šè®©æ™®é€šLLMæ— æ³•ç›´æ¥ç­”é¢˜ï¼Œéœ€è¦Agenté€æ­¥æ¨ç†è§£å†³
"""

import logging
import sys
import os
import time
import json
from pathlib import Path
from typing import Dict, List, Optional, Any

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

# å¯¼å…¥æ ¸å¿ƒç»„ä»¶
from config import get_config
from core.llm_clients.openai_api_client import OpenAIClient
from document_loader import DocumentLoader
from document_screener import DocumentScreener
from agent_depth_reasoning_framework import AgentDepthReasoningFramework
from agent_export_system import AgentExportSystem
from web_search import web_search

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('agent_reasoning_experiment.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class AgentReasoningMainFramework:
    """Agentæ¨ç†æµ‹è¯•ä¸»æ¡†æ¶"""
    
    def __init__(self):
        self.config = get_config()
        self.api_client = None
        self.search_client = web_search
        
        # æ ¸å¿ƒç»„ä»¶
        self.document_loader = DocumentLoader()
        self.document_screener = DocumentScreener()
        self.agent_reasoning_framework = None
        self.export_system = AgentExportSystem()
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.experiment_stats = {
            'session_start_time': time.time(),
            'documents_processed': 0,
            'successful_documents': 0,
            'failed_documents': 0,
            'total_reasoning_trees': 0,
            'total_composite_queries': 0,
            'step1_success_rate': 0.0,
            'step2_success_rate': 0.0,
            'step6_success_rate': 0.0
        }
    
    def initialize_framework(self, api_key: str) -> bool:
        """åˆå§‹åŒ–æ¡†æ¶ç»„ä»¶"""
        try:
            logger.info("ğŸ¯ åˆå§‹åŒ–Agentæ·±åº¦æ¨ç†æµ‹è¯•æ¡†æ¶...")
            
            # åˆå§‹åŒ–APIå®¢æˆ·ç«¯
            self.api_client = OpenAIClient(api_key=api_key)
            
            # è®¾ç½®APIå®¢æˆ·ç«¯åˆ°å„ç»„ä»¶
            self.document_screener.set_api_client(self.api_client)
            
            # åˆå§‹åŒ–Agentæ¨ç†æ¡†æ¶
            self.agent_reasoning_framework = AgentDepthReasoningFramework(
                api_client=self.api_client,
                search_client=self.search_client
            )
            
            logger.info("âœ… Agentæ¨ç†æ¡†æ¶åˆå§‹åŒ–å®Œæˆ")
            logger.info("ğŸ¯ æ¡†æ¶ç›®æ ‡:")
            logger.info("  - ä¸ºæ™ºèƒ½Agentç”Ÿæˆæ·±åº¦æ¨ç†æµ‹è¯•é¢˜")
            logger.info("  - é˜²æ­¢æ™®é€šLLMç›´æ¥è·å–ç­”æ¡ˆ")
            logger.info("  - é€šè¿‡å¤šå±‚çº§é—®é¢˜æ ‘è®­ç»ƒé€æ­¥æ¨ç†")
            logger.info("  - ç”ŸæˆåµŒå¥—å¼ç»¼åˆé—®é¢˜")
            
            return True
            
        except Exception as e:
            logger.error(f"æ¡†æ¶åˆå§‹åŒ–å¤±è´¥: {e}")
            return False
    
    def run_agent_reasoning_experiment(self, topic: str, max_documents: int = 20) -> Dict[str, Any]:
        """
        è¿è¡ŒAgentæ¨ç†æµ‹è¯•å®éªŒ
        
        Args:
            topic: ClueWeb22ä¸»é¢˜åç§°
            max_documents: æœ€å¤§å¤„ç†æ–‡æ¡£æ•°
        """
        logger.info(f"ğŸš€ å¯åŠ¨Agentæ·±åº¦æ¨ç†å®éªŒ: {topic}")
        logger.info(f"æœ€å¤§æ–‡æ¡£æ•°: {max_documents}")
        
        session_id = f"agent_reasoning_{topic}_{int(time.time())}"
        start_time = time.time()
        
        try:
            # 1. åŠ è½½æ–‡æ¡£
            logger.info("ğŸ“„ åŠ è½½ClueWeb22æ–‡æ¡£...")
            document_data_list = self.document_loader.load_documents_from_topic(topic, max_documents)
            
            if not document_data_list:
                return self._create_error_result(session_id, "No documents loaded")
            
            logger.info(f"åŠ è½½æ–‡æ¡£æ•°: {len(document_data_list)}")
            
            # 2. æ–‡æ¡£ç­›é€‰ï¼ˆå¯é€‰ï¼‰
            logger.info("ğŸ” æ–‡æ¡£è´¨é‡é¢„ç­›é€‰...")
            screened_documents = []
            
            for doc_data in document_data_list[:max_documents]:
                # åŸºæœ¬è´¨é‡æ£€æŸ¥
                if len(doc_data.content) < 200:
                    logger.info(f"è·³è¿‡çŸ­æ–‡æ¡£: {doc_data.doc_id} (é•¿åº¦: {len(doc_data.content)})")
                    continue
                
                screened_documents.append({
                    'doc_id': doc_data.doc_id,
                    'content': doc_data.content,
                    'topic': doc_data.topic,
                    'length': len(doc_data.content)
                })
                
                if len(screened_documents) >= max_documents:
                    break
            
            logger.info(f"ç­›é€‰åæ–‡æ¡£æ•°: {len(screened_documents)}")
            
            # 3. Agentæ¨ç†æµ‹è¯•æ•°æ®ç”Ÿæˆ
            results = self._run_agent_reasoning_generation(screened_documents, topic, session_id)
            
            # 4. è®¡ç®—æœ€ç»ˆç»Ÿè®¡
            total_time = time.time() - start_time
            final_results = self._generate_final_results(results, session_id, total_time)
            
            # 5. å¯¼å‡ºç»“æœï¼ˆä½¿ç”¨æ–°çš„å¯¼å‡ºç³»ç»Ÿï¼‰
            exported_files = self.export_system.export_agent_reasoning_results(final_results, session_id)
            
            logger.info(f"âœ… Agentæ¨ç†å®éªŒå®Œæˆ: {session_id}")
            logger.info(f"æ€»è€—æ—¶: {total_time:.2f}ç§’")
            logger.info(f"æˆåŠŸç‡: {final_results['summary']['success_rate']:.1%}")
            
            return final_results
            
        except Exception as e:
            logger.error(f"Agentæ¨ç†å®éªŒå¤±è´¥: {e}")
            return self._create_error_result(session_id, str(e))
    
    def _run_agent_reasoning_generation(
        self, documents: List[Dict], topic: str, session_id: str
    ) -> Dict[str, Any]:
        """è¿è¡ŒAgentæ¨ç†æµ‹è¯•æ•°æ®ç”Ÿæˆ"""
        logger.info("ğŸ§  å¼€å§‹ç”ŸæˆAgentæ¨ç†æµ‹è¯•æ•°æ®...")
        
        results = {
            'session_id': session_id,
            'mode': 'agent_reasoning',
            'topic': topic,
            'processed_documents': [],
            'statistics': {
                'total_documents': len(documents),
                'successful_documents': 0,
                'failed_documents': 0,
                'total_reasoning_trees': 0,
                'total_composite_queries': 0,
                'step_success_rates': {
                    'step1_root_queries': 0,
                    'step2_minimal_keywords': 0,
                    'step3_series_extensions': 0,
                    'step4_parallel_extensions': 0,
                    'step5_tree_building': 0,
                    'step6_composite_queries': 0
                }
            },
            'errors': []
        }
        
        for i, document in enumerate(documents):
            logger.info(f"ğŸ“„ å¤„ç†æ–‡æ¡£ {i+1}/{len(documents)}: {document['doc_id']}")
            
            try:
                # ä½¿ç”¨Agentæ¨ç†æ¡†æ¶å¤„ç†æ–‡æ¡£
                doc_result = self.agent_reasoning_framework.process_document_for_agent_reasoning(
                    document['content'], document['doc_id']
                )
                
                if doc_result.get('success'):
                    # æˆåŠŸå¤„ç†
                    reasoning_trees = doc_result.get('reasoning_trees', [])
                    composite_queries_count = sum(
                        1 for tree in reasoning_trees if tree.final_composite_query
                    )
                    
                    results['processed_documents'].append({
                        'doc_id': document['doc_id'],
                        'reasoning_trees': reasoning_trees,
                        'trajectory_records': doc_result.get('trajectory_records', []),
                        'processing_time': doc_result.get('processing_time', 0),
                        'total_trees': len(reasoning_trees),
                        'total_composite_queries': composite_queries_count
                    })
                    
                    results['statistics']['successful_documents'] += 1
                    results['statistics']['total_reasoning_trees'] += len(reasoning_trees)
                    results['statistics']['total_composite_queries'] += composite_queries_count
                    
                    logger.info(f"âœ… æ–‡æ¡£ {document['doc_id']} å¤„ç†æˆåŠŸ")
                    logger.info(f"   ç”Ÿæˆæ¨ç†æ ‘: {len(reasoning_trees)} ä¸ª")
                    logger.info(f"   ç»¼åˆé—®é¢˜: {composite_queries_count} ä¸ª")
                    
                else:
                    # å¤„ç†å¤±è´¥
                    results['statistics']['failed_documents'] += 1
                    results['errors'].append({
                        'doc_id': document['doc_id'],
                        'error': doc_result.get('error', 'Unknown error')
                    })
                    logger.warning(f"âŒ æ–‡æ¡£ {document['doc_id']} å¤„ç†å¤±è´¥: {doc_result.get('error', 'Unknown')}")
                
            except Exception as e:
                results['statistics']['failed_documents'] += 1
                results['errors'].append({
                    'doc_id': document['doc_id'],
                    'error': str(e)
                })
                logger.error(f"âŒ æ–‡æ¡£ {document['doc_id']} å¤„ç†å¼‚å¸¸: {e}")
        
        # æ›´æ–°å…¨å±€ç»Ÿè®¡
        self.experiment_stats['successful_documents'] += results['statistics']['successful_documents']
        self.experiment_stats['documents_processed'] += results['statistics']['total_documents']
        self.experiment_stats['total_reasoning_trees'] += results['statistics']['total_reasoning_trees']
        self.experiment_stats['total_composite_queries'] += results['statistics']['total_composite_queries']
        
        logger.info(f"âœ… Agentæ¨ç†æ•°æ®ç”Ÿæˆå®Œæˆ:")
        logger.info(f"  - æˆåŠŸå¤„ç†æ–‡æ¡£: {results['statistics']['successful_documents']}")
        logger.info(f"  - ç”Ÿæˆæ¨ç†æ ‘: {results['statistics']['total_reasoning_trees']}")
        logger.info(f"  - ç»¼åˆé—®é¢˜: {results['statistics']['total_composite_queries']}")
        
        return results
    
    def _generate_final_results(self, processing_results: Dict, session_id: str, total_time: float) -> Dict[str, Any]:
        """ç”Ÿæˆæœ€ç»ˆç»“æœ"""
        
        successful_docs = processing_results.get('statistics', {}).get('successful_documents', 0)
        total_docs = processing_results.get('statistics', {}).get('total_documents', 0)
        success_rate = successful_docs / max(total_docs, 1) if total_docs > 0 else 0
        
        return {
            'success': processing_results.get('success', True),
            'session_id': session_id,
            'mode': 'agent_reasoning',
            'total_processing_time': total_time,
            'processing_results': processing_results,
            'experiment_statistics': self.experiment_stats.copy(),
            'summary': {
                'total_documents_attempted': total_docs,
                'successful_documents': successful_docs,
                'failed_documents': processing_results.get('statistics', {}).get('failed_documents', 0),
                'success_rate': success_rate,
                'total_reasoning_trees': processing_results.get('statistics', {}).get('total_reasoning_trees', 0),
                'total_composite_queries': processing_results.get('statistics', {}).get('total_composite_queries', 0),
                'avg_processing_time': total_time / max(total_docs, 1) if total_docs > 0 else 0
            },
            'agent_reasoning_features': {
                'six_step_design': True,
                'minimal_precise_keywords': True,
                'no_correlation_requirement': True,
                'dynamic_tree_structure': True,
                'nested_composite_queries': True,
                'trajectory_recording': True,
                'agent_depth_testing': True
            }
        }
    
    def _save_complete_results(self, results: Dict, session_id: str):
        """ä¿å­˜å®Œæ•´ç»“æœ"""
        try:
            # åˆ›å»ºç»“æœç›®å½•
            results_dir = Path("results")
            results_dir.mkdir(exist_ok=True)
            
            # ä¿å­˜è¯¦ç»†JSONç»“æœ
            json_file = results_dir / f"{session_id}_agent_reasoning_results.json"
            with open(json_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2, default=str)
            
            # ä¿å­˜ç®€åŒ–æ‘˜è¦
            summary_file = results_dir / f"{session_id}_summary.json"
            summary_data = {
                'session_id': session_id,
                'mode': results.get('mode', 'agent_reasoning'),
                'success': results.get('success', False),
                'summary': results.get('summary', {}),
                'processing_time': results.get('total_processing_time', 0),
                'agent_features': results.get('agent_reasoning_features', {})
            }
            
            with open(summary_file, 'w', encoding='utf-8') as f:
                json.dump(summary_data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"ç»“æœå·²ä¿å­˜:")
            logger.info(f"  è¯¦ç»†ç»“æœ: {json_file}")
            logger.info(f"  æ‘˜è¦ç»“æœ: {summary_file}")
            
        except Exception as e:
            logger.error(f"ä¿å­˜ç»“æœå¤±è´¥: {e}")
    
    def _create_error_result(self, session_id: str, error_message: str) -> Dict[str, Any]:
        """åˆ›å»ºé”™è¯¯ç»“æœ"""
        return {
            'success': False,
            'session_id': session_id,
            'error': error_message,
            'experiment_statistics': self.experiment_stats.copy(),
            'summary': {
                'total_documents_attempted': 0,
                'successful_documents': 0,
                'success_rate': 0.0
            }
        }
    
    def get_framework_status(self) -> Dict[str, Any]:
        """è·å–æ¡†æ¶çŠ¶æ€"""
        return {
            'initialized': self.api_client is not None,
            'components_status': {
                'api_client': self.api_client is not None,
                'agent_reasoning_framework': self.agent_reasoning_framework is not None,
                'document_loader': True,
                'document_screener': True
            },
            'experiment_stats': self.experiment_stats.copy(),
            'framework_features': [
                'six_step_design_flow',
                'minimal_precise_keywords',
                'no_correlation_validation',
                'dynamic_tree_structure',
                'nested_composite_queries',
                'trajectory_recording',
                'agent_depth_testing'
            ]
        }

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ Agentæ·±åº¦æ¨ç†æµ‹è¯•æ¡†æ¶")
    print("=" * 80)
    print("ğŸ¯ æ ¸å¿ƒç›®æ ‡:")
    print("  ğŸ¤– ä¸ºæ™ºèƒ½Agentç”Ÿæˆæ·±åº¦æ¨ç†æµ‹è¯•é¢˜")
    print("  ğŸš« é˜²æ­¢æ™®é€šLLMç›´æ¥è·å–ç­”æ¡ˆ")
    print("  ğŸ§  è®­ç»ƒAgenté€æ­¥æ¨ç†èƒ½åŠ›")
    print("  ğŸ”— ç”ŸæˆåµŒå¥—å¼ç»¼åˆé—®é¢˜")
    print("=" * 80)
    print("ğŸ“‹ æ–°çš„6æ­¥è®¾è®¡æµç¨‹:")
    print("  Step1: æå–Short Answer + æ„å»ºæœ€å°ç²¾ç¡®é—®é¢˜")
    print("  Step2: æå–Root Queryçš„æœ€å°å…³é”®è¯")
    print("  Step3: é’ˆå¯¹æ¯ä¸ªå…³é”®è¯åšSeriesæ·±åº¦æ‰©å±•")
    print("  Step4: é’ˆå¯¹æ‰€æœ‰å…³é”®è¯åšParallelæ¨ªå‘æ‰©å±•")
    print("  Step5: é‡å¤æ„å»ºæœ€å¤š3å±‚é—®é¢˜æ ‘")
    print("  Step6: ç³…åˆç”Ÿæˆæœ€ç»ˆç»¼åˆé—®é¢˜")
    print("=" * 80)
    
    # è·å–ç”¨æˆ·è¾“å…¥
    try:
        api_key = input("è¯·è¾“å…¥OpenAI APIå¯†é’¥: ").strip()
        if not api_key:
            print("âŒ APIå¯†é’¥ä¸èƒ½ä¸ºç©º")
            return False
        
        # å‘ç°å¯ç”¨çš„ClueWeb22 topics
        print("\nğŸ” æ­£åœ¨æ‰«æClueWeb22æ•°æ®é›†...")
        document_loader = DocumentLoader()
        available_topics = document_loader.discover_topics()
        
        if not available_topics:
            print("âŒ æœªæ‰¾åˆ°å¯ç”¨çš„ClueWeb22 topicsï¼Œè¯·æ£€æŸ¥æ•°æ®è·¯å¾„")
            print(f"æ•°æ®è·¯å¾„: {document_loader.config.clueweb22_path}")
            return False
        
        # æ˜¾ç¤ºå¯ç”¨topicså¹¶è®©ç”¨æˆ·é€‰æ‹©
        print(f"\nğŸ“‹ å‘ç° {len(available_topics)} ä¸ªå¯ç”¨topics:")
        for i, topic in enumerate(available_topics, 1):
            print(f"  {i}. {topic}")
        
        while True:
            try:
                choice_input = input(f"\nè¯·é€‰æ‹©topic [1-{len(available_topics)}] (é»˜è®¤: 1): ").strip()
                if not choice_input:
                    choice = 1
                else:
                    choice = int(choice_input)
                
                if 1 <= choice <= len(available_topics):
                    selected_topic = available_topics[choice - 1]
                    break
                else:
                    print(f"âŒ è¯·è¾“å…¥ 1-{len(available_topics)} ä¹‹é—´çš„æ•°å­—")
            except ValueError:
                print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
        
        max_docs_input = input("è¯·è¾“å…¥æœ€å¤§æ–‡æ¡£æ•° (é»˜è®¤: 10): ").strip()
        max_docs = int(max_docs_input) if max_docs_input.isdigit() else 10
        
        print(f"\nğŸ¯ å®éªŒé…ç½®ç¡®è®¤:")
        print(f"  é€‰æ‹©çš„Topic: {selected_topic}")
        print(f"  æ¨¡å¼: Agentæ·±åº¦æ¨ç†æµ‹è¯•")
        print(f"  æœ€å¤§æ–‡æ¡£æ•°: {max_docs}")
        print(f"  è®¾è®¡ç†å¿µ: ä¸ºAgentå‡ºé¢˜ï¼Œé˜²æ­¢æ™®é€šLLMç›´æ¥ç­”é¢˜")
        print(f"  é—®é¢˜ç»“æ„: æœ€å°ç²¾ç¡®å…³é”®è¯ + æ— å…³è”æ€§ + åµŒå¥—ç»¼åˆ")
        
        confirm = input("\næ˜¯å¦ç»§ç»­? [y/N]: ").strip().lower()
        if confirm != 'y':
            print("å–æ¶ˆè¿è¡Œ")
            return False
        
        # åˆå§‹åŒ–å¹¶è¿è¡Œæ¡†æ¶
        framework = AgentReasoningMainFramework()
        
        if not framework.initialize_framework(api_key):
            print("âŒ æ¡†æ¶åˆå§‹åŒ–å¤±è´¥")
            return False
        
        # æ˜¾ç¤ºæ¡†æ¶çŠ¶æ€
        status = framework.get_framework_status()
        print(f"\nğŸ“Š æ¡†æ¶çŠ¶æ€:")
        print(f"  åˆå§‹åŒ–çŠ¶æ€: {'âœ…' if status['initialized'] else 'âŒ'}")
        print(f"  Agentæ¨ç†æ¡†æ¶: âœ…")
        print(f"  6æ­¥è®¾è®¡æµç¨‹: âœ…")
        print(f"  è½¨è¿¹è®°å½•: âœ…")
        print(f"  æ— å…³è”æ€§éªŒè¯: âœ…")
        
        # è¿è¡Œå®éªŒ
        print(f"\nğŸš€ å¼€å§‹è¿è¡ŒAgentæ·±åº¦æ¨ç†å®éªŒ...")
        results = framework.run_agent_reasoning_experiment(selected_topic, max_docs)
        
        # æ˜¾ç¤ºç»“æœæ‘˜è¦
        print(f"\nğŸ“Š å®éªŒç»“æœæ‘˜è¦:")
        print(f"  æˆåŠŸ: {'âœ…' if results['success'] else 'âŒ'}")
        
        if results['success']:
            summary = results['summary']
            print(f"  å¤„ç†æ–‡æ¡£: {summary.get('successful_documents', 0)}/{summary.get('total_documents_attempted', 0)}")
            print(f"  æˆåŠŸç‡: {summary.get('success_rate', 0):.1%}")
            print(f"  æ¨ç†æ ‘: {summary.get('total_reasoning_trees', 0)} ä¸ª")
            print(f"  ç»¼åˆé—®é¢˜: {summary.get('total_composite_queries', 0)} ä¸ª")
            print(f"  æ€»è€—æ—¶: {results.get('total_processing_time', 0):.2f}ç§’")
        else:
            print(f"  é”™è¯¯: {results.get('error', 'Unknown error')}")
        
        print(f"\nâœ… Agentæ¨ç†å®éªŒå®Œæˆï¼Œç»“æœå·²ä¿å­˜åˆ° results/ ç›®å½•")
        return results['success']
        
    except KeyboardInterrupt:
        print("\n\nç”¨æˆ·ä¸­æ–­å®éªŒ")
        return False
    except Exception as e:
        print(f"\nâŒ å®éªŒè¿è¡Œå¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    success = main()
    exit(0 if success else 1) 