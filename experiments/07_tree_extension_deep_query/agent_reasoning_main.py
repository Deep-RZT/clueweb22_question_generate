#!/usr/bin/env python3
"""
Agentæ·±åº¦æ¨ç†æµ‹è¯•æ¡†æ¶ - ä¸»å…¥å£æ–‡ä»¶
Agent Depth Reasoning Test Framework - Main Entry Point

åŸºäºå…¨æ–°çš„6æ­¥è®¾è®¡ï¼Œä¸ºæ™ºèƒ½Agentæ„å»ºæ·±åº¦æ¨ç†æµ‹è¯•é¢˜åº“
æ ¸å¿ƒç›®æ ‡ï¼šè®©æ™®é€šLLMæ— æ³•ç›´æ¥ç­”é¢˜ï¼Œéœ€è¦Agenté€æ­¥æ¨ç†è§£å†³
"""

import logging
import sys
import os
import time
import json
from pathlib import Path
from typing import Dict, List, Optional, Any

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

# å¯¼å…¥æ ¸å¿ƒç»„ä»¶
from config import get_config
from core.llm_clients.openai_api_client import OpenAIClient
from document_loader import DocumentLoader
from document_screener import DocumentScreener
from agent_depth_reasoning_framework_fixed import AgentDepthReasoningFramework
from agent_export_system import AgentExportSystem
from web_search import web_search

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('agent_reasoning_experiment.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class AgentReasoningMainFramework:
    """Agentæ¨ç†æµ‹è¯•ä¸»æ¡†æ¶"""
    
    def __init__(self):
        self.config = get_config()
        self.api_client = None
        self.search_client = web_search
        
        # æ ¸å¿ƒç»„ä»¶
        self.document_loader = DocumentLoader()
        self.document_screener = DocumentScreener()
        self.agent_reasoning_framework = None
        self.export_system = AgentExportSystem()
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.experiment_stats = {
            'session_start_time': time.time(),
            'documents_processed': 0,
            'successful_documents': 0,
            'failed_documents': 0,
            'total_reasoning_trees': 0,
            'total_composite_queries': 0,
            'step1_success_rate': 0.0,
            'step2_success_rate': 0.0,
            'step6_success_rate': 0.0
        }
    
    def initialize_framework(self, api_key: str) -> bool:
        """åˆå§‹åŒ–æ¡†æ¶ç»„ä»¶"""
        try:
            logger.info("ğŸ¯ åˆå§‹åŒ–Agentæ·±åº¦æ¨ç†æµ‹è¯•æ¡†æ¶...")
            
            # åˆå§‹åŒ–APIå®¢æˆ·ç«¯
            self.api_client = OpenAIClient(api_key=api_key)
            
            # è®¾ç½®APIå®¢æˆ·ç«¯åˆ°å„ç»„ä»¶
            self.document_screener.set_api_client(self.api_client)
            
            # åˆå§‹åŒ–Agentæ¨ç†æ¡†æ¶
            self.agent_reasoning_framework = AgentDepthReasoningFramework(
                api_client=self.api_client,
                search_client=self.search_client
            )
            
            logger.info("âœ… Agentæ¨ç†æ¡†æ¶åˆå§‹åŒ–å®Œæˆ")
            logger.info("ğŸ¯ æ¡†æ¶ç›®æ ‡:")
            logger.info("  - ä¸ºæ™ºèƒ½Agentç”Ÿæˆæ·±åº¦æ¨ç†æµ‹è¯•é¢˜")
            logger.info("  - é˜²æ­¢æ™®é€šLLMç›´æ¥è·å–ç­”æ¡ˆ")
            logger.info("  - é€šè¿‡å¤šå±‚çº§é—®é¢˜æ ‘è®­ç»ƒé€æ­¥æ¨ç†")
            logger.info("  - ç”ŸæˆåµŒå¥—å¼ç»¼åˆé—®é¢˜")
            
            return True
            
        except Exception as e:
            logger.error(f"æ¡†æ¶åˆå§‹åŒ–å¤±è´¥: {e}")
            return False
    
    def run_agent_reasoning_experiment(self, topic: str, max_documents: int = 20) -> Dict[str, Any]:
        """
        è¿è¡ŒAgentæ¨ç†æµ‹è¯•å®éªŒ
        
        Args:
            topic: ClueWeb22ä¸»é¢˜åç§°
            max_documents: æœ€å¤§å¤„ç†æ–‡æ¡£æ•°
        """
        logger.info(f"ğŸš€ å¯åŠ¨Agentæ·±åº¦æ¨ç†å®éªŒ: {topic}")
        logger.info(f"æœ€å¤§æ–‡æ¡£æ•°: {max_documents}")
        
        session_id = f"agent_reasoning_{topic}_{int(time.time())}"
        start_time = time.time()
        
        try:
            # 1. åŠ è½½æ–‡æ¡£
            logger.info("ğŸ“„ åŠ è½½ClueWeb22æ–‡æ¡£...")
            document_data_list = self.document_loader.load_documents_from_topic(topic, max_documents)
            
            if not document_data_list:
                return self._create_error_result(session_id, "No documents loaded")
            
            logger.info(f"åŠ è½½æ–‡æ¡£æ•°: {len(document_data_list)}")
            
            # 2. æ–‡æ¡£ç­›é€‰ï¼ˆå¯é€‰ï¼‰
            logger.info("ğŸ” æ–‡æ¡£è´¨é‡é¢„ç­›é€‰...")
            screened_documents = []
            
            for doc_data in document_data_list[:max_documents]:
                # åŸºæœ¬è´¨é‡æ£€æŸ¥
                if len(doc_data.content) < 200:
                    logger.info(f"è·³è¿‡çŸ­æ–‡æ¡£: {doc_data.doc_id} (é•¿åº¦: {len(doc_data.content)})")
                    continue
                
                screened_documents.append({
                    'doc_id': doc_data.doc_id,
                    'content': doc_data.content,
                    'topic': doc_data.topic,
                    'length': len(doc_data.content)
                })
                
                if len(screened_documents) >= max_documents:
                    break
            
            logger.info(f"ç­›é€‰åæ–‡æ¡£æ•°: {len(screened_documents)}")
            
            # 3. Agentæ¨ç†æµ‹è¯•æ•°æ®ç”Ÿæˆ
            results = self._run_agent_reasoning_generation(screened_documents, topic, session_id)
            
            # 4. è®¡ç®—æœ€ç»ˆç»Ÿè®¡
            total_time = time.time() - start_time
            final_results = self._generate_final_results(results, session_id, total_time)
            
            # 5. å¯¼å‡ºç»“æœï¼ˆä½¿ç”¨æ–°çš„å¯¼å‡ºç³»ç»Ÿï¼‰
            exported_files = self.export_system.export_agent_reasoning_results(final_results, session_id)
            
            logger.info(f"âœ… Agentæ¨ç†å®éªŒå®Œæˆ: {session_id}")
            logger.info(f"æ€»è€—æ—¶: {total_time:.2f}ç§’")
            logger.info(f"æˆåŠŸç‡: {final_results['summary']['success_rate']:.1%}")
            
            return final_results
            
        except Exception as e:
            logger.error(f"Agentæ¨ç†å®éªŒå¤±è´¥: {e}")
            return self._create_error_result(session_id, str(e))
    
    def _run_agent_reasoning_generation(
        self, documents: List[Dict], topic: str, session_id: str
    ) -> Dict[str, Any]:
        """è¿è¡ŒAgentæ¨ç†æµ‹è¯•æ•°æ®ç”Ÿæˆ"""
        logger.info("ğŸ§  å¼€å§‹ç”ŸæˆAgentæ¨ç†æµ‹è¯•æ•°æ®...")
        
        results = {
            'session_id': session_id,
            'mode': 'agent_reasoning',
            'topic': topic,
            'processed_documents': [],
            'statistics': {
                'total_documents': len(documents),
                'successful_documents': 0,
                'failed_documents': 0,
                'total_reasoning_trees': 0,
                'total_composite_queries': 0,
                'step_success_rates': {
                    'step1_root_queries': 0,
                    'step2_minimal_keywords': 0,
                    'step3_series_extensions': 0,
                    'step4_parallel_extensions': 0,
                    'step5_tree_building': 0,
                    'step6_composite_queries': 0
                }
            },
            'errors': []
        }
        
        for i, document in enumerate(documents):
            logger.info(f"ğŸ“„ å¤„ç†æ–‡æ¡£ {i+1}/{len(documents)}: {document['doc_id']}")
            
            try:
                # ä½¿ç”¨Agentæ¨ç†æ¡†æ¶å¤„ç†æ–‡æ¡£
                doc_result = self.agent_reasoning_framework.process_document_for_agent_reasoning(
                    document['content'], document['doc_id']
                )
                
                if doc_result.get('success'):
                    # æˆåŠŸå¤„ç†
                    reasoning_trees = doc_result.get('reasoning_trees', [])
                    composite_queries_count = sum(
                        1 for tree in reasoning_trees if tree.final_composite_query
                    )
                    
                    results['processed_documents'].append({
                        'doc_id': document['doc_id'],
                        'reasoning_trees': reasoning_trees,
                        'trajectory_records': doc_result.get('trajectory_records', []),
                        'processing_time': doc_result.get('processing_time', 0),
                        'total_trees': len(reasoning_trees),
                        'total_composite_queries': composite_queries_count
                    })
                    
                    results['statistics']['successful_documents'] += 1
                    results['statistics']['total_reasoning_trees'] += len(reasoning_trees)
                    results['statistics']['total_composite_queries'] += composite_queries_count
                    
                    logger.info(f"âœ… æ–‡æ¡£ {document['doc_id']} å¤„ç†æˆåŠŸ")
                    logger.info(f"   ç”Ÿæˆæ¨ç†æ ‘: {len(reasoning_trees)} ä¸ª")
                    logger.info(f"   ç»¼åˆé—®é¢˜: {composite_queries_count} ä¸ª")
                    
                else:
                    # å¤„ç†å¤±è´¥
                    results['statistics']['failed_documents'] += 1
                    results['errors'].append({
                        'doc_id': document['doc_id'],
                        'error': doc_result.get('error', 'Unknown error')
                    })
                    logger.warning(f"âŒ æ–‡æ¡£ {document['doc_id']} å¤„ç†å¤±è´¥: {doc_result.get('error', 'Unknown')}")
                
            except Exception as e:
                results['statistics']['failed_documents'] += 1
                results['errors'].append({
                    'doc_id': document['doc_id'],
                    'error': str(e)
                })
                logger.error(f"âŒ æ–‡æ¡£ {document['doc_id']} å¤„ç†å¼‚å¸¸: {e}")
        
        # æ›´æ–°å…¨å±€ç»Ÿè®¡
        self.experiment_stats['successful_documents'] += results['statistics']['successful_documents']
        self.experiment_stats['documents_processed'] += results['statistics']['total_documents']
        self.experiment_stats['total_reasoning_trees'] += results['statistics']['total_reasoning_trees']
        self.experiment_stats['total_composite_queries'] += results['statistics']['total_composite_queries']
        
        logger.info(f"âœ… Agentæ¨ç†æ•°æ®ç”Ÿæˆå®Œæˆ:")
        logger.info(f"  - æˆåŠŸå¤„ç†æ–‡æ¡£: {results['statistics']['successful_documents']}")
        logger.info(f"  - ç”Ÿæˆæ¨ç†æ ‘: {results['statistics']['total_reasoning_trees']}")
        logger.info(f"  - ç»¼åˆé—®é¢˜: {results['statistics']['total_composite_queries']}")
        
        return results
    
    def _generate_final_results(self, processing_results: Dict, session_id: str, total_time: float) -> Dict[str, Any]:
        """ç”Ÿæˆæœ€ç»ˆç»“æœ"""
        
        successful_docs = processing_results.get('statistics', {}).get('successful_documents', 0)
        total_docs = processing_results.get('statistics', {}).get('total_documents', 0)
        success_rate = successful_docs / max(total_docs, 1) if total_docs > 0 else 0
        
        return {
            'success': processing_results.get('success', True),
            'session_id': session_id,
            'mode': 'agent_reasoning',
            'total_processing_time': total_time,
            'processing_results': processing_results,
            'experiment_statistics': self.experiment_stats.copy(),
            'summary': {
                'total_documents_attempted': total_docs,
                'successful_documents': successful_docs,
                'failed_documents': processing_results.get('statistics', {}).get('failed_documents', 0),
                'success_rate': success_rate,
                'total_reasoning_trees': processing_results.get('statistics', {}).get('total_reasoning_trees', 0),
                'total_composite_queries': processing_results.get('statistics', {}).get('total_composite_queries', 0),
                'avg_processing_time': total_time / max(total_docs, 1) if total_docs > 0 else 0
            },
            'agent_reasoning_features': {
                'six_step_design': True,
                'minimal_precise_keywords': True,
                'no_correlation_requirement': True,
                'dynamic_tree_structure': True,
                'nested_composite_queries': True,
                'trajectory_recording': True,
                'agent_depth_testing': True
            }
        }
    
    def _save_complete_results(self, results: Dict, session_id: str):
        """ä¿å­˜å®Œæ•´ç»“æœ"""
        try:
            # åˆ›å»ºç»“æœç›®å½•
            results_dir = Path("results")
            results_dir.mkdir(exist_ok=True)
            
            # ä¿å­˜è¯¦ç»†JSONç»“æœ
            json_file = results_dir / f"{session_id}_agent_reasoning_results.json"
            with open(json_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2, default=str)
            
            # ä¿å­˜ç®€åŒ–æ‘˜è¦
            summary_file = results_dir / f"{session_id}_summary.json"
            summary_data = {
                'session_id': session_id,
                'mode': results.get('mode', 'agent_reasoning'),
                'success': results.get('success', False),
                'summary': results.get('summary', {}),
                'processing_time': results.get('total_processing_time', 0),
                'agent_features': results.get('agent_reasoning_features', {})
            }
            
            with open(summary_file, 'w', encoding='utf-8') as f:
                json.dump(summary_data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"ç»“æœå·²ä¿å­˜:")
            logger.info(f"  è¯¦ç»†ç»“æœ: {json_file}")
            logger.info(f"  æ‘˜è¦ç»“æœ: {summary_file}")
            
        except Exception as e:
            logger.error(f"ä¿å­˜ç»“æœå¤±è´¥: {e}")
    
    def _create_error_result(self, session_id: str, error_message: str) -> Dict[str, Any]:
        """åˆ›å»ºé”™è¯¯ç»“æœ"""
        return {
            'success': False,
            'session_id': session_id,
            'error': error_message,
            'experiment_statistics': self.experiment_stats.copy(),
            'summary': {
                'total_documents_attempted': 0,
                'successful_documents': 0,
                'success_rate': 0.0
            }
        }
    
    def get_framework_status(self) -> Dict[str, Any]:
        """è·å–æ¡†æ¶çŠ¶æ€"""
        return {
            'initialized': self.api_client is not None,
            'components_status': {
                'api_client': self.api_client is not None,
                'agent_reasoning_framework': self.agent_reasoning_framework is not None,
                'document_loader': True,
                'document_screener': True
            },
            'experiment_stats': self.experiment_stats.copy(),
            'framework_features': [
                'six_step_design_flow',
                'minimal_precise_keywords',
                'no_correlation_validation',
                'dynamic_tree_structure',
                'nested_composite_queries',
                'trajectory_recording',
                'agent_depth_testing'
            ]
        }

    def run_agent_reasoning_experiment_production(self, topic: str) -> Dict[str, Any]:
        """
        è¿è¡Œç”Ÿäº§çº§åˆ«Agentæ¨ç†æµ‹è¯•å®éªŒ - å…¨é‡å¤„ç†
        
        Args:
            topic: ClueWeb22ä¸»é¢˜åç§°
        """
        logger.info(f"ğŸ­ å¯åŠ¨ç”Ÿäº§çº§åˆ«Agentæ·±åº¦æ¨ç†å®éªŒ: {topic}")
        
        session_id = f"agent_reasoning_production_{topic}_{int(time.time())}"
        start_time = time.time()
        
        try:
            # 1. åŠ è½½æ‰€æœ‰æ–‡æ¡£
            logger.info("ğŸ“„ åŠ è½½ClueWeb22æ–‡æ¡£...")
            print("ğŸ“„ æ­£åœ¨åŠ è½½æ‰€æœ‰æ–‡æ¡£...")
            
            document_data_list = self.document_loader.load_documents_from_topic(topic, max_docs=None)
            
            if not document_data_list:
                return self._create_error_result(session_id, "No documents loaded")
            
            total_docs = len(document_data_list)
            logger.info(f"ğŸ“Š åŠ è½½æ–‡æ¡£æ€»æ•°: {total_docs}")
            print(f"ğŸ“Š å·²åŠ è½½ {total_docs} ä¸ªæ–‡æ¡£")
            
            # 2. æ–‡æ¡£é¢„ç­›é€‰
            logger.info("ğŸ” æ–‡æ¡£è´¨é‡é¢„ç­›é€‰...")
            print("ğŸ” æ­£åœ¨è¿›è¡Œæ–‡æ¡£è´¨é‡ç­›é€‰...")
            
            screened_documents = []
            skipped_count = 0
            
            for doc_data in document_data_list:
                # åŸºæœ¬è´¨é‡æ£€æŸ¥
                if len(doc_data.content) < 200:
                    skipped_count += 1
                    logger.debug(f"è·³è¿‡çŸ­æ–‡æ¡£: {doc_data.doc_id} (é•¿åº¦: {len(doc_data.content)})")
                    continue
                
                screened_documents.append({
                    'doc_id': doc_data.doc_id,
                    'content': doc_data.content,
                    'topic': doc_data.topic,
                    'length': len(doc_data.content)
                })
            
            final_doc_count = len(screened_documents)
            logger.info(f"âœ… ç­›é€‰å®Œæˆ: {final_doc_count}/{total_docs} ä¸ªæ–‡æ¡£é€šè¿‡ç­›é€‰")
            print(f"âœ… ç­›é€‰å®Œæˆ: {final_doc_count}/{total_docs} ä¸ªæ–‡æ¡£é€šè¿‡ç­›é€‰ (è·³è¿‡{skipped_count}ä¸ªçŸ­æ–‡æ¡£)")
            
            # 3. ç”Ÿäº§çº§åˆ«å¤„ç†
            print(f"\nğŸš€ å¼€å§‹ç”Ÿäº§çº§åˆ«å¤„ç† {final_doc_count} ä¸ªæ–‡æ¡£")
            print("=" * 60)
            
            results = self._run_agent_reasoning_generation_production(
                screened_documents, topic, session_id
            )
            
            # 4. ç”Ÿæˆæœ€ç»ˆç»“æœ
            total_time = time.time() - start_time
            final_results = self._generate_final_results(results, session_id, total_time)
            
            # 5. å¯¼å‡ºç»“æœï¼ˆJSON + Excelï¼‰
            exported_files = self.export_system.export_agent_reasoning_results(final_results, session_id)
            self._save_production_results(final_results, topic, session_id)
            
            # æ˜¾ç¤ºå¯¼å‡ºç»“æœ
            print(f"\nğŸ’¾ ç»“æœå¯¼å‡ºå®Œæˆ:")
            for format_type, file_path in exported_files.items():
                print(f"   {format_type.upper()}: {file_path}")
            
            logger.info(f"ğŸ‰ ç”Ÿäº§å®éªŒå®Œæˆ: æ€»è€—æ—¶ {total_time/60:.1f} åˆ†é’Ÿ")
            return final_results
            
        except Exception as e:
            logger.error(f"ç”Ÿäº§å®éªŒå¤±è´¥ {topic}: {e}")
            return self._create_error_result(session_id, str(e))
    
    def _run_agent_reasoning_generation_production(
        self, documents: List[Dict], topic: str, session_id: str
    ) -> Dict[str, Any]:
        """è¿è¡Œç”Ÿäº§çº§åˆ«çš„Agentæ¨ç†æµ‹è¯•æ•°æ®ç”Ÿæˆ"""
        logger.info("ğŸ§  å¼€å§‹ç”Ÿäº§çº§åˆ«Agentæ¨ç†æµ‹è¯•æ•°æ®ç”Ÿæˆ...")
        
        results = {
            'session_id': session_id,
            'mode': 'agent_reasoning_production',
            'topic': topic,
            'processed_documents': [],
            'statistics': {
                'total_documents': len(documents),
                'successful_documents': 0,
                'failed_documents': 0,
                'total_reasoning_trees': 0,
                'total_composite_queries': 0,
                'processing_times': [],
                'step_success_rates': {
                    'step1_root_queries': 0,
                    'step2_minimal_keywords': 0,
                    'step3_series_extensions': 0,
                    'step4_parallel_extensions': 0,
                    'step5_tree_building': 0,
                    'step6_composite_queries': 0
                }
            },
            'errors': [],
            'success': True
        }
        
        total_docs = len(documents)
        
        for i, document in enumerate(documents):
            current_doc_num = i + 1
            doc_id = document['doc_id']
            
            # è¯¦ç»†çš„è¿›åº¦æ—¥å¿—
            print(f"\nğŸ“„ å¤„ç†æ–‡æ¡£ [{current_doc_num:>3}/{total_docs}]: {doc_id}")
            print(f"   ğŸ“ æ–‡æ¡£é•¿åº¦: {document['length']:,} å­—ç¬¦")
            
            doc_start_time = time.time()
            
            try:
                # ä½¿ç”¨Agentæ¨ç†æ¡†æ¶å¤„ç†æ–‡æ¡£
                logger.info(f"ğŸ”„ å¼€å§‹å¤„ç†æ–‡æ¡£ {current_doc_num}/{total_docs}: {doc_id}")
                
                doc_result = self.agent_reasoning_framework.process_document_for_agent_reasoning(
                    document['content'], doc_id
                )
                
                doc_processing_time = time.time() - doc_start_time
                results['statistics']['processing_times'].append(doc_processing_time)
                
                if doc_result.get('success'):
                    # æˆåŠŸå¤„ç†
                    reasoning_trees = doc_result.get('reasoning_trees', [])
                    composite_queries_count = sum(
                        1 for tree in reasoning_trees if tree.final_composite_query
                    )
                    
                    results['processed_documents'].append({
                        'doc_id': doc_id,
                        'reasoning_trees': reasoning_trees,
                        'trajectory_records': doc_result.get('trajectory_records', []),
                        'processing_time': doc_processing_time,
                        'total_trees': len(reasoning_trees),
                        'total_composite_queries': composite_queries_count
                    })
                    
                    results['statistics']['successful_documents'] += 1
                    results['statistics']['total_reasoning_trees'] += len(reasoning_trees)
                    results['statistics']['total_composite_queries'] += composite_queries_count
                    
                    # æˆåŠŸæ—¥å¿—
                    print(f"   âœ… å¤„ç†æˆåŠŸ ({doc_processing_time:.1f}ç§’)")
                    print(f"   ğŸŒ³ æ¨ç†æ ‘: {len(reasoning_trees)} ä¸ª")
                    print(f"   â“ ç»¼åˆé—®é¢˜: {composite_queries_count} ä¸ª")
                    
                    logger.info(f"âœ… æ–‡æ¡£ {doc_id} å¤„ç†æˆåŠŸ: {len(reasoning_trees)} ä¸ªæ¨ç†æ ‘, {composite_queries_count} ä¸ªç»¼åˆé—®é¢˜")
                    
                else:
                    # å¤„ç†å¤±è´¥
                    error_msg = doc_result.get('error', 'Unknown error')
                    results['statistics']['failed_documents'] += 1
                    results['errors'].append({
                        'doc_id': doc_id,
                        'error': error_msg,
                        'processing_time': doc_processing_time
                    })
                    
                    print(f"   âŒ å¤„ç†å¤±è´¥ ({doc_processing_time:.1f}ç§’): {error_msg}")
                    logger.warning(f"âŒ æ–‡æ¡£ {doc_id} å¤„ç†å¤±è´¥: {error_msg}")
                
                # è¿›åº¦ç»Ÿè®¡
                success_rate = results['statistics']['successful_documents'] / current_doc_num
                avg_time = sum(results['statistics']['processing_times']) / len(results['statistics']['processing_times'])
                remaining_docs = total_docs - current_doc_num
                eta_minutes = (remaining_docs * avg_time) / 60
                
                print(f"   ğŸ“Š è¿›åº¦: {success_rate:.1%} æˆåŠŸç‡, å¹³å‡ {avg_time:.1f}ç§’/æ–‡æ¡£, é¢„è®¡å‰©ä½™ {eta_minutes:.1f} åˆ†é’Ÿ")
                
                # æ¯å¤„ç†10ä¸ªæ–‡æ¡£æ˜¾ç¤ºä¸€æ¬¡æ€»ä½“è¿›åº¦
                if current_doc_num % 10 == 0 or current_doc_num == total_docs:
                    print(f"\nğŸ“ˆ æ€»ä½“è¿›åº¦: {current_doc_num}/{total_docs} å®Œæˆ ({current_doc_num/total_docs:.1%})")
                    print(f"   âœ… æˆåŠŸ: {results['statistics']['successful_documents']} ä¸ª")
                    print(f"   âŒ å¤±è´¥: {results['statistics']['failed_documents']} ä¸ª")
                    print(f"   ğŸŒ³ æ€»æ¨ç†æ ‘: {results['statistics']['total_reasoning_trees']} ä¸ª")
                    print(f"   â“ æ€»ç»¼åˆé—®é¢˜: {results['statistics']['total_composite_queries']} ä¸ª")
                    
                    # è‡ªåŠ¨ä¿å­˜ä¸­é—´ç»“æœ
                    if current_doc_num % 20 == 0:
                        self._save_intermediate_results(results, topic, session_id, current_doc_num)
                        print(f"   ğŸ’¾ ä¸­é—´ç»“æœå·²ä¿å­˜ (ç¬¬{current_doc_num}ä¸ªæ–‡æ¡£)")
                
            except Exception as e:
                doc_processing_time = time.time() - doc_start_time
                error_msg = f"æ–‡æ¡£å¤„ç†å¼‚å¸¸: {str(e)}"
                
                results['statistics']['failed_documents'] += 1
                results['errors'].append({
                    'doc_id': doc_id,
                    'error': error_msg,
                    'processing_time': doc_processing_time
                })
                
                print(f"   ğŸ’¥ å¼‚å¸¸é”™è¯¯ ({doc_processing_time:.1f}ç§’): {str(e)}")
                logger.error(f"ğŸ’¥ æ–‡æ¡£ {doc_id} å¤„ç†å¼‚å¸¸: {e}")
        
        print(f"\n" + "=" * 60)
        print(f"ğŸ¯ ç”Ÿäº§å¤„ç†å®Œæˆ!")
        print(f"   ğŸ“Š æ€»æ–‡æ¡£: {total_docs}")
        print(f"   âœ… æˆåŠŸ: {results['statistics']['successful_documents']}")
        print(f"   âŒ å¤±è´¥: {results['statistics']['failed_documents']}")
        print(f"   ğŸ“ˆ æˆåŠŸç‡: {results['statistics']['successful_documents']/total_docs:.1%}")
        print(f"   ğŸŒ³ æ€»æ¨ç†æ ‘: {results['statistics']['total_reasoning_trees']}")
        print(f"   â“ æ€»ç»¼åˆé—®é¢˜: {results['statistics']['total_composite_queries']}")
        
        return results
    
    def _save_production_results(self, results: Dict[str, Any], topic: str, session_id: str):
        """ä¿å­˜ç”Ÿäº§ç»“æœ"""
        try:
            # ç¡®ä¿ç»“æœç›®å½•å­˜åœ¨
            results_dir = Path("results")
            results_dir.mkdir(exist_ok=True)
            
            # ç”Ÿæˆæ–‡ä»¶å
            from datetime import datetime
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            # ä¿å­˜å®Œæ•´ç»“æœJSON
            json_filename = f"agent_reasoning_production_{topic}_{timestamp}.json"
            json_path = results_dir / json_filename
            
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(results, f, indent=2, ensure_ascii=False, default=str)
            
            logger.info(f"ğŸ’¾ ç”Ÿäº§ç»“æœå·²ä¿å­˜: {json_path}")
            print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {json_filename}")
            
        except Exception as e:
            logger.error(f"ä¿å­˜ç”Ÿäº§ç»“æœå¤±è´¥: {e}")
            print(f"âš ï¸  ä¿å­˜ç»“æœå¤±è´¥: {e}")
    
    def _save_intermediate_results(self, results: Dict[str, Any], topic: str, session_id: str, doc_count: int):
        """ä¿å­˜ä¸­é—´ç»“æœ"""
        try:
            results_dir = Path("results")
            results_dir.mkdir(exist_ok=True)
            
            from datetime import datetime
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"agent_reasoning_intermediate_{topic}_{doc_count}docs_{timestamp}.json"
            filepath = results_dir / filename
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(results, f, indent=2, ensure_ascii=False, default=str)
            
            logger.info(f"ğŸ’¾ ä¸­é—´ç»“æœå·²ä¿å­˜: {filepath}")
            
        except Exception as e:
            logger.error(f"ä¿å­˜ä¸­é—´ç»“æœå¤±è´¥: {e}")


def main():
    """ç”Ÿäº§çº§åˆ«ä¸»å‡½æ•° - å…¨é‡å¤„ç†ClueWeb22æ•°æ®"""
    print("ğŸ¯ Agentæ·±åº¦æ¨ç†æµ‹è¯•æ¡†æ¶ - ç”Ÿäº§ç‰ˆæœ¬")
    print("=" * 80)
    print("ğŸ¯ æ ¸å¿ƒç›®æ ‡:")
    print("  ğŸ¤– ä¸ºæ™ºèƒ½Agentç”Ÿæˆæ·±åº¦æ¨ç†æµ‹è¯•é¢˜")
    print("  ğŸš« é˜²æ­¢æ™®é€šLLMç›´æ¥è·å–ç­”æ¡ˆ")
    print("  ğŸ§  è®­ç»ƒAgenté€æ­¥æ¨ç†èƒ½åŠ›")
    print("  ğŸ”— ç”ŸæˆåµŒå¥—å¼ç»¼åˆé—®é¢˜")
    print("=" * 80)
    print("ğŸ“‹ 6æ­¥è®¾è®¡æµç¨‹:")
    print("  Step1: æå–Short Answer + æ„å»ºæœ€å°ç²¾ç¡®é—®é¢˜")
    print("  Step2: æå–Root Queryçš„æœ€å°å…³é”®è¯")
    print("  Step3: é’ˆå¯¹æ¯ä¸ªå…³é”®è¯åšSeriesæ·±åº¦æ‰©å±•")
    print("  Step4: é’ˆå¯¹æ‰€æœ‰å…³é”®è¯åšParallelæ¨ªå‘æ‰©å±•")
    print("  Step5: é‡å¤æ„å»ºæœ€å¤š3å±‚é—®é¢˜æ ‘")
    print("  Step6: ç³…åˆç”Ÿæˆæœ€ç»ˆç»¼åˆé—®é¢˜")
    print("=" * 80)
    print("ğŸ­ ç”Ÿäº§æ¨¡å¼ç‰¹æ€§:")
    print("  ğŸ“Š å…¨é‡å¤„ç† - å¤„ç†é€‰å®štopicçš„æ‰€æœ‰æ–‡æ¡£")
    print("  ğŸ“ è¯¦ç»†æ—¥å¿— - å®æ—¶æ˜¾ç¤ºå¤„ç†è¿›åº¦å’Œæ–‡æ¡£çŠ¶æ€")
    print("  ğŸ”’ å¾ªç¯é¢„é˜² - å®Œæ•´çš„å¾ªç¯æ¨ç†æ£€æµ‹æœºåˆ¶")
    print("  ğŸ’¾ è‡ªåŠ¨ä¿å­˜ - å®æ—¶ä¿å­˜ç»“æœï¼Œæ”¯æŒæ–­ç‚¹æ¢å¤")
    print("=" * 80)
    
    # è·å–ç”¨æˆ·è¾“å…¥
    try:
        api_key = input("è¯·è¾“å…¥OpenAI APIå¯†é’¥: ").strip()
        if not api_key:
            print("âŒ APIå¯†é’¥ä¸èƒ½ä¸ºç©º")
            return False
        
        # å‘ç°å¯ç”¨çš„ClueWeb22 topics
        print("\nğŸ” æ­£åœ¨æ‰«æClueWeb22æ•°æ®é›†...")
        document_loader = DocumentLoader()
        available_topics = document_loader.discover_topics()
        
        if not available_topics:
            print("âŒ æœªæ‰¾åˆ°å¯ç”¨çš„ClueWeb22 topicsï¼Œè¯·æ£€æŸ¥æ•°æ®è·¯å¾„")
            print(f"æ•°æ®è·¯å¾„: {document_loader.config.clueweb22_path}")
            return False
        
        # æ˜¾ç¤ºå¯ç”¨topicså¹¶è®©ç”¨æˆ·é€‰æ‹©
        print(f"\nğŸ“‹ å‘ç° {len(available_topics)} ä¸ªå¯ç”¨topics:")
        for i, topic in enumerate(available_topics, 1):
            # ç»Ÿè®¡æ–‡æ¡£æ•°é‡
            try:
                # ä½¿ç”¨æ­£ç¡®çš„å‚æ•°å max_docs è€Œä¸æ˜¯ max_limit
                docs = document_loader.load_documents_from_topic(topic, max_docs=None)
                total_docs = len(docs)
                print(f"  {i}. {topic} ({total_docs} ä¸ªæ–‡æ¡£)")
            except Exception as e:
                # å¦‚æœå‡ºé”™ï¼Œå°è¯•æ›´ç®€å•çš„æ–¹æ³•ç»Ÿè®¡
                try:
                    import os
                    topic_path = os.path.join(document_loader.config.clueweb22_path, topic)
                    if os.path.exists(topic_path):
                        files = [f for f in os.listdir(topic_path) if f.endswith('.txt')]
                        print(f"  {i}. {topic} (~{len(files)} ä¸ªæ–‡æ¡£)")
                    else:
                        print(f"  {i}. {topic} (è·¯å¾„ä¸å­˜åœ¨)")
                except:
                    print(f"  {i}. {topic} (ç»Ÿè®¡å¤±è´¥)")
        
        while True:
            try:
                choice_input = input(f"\nè¯·é€‰æ‹©topic [1-{len(available_topics)}] (é»˜è®¤: 1): ").strip()
                if not choice_input:
                    choice = 1
                else:
                    choice = int(choice_input)
                
                if 1 <= choice <= len(available_topics):
                    selected_topic = available_topics[choice - 1]
                    break
                else:
                    print(f"âŒ è¯·è¾“å…¥ 1-{len(available_topics)} ä¹‹é—´çš„æ•°å­—")
            except ValueError:
                print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
        
        # è·å–è¯¥topicçš„æ–‡æ¡£æ€»æ•°
        print(f"\nğŸ“Š æ­£åœ¨ç»Ÿè®¡ {selected_topic} çš„æ–‡æ¡£æ•°é‡...")
        try:
            # ä½¿ç”¨æ­£ç¡®çš„å‚æ•°å max_docs è€Œä¸æ˜¯ max_limit
            all_docs = document_loader.load_documents_from_topic(selected_topic, max_docs=None)
            total_docs = len(all_docs)
            print(f"ğŸ“„ å‘ç° {total_docs} ä¸ªæ–‡æ¡£")
        except Exception as e:
            print(f"âŒ è·å–æ–‡æ¡£æ•°é‡å¤±è´¥: {e}")
            # å°è¯•å¤‡ç”¨æ–¹æ³•
            try:
                import os
                topic_path = os.path.join(document_loader.config.clueweb22_path, selected_topic)
                if os.path.exists(topic_path):
                    files = [f for f in os.listdir(topic_path) if f.endswith('.txt')]
                    total_docs = len(files)
                    print(f"ğŸ“„ ä½¿ç”¨å¤‡ç”¨æ–¹æ³•ç»Ÿè®¡: ~{total_docs} ä¸ªæ–‡æ¡£")
                else:
                    print(f"âŒ ä¸»é¢˜è·¯å¾„ä¸å­˜åœ¨: {topic_path}")
                    return False
            except Exception as e2:
                print(f"âŒ å¤‡ç”¨ç»Ÿè®¡æ–¹æ³•ä¹Ÿå¤±è´¥: {e2}")
                return False
        
        print(f"\nğŸ¯ ç”Ÿäº§å®éªŒé…ç½®:")
        print(f"  é€‰æ‹©çš„Topic: {selected_topic}")
        print(f"  å¤„ç†æ¨¡å¼: å…¨é‡å¤„ç†")
        print(f"  æ–‡æ¡£æ€»æ•°: {total_docs} ä¸ª")
        print(f"  é¢„è®¡è€—æ—¶: {total_docs * 30 / 60:.1f} åˆ†é’Ÿ (ä¼°ç®—)")
        print(f"  å¾ªç¯æ£€æµ‹: âœ… å·²å¯ç”¨")
        print(f"  è‡ªåŠ¨ä¿å­˜: âœ… æ¯ä¸ªæ–‡æ¡£å®Œæˆåä¿å­˜")
        print(f"  é—®é¢˜ç»“æ„: æœ€å°ç²¾ç¡®å…³é”®è¯ + æ— å…³è”æ€§ + åµŒå¥—ç»¼åˆ")
        
        confirm = input("\nâš ï¸  ç”Ÿäº§æ¨¡å¼å°†å¤„ç†æ‰€æœ‰æ–‡æ¡£ï¼Œæ˜¯å¦ç»§ç»­? [y/N]: ").strip().lower()
        if confirm != 'y':
            print("å–æ¶ˆè¿è¡Œ")
            return False
        
        # åˆå§‹åŒ–å¹¶è¿è¡Œæ¡†æ¶
        framework = AgentReasoningMainFramework()
        
        if not framework.initialize_framework(api_key):
            print("âŒ æ¡†æ¶åˆå§‹åŒ–å¤±è´¥")
            return False
        
        # æ˜¾ç¤ºæ¡†æ¶çŠ¶æ€
        status = framework.get_framework_status()
        print(f"\nğŸ“Š æ¡†æ¶çŠ¶æ€:")
        print(f"  åˆå§‹åŒ–çŠ¶æ€: {'âœ…' if status['initialized'] else 'âŒ'}")
        print(f"  Agentæ¨ç†æ¡†æ¶: âœ…")
        print(f"  6æ­¥è®¾è®¡æµç¨‹: âœ…")
        print(f"  è½¨è¿¹è®°å½•: âœ…")
        print(f"  æ— å…³è”æ€§éªŒè¯: âœ…")
        print(f"  å¾ªç¯æ¨ç†æ£€æµ‹: âœ…")
        
        # è¿è¡Œç”Ÿäº§çº§åˆ«å®éªŒ
        print(f"\nğŸš€ å¼€å§‹è¿è¡Œç”Ÿäº§çº§åˆ«Agentæ·±åº¦æ¨ç†å®éªŒ...")
        print(f"ğŸ“Š å°†å¤„ç† {total_docs} ä¸ªæ–‡æ¡£...")
        print("=" * 80)
        
        results = framework.run_agent_reasoning_experiment_production(selected_topic)
        
        # æ˜¾ç¤ºç»“æœæ‘˜è¦
        print("\n" + "=" * 80)
        print(f"ğŸ“Š ç”Ÿäº§å®éªŒç»“æœæ‘˜è¦:")
        print(f"  æˆåŠŸ: {'âœ…' if results['success'] else 'âŒ'}")
        
        if results['success']:
            summary = results['summary']
            print(f"  å¤„ç†æ–‡æ¡£: {summary.get('successful_documents', 0)}/{summary.get('total_documents_attempted', 0)}")
            print(f"  æˆåŠŸç‡: {summary.get('success_rate', 0):.1%}")
            print(f"  æ¨ç†æ ‘: {summary.get('total_reasoning_trees', 0)} ä¸ª")
            print(f"  ç»¼åˆé—®é¢˜: {summary.get('total_composite_queries', 0)} ä¸ª")
            print(f"  æ€»è€—æ—¶: {results.get('total_processing_time', 0) / 60:.1f} åˆ†é’Ÿ")
            print(f"  å¹³å‡æ¯æ–‡æ¡£: {results.get('total_processing_time', 0) / max(summary.get('total_documents_attempted', 1), 1):.1f} ç§’")
        else:
            print(f"  é”™è¯¯: {results.get('error', 'Unknown error')}")
        
        print(f"\nâœ… ç”Ÿäº§çº§åˆ«Agentæ¨ç†å®éªŒå®Œæˆ")
        print(f"ğŸ“ ç»“æœå·²ä¿å­˜åˆ° results/ ç›®å½•")
        print(f"ğŸ“Š è¯¦ç»†æ—¥å¿—è¯·æŸ¥çœ‹æ§åˆ¶å°è¾“å‡º")
        return results['success']
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­å®éªŒ")
        print("ğŸ’¾ å·²å¤„ç†çš„æ•°æ®å·²è‡ªåŠ¨ä¿å­˜")
        return False
    except Exception as e:
        print(f"\nâŒ å®éªŒæ‰§è¡Œå¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    success = main()
    exit(0 if success else 1) 