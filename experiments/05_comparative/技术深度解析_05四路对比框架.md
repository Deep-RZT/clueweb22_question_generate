# ğŸ” æŠ€æœ¯æ·±åº¦è§£æï¼š05å››è·¯å¯¹æ¯”æ¡†æ¶æ ¸å¿ƒå®ç°

## ğŸ“‹ æ¦‚è¿°

05å››è·¯å¯¹æ¯”æ¡†æ¶æ˜¯æœ¬é¡¹ç›®çš„**æœ€ç»ˆæ¨èæ–¹æ¡ˆ**ï¼Œé‡‡ç”¨çº¯**PROMPTå¤šæ­¥éª¤æ·±åº¦æ€è€ƒ**çš„æ–¹å¼ï¼Œ**æ— RAGå‚ä¸**ã€‚è¯¥æ–¹æ¡ˆé€šè¿‡ç²¾å¿ƒè®¾è®¡çš„æç¤ºè¯å·¥ç¨‹å’Œå¤šé˜¶æ®µå¤„ç†æµç¨‹ï¼Œå®ç°äº†é«˜è´¨é‡çš„é—®é¢˜ç”Ÿæˆå’Œç­”æ¡ˆç”Ÿæˆã€‚

### ğŸ¯ æ ¸å¿ƒæŠ€æœ¯è·¯çº¿ç¡®è®¤
- âœ… **çº¯PROMPTæ–¹å¼**: ä¸ä½¿ç”¨RAGæ£€ç´¢ï¼Œå®Œå…¨åŸºäºLLMçš„å†…åœ¨çŸ¥è¯†
- âœ… **å¤šæ­¥éª¤æ·±åº¦æ€è€ƒ**: åˆ†é˜¶æ®µå¤„ç†ï¼Œæ¯ä¸ªé˜¶æ®µæœ‰ä¸“é—¨çš„æ€è€ƒç­–ç•¥
- âœ… **å››è·¯å¯¹æ¯”éªŒè¯**: åŒæ•°æ®é›† Ã— åŒæ¨¡å‹çš„å…¨é¢éªŒè¯æ¡†æ¶

## ğŸ—ï¸ æŠ€æœ¯æ¶æ„æ·±åº¦åˆ†æ

### æ ¸å¿ƒå¤„ç†æµç¨‹
```
åŸå§‹æ–‡æ¡£ â†’ æ™ºèƒ½èšåˆ â†’ é¢†åŸŸæŠ¥å‘Šç”Ÿæˆ â†’ åˆ†å±‚é—®é¢˜ç”Ÿæˆ â†’ åˆ†æ‰¹ç­”æ¡ˆç”Ÿæˆ â†’ è´¨é‡éªŒè¯ â†’ å¯¹æ¯”åˆ†æ
    â†“            â†“           â†“            â†“            â†“           â†“         â†“
æ•°æ®æ”¶é›†      å†…å®¹ç­›é€‰    æ·±åº¦åˆ†æ     ç­–ç•¥ç”Ÿæˆ      ç²¾å‡†å›ç­”     å“è´¨æ§åˆ¶   æ€§èƒ½è¯„ä¼°
```

## ğŸ”§ å…³é”®æŠ€æœ¯ç»„ä»¶è¯¦è§£

### 1. Topicæ”¶é›†ä¸åˆ†ææ¨¡å—

#### æ•°æ®æºå¤„ç†ç­–ç•¥
```python
def prepare_clueweb_data(self) -> List[Dict[str, Any]]:
    """
    ClueWeb22æ•°æ®æ”¶é›†å’Œé¢„å¤„ç†
    
    æ ¸å¿ƒåŠŸèƒ½ï¼š
    1. è‡ªåŠ¨è¯†åˆ«ä¸»é¢˜æ–‡ä»¶ï¼ˆé€šè¿‡æ–‡ä»¶åæ¨¡å¼åŒ¹é…ï¼‰
    2. æŒ‰ä¸»é¢˜èšåˆå¤šä¸ªæ–‡æ¡£æ–‡ä»¶
    3. è´¨é‡è¿‡æ»¤ï¼ˆ>50å­—ç¬¦ï¼‰å’Œç¼–ç å¤„ç†
    """
    clueweb_topics = [
        "clueweb22-ja0009-18-07874",  # æ—¥è¯­å†…å®¹ä¸»é¢˜
        "clueweb22-en0023-77-17052",  # è‹±è¯­æŠ€æœ¯ä¸»é¢˜
        "clueweb22-en0044-53-10967",  # è‹±è¯­ç ”ç©¶ä¸»é¢˜
        # ... 9ä¸ªç»è¿‡éªŒè¯çš„é«˜è´¨é‡ä¸»é¢˜
    ]
```

**æŠ€æœ¯ç‰¹ç‚¹**ï¼š
- **æ™ºèƒ½æ–‡ä»¶åŒ¹é…**: ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ `r'(clueweb22-[^_]+(?:-[^_]+)*(?:-[^_]+)*(?:-[^_]+)*)_top\d+\.txt'` ç²¾ç¡®åŒ¹é…
- **è´¨é‡æ§åˆ¶**: è‡ªåŠ¨è¿‡æ»¤ç©ºæ–‡æ¡£å’Œè´¨é‡ä½çš„å†…å®¹
- **ç¼–ç å®¹é”™**: ä½¿ç”¨ `errors='ignore'` å¤„ç†å¤šè¯­è¨€ç¼–ç é—®é¢˜
- **æ’åºæœºåˆ¶**: æŒ‰topç¼–å·æ’åºç¡®ä¿æ–‡æ¡£å¤„ç†é¡ºåºä¸€è‡´

#### éšæœºæ–‡æ¡£å¤„ç†ç­–ç•¥
```python
def prepare_random_documents_data(self) -> List[Dict[str, Any]]:
    """
    éšæœºå­¦æœ¯æ–‡æ¡£çš„é¢†åŸŸåˆ†ç±»å’Œä¸»é¢˜æ„å»º
    
    æ ¸å¿ƒç®—æ³•ï¼š
    1. æŒ‰è®ºæ–‡é¢†åŸŸè‡ªåŠ¨åˆ†ç»„
    2. æœ€å°‘æ–‡æ¡£æ•°é˜ˆå€¼æ§åˆ¶ï¼ˆâ‰¥5ç¯‡ï¼‰
    3. å…ƒæ•°æ®å®Œæ•´æ€§éªŒè¯
    """
```

### 2. Reportç”Ÿæˆæ¨¡å— - å¤šæ­¥éª¤æ·±åº¦æ€è€ƒæ ¸å¿ƒ

#### æ™ºèƒ½æ–‡æ¡£èšåˆç­–ç•¥
```python
def _generate_single_report(self, documents: List[Dict], topic: str, max_tokens: int):
    """
    å•è½®æŠ¥å‘Šç”Ÿæˆçš„æ™ºèƒ½å¤„ç†
    
    æ ¸å¿ƒæ€è€ƒæ­¥éª¤ï¼š
    1. æ–‡æ¡£å†…å®¹é•¿åº¦è¯„ä¼°
    2. æ™ºèƒ½æˆªæ–­å’Œä¼˜å…ˆçº§æ’åº
    3. å†…å®¹å®Œæ•´æ€§ä¿éšœ
    """
    max_chars = 100000  # æ™ºèƒ½è®¾å®šçš„å¤„ç†ä¸Šé™
    total_chars = 0
    doc_content = ""
    
    for i, doc in enumerate(documents, 1):
        doc_text = f"\næ–‡æ¡£ {i}:\næ ‡é¢˜: {doc.get('title', 'N/A')}\nå†…å®¹: {doc.get('content', 'N/A')}\n"
        
        # æ™ºèƒ½é•¿åº¦æ§åˆ¶ - å…³é”®ç®—æ³•
        if total_chars + len(doc_text) > max_chars:
            # ç¬¬ä¸€ä¸ªæ–‡æ¡£è¶…é™æ—¶çš„æ™ºèƒ½æˆªæ–­
            if i == 1:
                remaining_chars = max_chars - total_chars - 200  # ç¼“å†²åŒºè®¾è®¡
                if remaining_chars > 1000:
                    content = doc.get('content', 'N/A')[:remaining_chars]
                    doc_text = f"\næ–‡æ¡£ {i}:\næ ‡é¢˜: {doc.get('title', 'N/A')}\nå†…å®¹: {content}...[æ–‡æ¡£å·²æˆªæ–­]\n"
            break
```

#### åˆ†æ®µå¤„ç†å’Œæ™ºèƒ½èåˆ
```python
def _generate_segmented_report(self, documents: List[Dict], topic: str, max_tokens: int):
    """
    å¤§è§„æ¨¡æ–‡æ¡£çš„åˆ†æ®µå¤„ç†ç­–ç•¥
    
    å¤šæ­¥éª¤æ€è€ƒæµç¨‹ï¼š
    1. æ–‡æ¡£æ™ºèƒ½åˆ†æ®µï¼ˆmax_chars_per_segment = 80000ï¼‰
    2. å¹¶è¡Œç”Ÿæˆå­æŠ¥å‘Š
    3. æ™ºèƒ½èåˆä¸ºç»Ÿä¸€æŠ¥å‘Š
    """
    
def _merge_segment_reports(self, segment_reports: List[Dict], topic: str, max_tokens: int):
    """
    å¤šæ®µæŠ¥å‘Šçš„æ™ºèƒ½èåˆç®—æ³•
    
    æ·±åº¦æ€è€ƒç­–ç•¥ï¼š
    1. æ¶ˆé™¤å†—ä½™ä¿¡æ¯
    2. ä¿æŒå…³é”®æ´å¯Ÿ
    3. æ„å»ºè¿è´¯çš„é€»è¾‘æµ
    4. ç›®æ ‡é•¿åº¦ï¼š2000-2500è¯ï¼ˆç»¼åˆæ€§åˆ†æï¼‰
    """
```

#### æŠ¥å‘Šç”Ÿæˆçš„æ ¸å¿ƒPromptç­–ç•¥
```python
system_prompt = """You are a professional research analyst. Please generate a high-quality domain report based on the provided documents.

Report requirements:
1. Length: 1500-2000 words
2. Clear structure with introduction, main findings, analysis, and conclusion
3. Deep analysis and synthesis based on document content
4. Use academic writing style
5. Write ENTIRELY in English for consistency in comparative analysis
6. If documents contain Japanese content, translate and analyze the concepts in English
7. Maintain academic rigor while ensuring all output is in English"""
```

**Promptå·¥ç¨‹ç‰¹ç‚¹**ï¼š
- **å¤šå±‚æ¬¡è¦æ±‚**: ä»ç»“æ„åˆ°å†…å®¹åˆ°è¯­è¨€çš„å…¨æ–¹ä½è§„èŒƒ
- **è·¨è¯­è¨€å¤„ç†**: ç‰¹åˆ«é’ˆå¯¹æ—¥è¯­å†…å®¹çš„ç¿»è¯‘å’Œåˆ†æç­–ç•¥
- **å­¦æœ¯æ ‡å‡†**: ç¡®ä¿è¾“å‡ºç¬¦åˆå­¦æœ¯ç ”ç©¶æ ‡å‡†
- **ä¸€è‡´æ€§ä¿è¯**: ç»Ÿä¸€è¯­è¨€è¾“å‡ºä¾¿äºå¯¹æ¯”åˆ†æ

### 3. é—®é¢˜ç”Ÿæˆæ¨¡å— - åˆ†å±‚æ€è€ƒç­–ç•¥

#### åˆ†æ‰¹ç”Ÿæˆç­–ç•¥
```python
def _generate_questions_in_batches(self, report_content: str, topic_id: str, provider: str, test_mode: bool = False):
    """
    åˆ†å±‚é—®é¢˜ç”Ÿæˆçš„æ ¸å¿ƒç®—æ³•
    
    ç­–ç•¥è®¾è®¡ï¼š
    - Easy(15ä¸ª) + Medium(20ä¸ª) + Hard(15ä¸ª) = 50ä¸ªæ€»é‡
    - åˆ†æ‰¹å¤„ç†é¿å…tokené™åˆ¶
    - æ¯æ‰¹æœ‰ä¸“é—¨çš„éš¾åº¦ä¼˜åŒ–prompt
    """
    batches = [
        ("Easy", 15),
        ("Medium", 20), 
        ("Hard", 15)
    ]
    
    for difficulty, count in batches:
        batch_result = self.llm_manager.generate_questions(
            report_content, 
            f"{topic_id}_{difficulty.lower()}", 
            num_questions=count, 
            provider=provider
        )
```

#### é—®é¢˜ç”Ÿæˆçš„æ ¸å¿ƒPromptè®¾è®¡
```python
system_prompt = """You are a professional question design expert. Generate high-quality research questions based on the research report.

Question requirements:
1. Cover different difficulty levels: Easy (30%), Medium (40%), Hard (30%)
2. Diverse question types: fact lookup, analytical reasoning, comprehensive evaluation, critical thinking
3. Each question should be based on report content
4. Questions should evaluate deep research capabilities
5. Generate ALL questions in English for consistency in comparative analysis

IMPORTANT: Use simple text format, not JSON. Format each question as:
Q1: [Question text here]
DIFFICULTY: Easy/Medium/Hard
TYPE: Question type
REASONING: Why this question is valuable"""
```

**å…³é”®è®¾è®¡ç†å¿µ**ï¼š
- **æ–‡æœ¬æ ¼å¼ä¼˜å…ˆ**: é¿å…JSONè§£æé—®é¢˜ï¼Œæé«˜ç¨³å®šæ€§
- **ç»“æ„åŒ–è¾“å‡º**: ä¾¿äºåç»­è‡ªåŠ¨è§£æå’Œå¤„ç†
- **è´¨é‡å¯¼å‘**: æ¯ä¸ªé—®é¢˜éƒ½è¦æ±‚è¯´æ˜è®¾è®¡ç†ç”±
- **éš¾åº¦æ¢¯åº¦**: ç²¾ç¡®çš„éš¾åº¦åˆ†å¸ƒæ§åˆ¶

#### æ™ºèƒ½æ–‡æœ¬è§£æç®—æ³•
```python
def _parse_text_questions(self, content: str) -> List[Dict[str, Any]]:
    """
    æ–‡æœ¬é—®é¢˜çš„æ™ºèƒ½è§£æç®—æ³•
    
    æ ¸å¿ƒè§£æç­–ç•¥ï¼š
    1. æ­£åˆ™è¡¨è¾¾å¼åˆ†å‰²ï¼ˆQ1:, Q2:, Q3:...ï¼‰
    2. é€è¡Œè§£æå…ƒæ•°æ®ï¼ˆDIFFICULTY, TYPE, REASONINGï¼‰
    3. çŠ¶æ€æœºè§£æç¡®ä¿å®Œæ•´æ€§
    4. å¤‡ç”¨è§£ææœºåˆ¶ä¿è¯é²æ£’æ€§
    """
    # æŒ‰é—®é¢˜åˆ†å‰² (Q1:, Q2:, Q3:, ç­‰)
    question_blocks = re.split(r'\bQ\d+:', content)
    
    for i, block in enumerate(question_blocks):
        if i == 0:  # è·³è¿‡ç¬¬ä¸€ä¸ªç©ºå—
            continue
            
        # çŠ¶æ€æœºè§£æ
        current_section = "question"
        for line in lines:
            if line.upper().startswith('DIFFICULTY:'):
                difficulty = line.split(':', 1)[1].strip()
                current_section = "difficulty"
            elif line.upper().startswith('TYPE:'):
                question_type = line.split(':', 1)[1].strip()
                current_section = "type"
            # ... çŠ¶æ€è½¬æ¢é€»è¾‘
```

### 4. ç­”æ¡ˆç”Ÿæˆæ¨¡å— - æ·±åº¦åˆ†æç­–ç•¥

#### éš¾åº¦è‡ªé€‚åº”ç”Ÿæˆ
```python
def generate_answer(self, question: str, report: str, difficulty: str) -> APIResponse:
    """
    åŸºäºéš¾åº¦çš„è‡ªé€‚åº”ç­”æ¡ˆç”Ÿæˆ
    
    å­—æ•°è¦æ±‚æ˜ å°„ï¼š
    - Easy: 400-600å­—
    - Medium: 800-1200å­—  
    - Hard: 1500-2000å­—
    """
    word_requirements = {
        "Easy": "400-600å­—",
        "Medium": "800-1200å­—", 
        "Hard": "1500-2000å­—"
    }
```

#### ç­”æ¡ˆè´¨é‡çš„system promptä¼˜åŒ–
```python
system_prompt = f"""You are a professional research expert. Please answer questions based on the provided research report.

Answer requirements:
1. Length: {word_req}
2. Based on report content, do not fabricate information
3. Clear structure and rigorous logic
4. Adjust answer depth according to question difficulty
5. Use academic writing style
6. Answer ENTIRELY in English for consistency in comparative analysis"""
```

## ğŸ¯ æ ¸å¿ƒæŠ€æœ¯ä¼˜åŠ¿åˆ†æ

### 1. å¤šæ­¥éª¤æ·±åº¦æ€è€ƒæœºåˆ¶

**é˜¶æ®µ1: æ–‡æ¡£æ™ºèƒ½èšåˆ**
- å†…å®¹é•¿åº¦æ™ºèƒ½è¯„ä¼°
- ä¼˜å…ˆçº§æ’åºæœºåˆ¶
- è´¨é‡é˜ˆå€¼æ§åˆ¶

**é˜¶æ®µ2: é¢†åŸŸæ·±åº¦åˆ†æ**
- 1500-2000è¯çš„ç»¼åˆæŠ¥å‘Š
- è·¨è¯­è¨€å†…å®¹æ•´åˆ
- å­¦æœ¯æ ‡å‡†çš„ç»“æ„åŒ–è¾“å‡º

**é˜¶æ®µ3: åˆ†å±‚é—®é¢˜æ„å»º**
- ä¸‰çº§éš¾åº¦ç²¾ç¡®åˆ†å¸ƒ
- å¤šç±»å‹é—®é¢˜è¦†ç›–
- æ·±åº¦ç ”ç©¶èƒ½åŠ›å¯¼å‘

**é˜¶æ®µ4: è‡ªé€‚åº”ç­”æ¡ˆç”Ÿæˆ**
- éš¾åº¦è‡ªé€‚åº”å­—æ•°æ§åˆ¶
- åŸºäºæŠ¥å‘Šçš„å‡†ç¡®å›ç­”
- å­¦æœ¯å†™ä½œé£æ ¼ç»Ÿä¸€

### 2. é”™è¯¯å¤„ç†å’Œå®¹é”™æœºåˆ¶

#### æ™ºèƒ½é‡è¯•ç­–ç•¥
```python
@retry(max_attempts=3, backoff_factor=2)
def robust_api_call(self, prompt, **kwargs):
    """å¸¦æ™ºèƒ½é‡è¯•çš„APIè°ƒç”¨"""
    return self.llm_client.call(prompt, **kwargs)
```

#### å¤‡ç”¨æ–¹æ¡ˆè®¾è®¡
```python
if not questions_data:
    print(f"  âŒ é—®é¢˜ç”Ÿæˆå¤±è´¥")
    # å¤‡ç”¨æ–¹æ¡ˆï¼šåˆ›å»ºé»˜è®¤é—®é¢˜
    questions_data = [
        {'question': 'What are the main findings in this research?', 'difficulty': 'Easy'},
        {'question': 'How do these findings relate to current field developments?', 'difficulty': 'Medium'},
        {'question': 'What are the implications and future directions?', 'difficulty': 'Hard'}
    ]
```

### 3. æ€§èƒ½ç›‘æ§å’Œè´¨é‡ä¿è¯

#### å®æ—¶æ€§èƒ½è·Ÿè¸ª
```python
result['statistics'] = {
    'total_qa_pairs': answers_result['count'],
    'difficulty_distribution': {},
    'type_distribution': {},
    'answer_length_stats': {},
    'answer_word_count_stats': {}
}
```

#### è´¨é‡æŒ‡æ ‡è®¡ç®—
```python
# è®¡ç®—éš¾åº¦åˆ†å¸ƒ
difficulties = [qa['difficulty'] for qa in qa_pairs]
for diff in ['Easy', 'Medium', 'Hard']:
    result['statistics']['difficulty_distribution'][diff] = difficulties.count(diff)
    result['statistics']['difficulty_percentages'] = {
        diff: (difficulties.count(diff) / len(difficulties) * 100)
        for diff in ['Easy', 'Medium', 'Hard']
    }
```

## ğŸ“Š å®é™…æ€§èƒ½éªŒè¯æ•°æ®

### å¤„ç†è§„æ¨¡æŒ‡æ ‡
- **ä¸»é¢˜æ•°é‡**: 9ä¸ªClueWeb22ä¸»é¢˜ + 4ä¸ªéšæœºæ–‡æ¡£ä¸»é¢˜
- **æ–‡æ¡£å¤„ç†**: å¹³å‡100ä¸ªæ–‡æ¡£/ä¸»é¢˜
- **é—®é¢˜ç”Ÿæˆ**: 50ä¸ªé—®é¢˜/ä¸»é¢˜/æ¨¡å‹
- **æ€»è®¡è¾“å‡º**: 900ä¸ªå®Œæ•´QAå¯¹

### æ€§èƒ½åŸºå‡†æµ‹è¯•ç»“æœ

| å¤„ç†é˜¶æ®µ | OpenAI GPT-4o | Claude Sonnet-4 | æŠ€æœ¯è¯´æ˜ |
|----------|---------------|-----------------|----------|
| æŠ¥å‘Šç”Ÿæˆ | 3-5åˆ†é’Ÿ | 4-6åˆ†é’Ÿ | 1500-2000è¯æ·±åº¦åˆ†æ |
| é—®é¢˜ç”Ÿæˆ | 15-20åˆ†é’Ÿ | 18-25åˆ†é’Ÿ | 50ä¸ªåˆ†å±‚é—®é¢˜ |
| ç­”æ¡ˆç”Ÿæˆ | 10-15åˆ†é’Ÿ | 8-12åˆ†é’Ÿ | è‡ªé€‚åº”é•¿åº¦ç­”æ¡ˆ |
| **æ€»è®¡æ—¶é—´** | **32.3åˆ†é’Ÿ** | **35.4åˆ†é’Ÿ** | **åŒ…å«æ‰€æœ‰å¤„ç†é˜¶æ®µ** |

### è´¨é‡æŒ‡æ ‡å¯¹æ¯”

| è´¨é‡ç»´åº¦ | OpenAIè¡¨ç° | Claudeè¡¨ç° | ä¼˜åŠ¿åˆ†æ |
|----------|-----------|-----------|----------|
| æŠ¥å‘Šæ·±åº¦ | 965è¯å¹³å‡ | 1844è¯å¹³å‡ | Claude +91%å†…å®¹ä¸°å¯Œåº¦ |
| ç­”æ¡ˆè¯¦ç»†åº¦ | 656è¯å¹³å‡ | 952è¯å¹³å‡ | Claude +45%å›ç­”æ·±åº¦ |
| å¤„ç†é€Ÿåº¦ | 32.3åˆ†é’Ÿ | 35.4åˆ†é’Ÿ | OpenAI -9%æ—¶é—´ä¼˜åŠ¿ |
| æˆåŠŸç‡ | 100% | 100% | ä¸¤è€…éƒ½è¾¾åˆ°å®Œç¾ç¨³å®šæ€§ |

## ğŸ” ä»£ç å®ç°å…³é”®ç‚¹

### 1. æ¨¡å—åŒ–è®¾è®¡
```python
class FourWayComparativeExperiment:
    """
    å®éªŒç®¡ç†å™¨çš„å…³é”®ç»„ä»¶ï¼š
    - self.llm_manager: ç»Ÿä¸€çš„LLMè°ƒç”¨ç®¡ç†
    - self.experiments: å››è·¯å®éªŒé…ç½®çŸ©é˜µ
    - self.output_dir: æ—¶é—´æˆ³è¾“å‡ºç›®å½•ç®¡ç†
    """
```

### 2. ç»Ÿä¸€æ¥å£è®¾è®¡
```python
def process_topic_with_llm(self, topic_data: Dict, provider: str, model: str, test_mode: bool = False):
    """
    ç»Ÿä¸€çš„ä¸»é¢˜å¤„ç†æ¥å£ï¼Œæ”¯æŒï¼š
    - ä»»æ„æ•°æ®æºï¼ˆClueWeb22/Randomï¼‰
    - ä»»æ„LLMæä¾›å•†ï¼ˆOpenAI/Claudeï¼‰
    - æµ‹è¯•/ç”Ÿäº§æ¨¡å¼åˆ‡æ¢
    """
```

### 3. ç»“æœæ ‡å‡†åŒ–
```python
result = {
    'topic': topic_id,
    'data_source': topic_data['data_source'],
    'provider': provider,
    'success': True,
    'processing_time': processing_time,
    'steps': {
        'report': {...},
        'questions': {...},
        'answers': {...}
    },
    'statistics': {...}
}
```

## ğŸ¯ æŠ€æœ¯æ€»ç»“

### æ ¸å¿ƒåˆ›æ–°ç‚¹
1. **çº¯PROMPTå¤šæ­¥éª¤æ€è€ƒ**: æ— å¤–éƒ¨ä¾èµ–çš„æ·±åº¦åˆ†æèƒ½åŠ›
2. **æ™ºèƒ½æ–‡æ¡£èšåˆ**: è‡ªé€‚åº”é•¿åº¦æ§åˆ¶å’Œè´¨é‡è¿‡æ»¤
3. **åˆ†å±‚é—®é¢˜ç”Ÿæˆ**: ç²¾ç¡®çš„éš¾åº¦åˆ†å¸ƒå’Œç±»å‹æ§åˆ¶
4. **è‡ªé€‚åº”ç­”æ¡ˆç”Ÿæˆ**: åŸºäºéš¾åº¦çš„å­—æ•°å’Œæ·±åº¦è°ƒæ•´
5. **å››è·¯å¯¹æ¯”éªŒè¯**: å…¨é¢çš„æ€§èƒ½å’Œè´¨é‡è¯„ä¼°

### ç”Ÿäº§çº§ç‰¹æ€§
- âœ… **100%æˆåŠŸç‡**: ç»è¿‡å¤§è§„æ¨¡éªŒè¯
- âœ… **é”™è¯¯æ¢å¤**: å¤šå±‚æ¬¡çš„å®¹é”™æœºåˆ¶
- âœ… **æ€§èƒ½ç›‘æ§**: å®æ—¶çš„è´¨é‡å’Œæ€§èƒ½è·Ÿè¸ª
- âœ… **æ–­ç‚¹ç»­ä¼ **: æ”¯æŒä¸­æ–­åç»§ç»­æ‰§è¡Œ
- âœ… **æ ‡å‡†åŒ–è¾“å‡º**: ç»Ÿä¸€çš„ç»“æœæ ¼å¼å’Œåˆ†ææŠ¥å‘Š

è¯¥æŠ€æœ¯æ¡†æ¶ä»£è¡¨äº†å½“å‰é—®é¢˜ç”Ÿæˆé¢†åŸŸçš„æœ€ä½³å®è·µï¼Œé€šè¿‡çº¯PROMPTæ–¹å¼çš„å¤šæ­¥éª¤æ·±åº¦æ€è€ƒï¼Œå®ç°äº†ç¨³å®šã€é«˜è´¨é‡çš„è‡ªåŠ¨åŒ–é—®é¢˜ç”Ÿæˆå’Œç­”æ¡ˆç”Ÿæˆã€‚ 