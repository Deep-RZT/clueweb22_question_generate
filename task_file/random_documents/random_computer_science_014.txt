Title: VisCoder: Fine-Tuning LLMs for Executable Python Visualization Code
  Generation

Authors: Yuansheng Ni, Ping Nie, Kai Zou, Xiang Yue, Wenhu Chen

Abstract: Large language models (LLMs) often struggle with visualization tasks like
plotting diagrams, charts, where success depends on both code correctness and
visual semantics. Existing instruction-tuning datasets lack execution-grounded
supervision and offer limited support for iterative code correction, resulting
in fragile and unreliable plot generation. We present VisCode-200K, a
large-scale instruction tuning dataset for Python-based visualization and
self-correction. It contains over 200K examples from two sources: (1) validated
plotting code from open-source repositories, paired with natural language
instructions and rendered plots; and (2) 45K multi-turn correction dialogues
from Code-Feedback, enabling models to revise faulty code using runtime
feedback. We fine-tune Qwen2.5-Coder-Instruct on VisCode-200K to create
VisCoder, and evaluate it on PandasPlotBench. VisCoder significantly
outperforms strong open-source baselines and approaches the performance of
proprietary models like GPT-4o-mini. We further adopt a self-debug evaluation
protocol to assess iterative repair, demonstrating the benefits of
feedback-driven learning for executable, visually accurate code generation.

Introduction: Recent advances in this field have opened new possibilities for innovative applications. This research addresses current limitations and proposes novel solutions.

Methodology: We employed rigorous experimental protocols and advanced computational techniques to validate our approach. Statistical analysis was performed to ensure result reliability.

Results: The experimental data shows significant improvements over baseline methods. Key performance indicators demonstrate the effectiveness of our proposed approach.

Discussion: These findings contribute to the current understanding of the field and provide insights for future research directions. Potential applications span multiple domains.

Conclusion: This work presents a significant advancement in the field with practical implications for real-world applications.